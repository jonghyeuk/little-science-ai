from openai import OpenAI
import streamlit as st
import re

# DOI ë§í¬ ë³€í™˜ í•¨ìˆ˜ ì¶”ê°€ (app.pyì—ì„œë„ ì‚¬ìš© ê°€ëŠ¥í•˜ë„ë¡)
def convert_doi_to_links(text):
    """DOI íŒ¨í„´ì„ ê°ì§€í•˜ì—¬ í´ë¦­ ê°€ëŠ¥í•œ ë§í¬ë¡œ ë³€í™˜"""
    # ë‹¤ì–‘í•œ DOI íŒ¨í„´ ì¸ì‹
    doi_pattern = r'(?:DOI\s*:?\s*)?(\b10\.\d{4,}\/[a-zA-Z0-9./_()-]+\b)'
    
    # HTML ë§í¬ë¡œ ë³€í™˜
    def replace_doi(match):
        doi = match.group(1)
        return f'<a href="https://doi.org/{doi}" target="_blank" style="color: #0969da; text-decoration: underline;">{doi}</a>'
    
    # í…ìŠ¤íŠ¸ ë‚´ DOI íŒ¨í„´ì„ ë§í¬ë¡œ ë³€í™˜
    linked_text = re.sub(doi_pattern, replace_doi, text)
    
    return linked_text

@st.cache_data(show_spinner="ğŸ¤– AI ì„¤ëª…ì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤...", ttl=3600)
def explain_topic(topic: str) -> list:
    """GPT-4 ê¸°ë°˜ ì£¼ì œ ì„¤ëª… ìƒì„± (ë¬¸ë‹¨ ë‹¨ìœ„ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜)"""
    try:
        client = OpenAI(api_key=st.secrets["api"]["openai_key"])
    except KeyError:
        st.error("âŒ OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        st.stop()
    
    system_prompt = """
    ë„ˆëŠ” 'LittleScienceAI ë„ìš°ë¯¸'ë¼ëŠ” AIë¡œ,
    ê³ ë“±í•™ìƒ ë˜ëŠ” ì²­ì†Œë…„ ì—°êµ¬ìì—ê²Œ ê³¼í•™ ì£¼ì œë¥¼ ì¹œì ˆí•˜ê³  ì •í™•í•˜ê²Œ ì„¤ëª…í•˜ëŠ” ì—­í• ì„ í•´.
    ì•„ë˜ì˜ í˜•ì‹ê³¼ ì›ì¹™ì„ ë”°ë¼ ì„¤ëª…í•´ì¤˜:
    
    1. ê°œë… ì •ì˜
    2. ì‘ë™ ì›ë¦¬
    3. í˜„ì¬ ê³¼í•™ì /ì‚¬íšŒì  ë°°ê²½
    4. ì‘ìš© ì‚¬ë¡€ ë° ë¶„ì•¼
    5. ê´€ë ¨ ë…¼ë¬¸ ì œëª©ê³¼ ì¶œì²˜(ê°€ëŠ¥í•œ DOI ë˜ëŠ” ë§í¬ í¬í•¨)
    6. í™•ì¥ ê°€ëŠ¥í•œ íƒêµ¬ ì•„ì´ë””ì–´ ì œì•ˆ
    
    âœ… ë°˜ë“œì‹œ ì§€í‚¬ ê²ƒ:
    - ì„¤ëª…ì€ ì¤‘ë¦½ì ì´ê³  êµìœ¡ì  í†¤ìœ¼ë¡œ, ê³ ë“±í•™ìƒ ëˆˆë†’ì´ì— ë§ê²Œ, êµ¬ì²´ì ìœ¼ë¡œ ì´í•´í•˜ê¸° ì‰½ê²Œ
    - ë¬¸ë‹¨ë³„ë¡œ êµ¬ë¶„í•˜ê³ , ê° ì„¹ì…˜ì˜ ì œëª©ì€ êµµì€ ê¸€ì”¨ë¡œ
    - ì‹¤ì œ í™•ì¸ëœ ë…¼ë¬¸ë§Œ ì¸ìš©í•˜ë˜ ë…¼ë¬¸ ì¸ìš©ì€ 1ê°œ~3ê°œì •ë„, ë…¼ë¬¸ì œëª©ì„ ë³´ì—¬ì£¼ê³  ì¶œì²˜ë¥¼ ë³´ì—¬ì¤„ê²ƒ
    - ì„¤ëª…ì€ í•œêµ­ì–´ë¡œ
    
    **í™•ì¥ ê°€ëŠ¥í•œ íƒêµ¬ ì•„ì´ë””ì–´ ì œì•ˆ** ì„¹ì…˜ì—ì„œëŠ”:
    - ìµœì†Œ 3ê°œ ì´ìƒì˜ êµ¬ì²´ì ì¸ ì—°êµ¬ ì•„ì´ë””ì–´ë¥¼ ì œì‹œí•  ê²ƒ
    - ê° ì•„ì´ë””ì–´ëŠ” ë³„ë„ì˜ ê¸€ë¨¸ë¦¬ ê¸°í˜¸(â€¢)ë¡œ êµ¬ë¶„í•˜ì—¬ ëª…í™•íˆ í‘œì‹œí•˜ê³  í•œì¤„ì— 1ê°œì”© í‘œì‹œ
    - ê° ì•„ì´ë””ì–´ë¥¼ 1-2ë¬¸ì¥ìœ¼ë¡œ ê°„ê²°í•˜ê²Œ ì„¤ëª…í•˜ë˜ ì•„ì´ë””ì–´ ê¸€ë¨¸ë¦¬ ë‹¤ìŒ ì¤„ì— í‘œì‹œ
    - ê° ì•„ì´ë””ì–´ì˜ ì„¤ëª…ì´ ì¤„ì´ ë„˜ì–´ê°€ë©´ ì•„ì´ë””ì–´ì˜ ê¸€ë¨¸ë¦¬ëŠ” ê·¸ ë‹¤ìŒì¤„ì— í‘œì‹œ
    - ë§ˆì§€ë§‰ì— "ì´ ë‚´ìš©ë“¤ì„ í† ëŒ€ë¡œ ì¶”ê°€ì ì¸ íƒêµ¬ì™€ í•™ìŠµì„ ìœ„í•´ ìœ„ ê²€ìƒ‰ì°¸ì— ì¬ê²€ìƒ‰ì„ ì§„í–‰í•´ ë³´ì„¸ìš”."ë¼ëŠ” ë¬¸êµ¬ë¥¼ ì¶”ê°€í•  ê²ƒ
    """
    
    user_prompt = f"ì£¼ì œ: {topic}"
    
    try:
        response = client.chat.completions.create(
            model="gpt-4-turbo",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            temperature=0.7
        )
        full_text = response.choices[0].message.content
        paragraphs = full_text.strip().split('\n\n')
        return [p.strip() for p in paragraphs if p.strip()]
    except Exception as e:
        st.error(f"âŒ GPT ì„¤ëª… ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return ["AI ì„¤ëª…ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."]

# ì§ì ‘ ë§í¬ê°€ í¬í•¨ëœ ì„¤ëª… ìƒì„± (ì•±ì—ì„œ ì„ íƒì  ì‚¬ìš© ê°€ëŠ¥)
def explain_topic_with_links(topic: str) -> str:
    """DOI ë§í¬ê°€ ìë™ ë³€í™˜ëœ ì£¼ì œ ì„¤ëª… ìƒì„±"""
    explanation_lines = explain_topic(topic)
    explanation_text = "\n\n".join(explanation_lines)
    return convert_doi_to_links(explanation_text)
