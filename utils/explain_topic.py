from openai import OpenAI
import streamlit as st

@st.cache_data(show_spinner="ğŸ¤– AI ì„¤ëª…ì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤...", ttl=3600)
def explain_topic(topic: str) -> list:
    """GPT-4 ê¸°ë°˜ ì£¼ì œ ì„¤ëª… ìƒì„± (ë¬¸ë‹¨ ë‹¨ìœ„ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜)"""
    try:
        client = OpenAI(api_key=st.secrets["api"]["openai_key"])
    except KeyError:
        st.error("âŒ OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        st.stop()

    system_prompt = """
    ë„ˆëŠ” 'LittleScienceAI ë„ìš°ë¯¸'ë¼ëŠ” AIë¡œ,
    ê³ ë“±í•™ìƒ ë˜ëŠ” ì²­ì†Œë…„ ì—°êµ¬ìì—ê²Œ ê³¼í•™ ì£¼ì œë¥¼ ì¹œì ˆí•˜ê³  ì •í™•í•˜ê²Œ ì„¤ëª…í•˜ëŠ” ì—­í• ì„ í•´.

    ì•„ë˜ì˜ í˜•ì‹ê³¼ ì›ì¹™ì„ ë”°ë¼ ì„¤ëª…í•´ì¤˜:

    1. ê°œë… ì •ì˜
    2. ì‘ë™ ì›ë¦¬
    3. í˜„ì¬ ê³¼í•™ì /ì‚¬íšŒì  ë°°ê²½
    4. ì‘ìš© ì‚¬ë¡€ ë° ë¶„ì•¼
    5. ê´€ë ¨ ë…¼ë¬¸ ì œëª©ê³¼ ì¶œì²˜(ê°€ëŠ¥í•œ DOI ë˜ëŠ” ë§í¬ í¬í•¨)
    6. í™•ì¥ ê°€ëŠ¥í•œ íƒêµ¬ ì•„ì´ë””ì–´ ì œì•ˆ

    âœ… ë°˜ë“œì‹œ ì§€í‚¬ ê²ƒ:
    - ì„¤ëª…ì€ ì¤‘ë¦½ì ì´ê³  êµìœ¡ì  í†¤ìœ¼ë¡œ, ê³ ë“±í•™ìƒ ëˆˆë†’ì´ì— ë§ê²Œ
    - ë¬¸ë‹¨ë³„ë¡œ êµ¬ë¶„í•˜ê³ , ê° ì„¹ì…˜ì˜ ì œëª©ì€ êµµì€ ê¸€ì”¨ë¡œ
    - ë…¼ë¬¸ ì¸ìš©ì€ ì ˆëŒ€ ê¸ˆì§€ì´ë©°, ìƒì„±ëœ ë‚´ìš©ì€ 'AIì˜ ì¶”ë¡ 'ì„ì„ ëª…ì‹œ
    - ì„¤ëª…ì€ í•œêµ­ì–´ë¡œ
    """

    user_prompt = f"ì£¼ì œ: {topic}"

    try:
        response = client.chat.completions.create(
            model="gpt-4-turbo",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            temperature=0.7
        )
        full_text = response.choices[0].message.content
        paragraphs = full_text.strip().split('\n\n')
        return [p.strip() for p in paragraphs if p.strip()]

    except Exception as e:
        st.error(f"âŒ GPT ì„¤ëª… ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return ["AI ì„¤ëª…ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."]
