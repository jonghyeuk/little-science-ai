import streamlit as st
import anthropic
import json
import re

@st.cache_data(ttl=3600, show_spinner=False)
def generate_research_paper(topic, research_idea, references=""):
    """
    ì„ íƒëœ ì—°êµ¬ ì•„ì´ë””ì–´ì— ëŒ€í•œ ë…¼ë¬¸ í˜•ì‹ì˜ ì—°êµ¬ ê³„íšì„ ìƒì„±
    """
    try:
        client = anthropic.Anthropic(api_key=st.secrets["api"]["claude_key"])
        
        # ğŸ”¥ ê°„ë‹¨í•˜ê³  ëª…í™•í•œ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ë¡œ ìˆ˜ì •
        system_prompt = """
        ê³ ë“±í•™ìƒ ì—°êµ¬ ê³„íšì„œë¥¼ JSON í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.

        ë°˜ë“œì‹œ ì´ JSON í˜•ì‹ë§Œ ì‚¬ìš©:
        {"abstract": "ì´ˆë¡ë‚´ìš©", "introduction": "ì„œë¡ ë‚´ìš©", "methods": "ë°©ë²•ë‚´ìš©", "results": "ê²°ê³¼ë‚´ìš©", "visuals": "ì‹œê°ìë£Œë‚´ìš©", "conclusion": "ê²°ë¡ ë‚´ìš©", "references": "ì°¸ê³ ë¬¸í—Œë‚´ìš©"}

        ê° ì„¹ì…˜ ìš”êµ¬ì‚¬í•­:
        - abstract: ì—°êµ¬ëª©ì ê³¼ ì˜ˆìƒê²°ê³¼ ìš”ì•½ (100-150ë‹¨ì–´) - í•™ìˆ ë…¼ë¬¸ í˜•ì‹, êµìœ¡ ëŒ€ìƒ ì–¸ê¸‰ ê¸ˆì§€
        - introduction: ë°°ê²½â†’ë¬¸ì œâ†’ëª©ì  ìˆœì„œ (200-250ë‹¨ì–´) - í•™ìˆ ë…¼ë¬¸ í˜•ì‹, êµìœ¡ ëŒ€ìƒ ì–¸ê¸‰ ê¸ˆì§€
        - methods: ì‹¤í—˜ë‹¨ê³„ë¥¼ ëª…í™•íˆ êµ¬ë¶„í•´ì„œ ì‘ì„± (250-300ë‹¨ì–´)
        - results: ì˜ˆìƒë˜ëŠ” êµ¬ì²´ì  ê²°ê³¼ë“¤ (150-200ë‹¨ì–´)
        - visuals: í•„ìš”í•œ ê·¸ë˜í”„/ì°¨íŠ¸ ì„¤ëª… (100-150ë‹¨ì–´)
        - conclusion: ì‹¤í—˜ì„ í†µí•´ ì¦ëª…í•˜ë ¤ëŠ” ê³¼í•™ì  ê²°ë¡ ê³¼ í•™ìˆ ì  ì˜ì˜ (100-150ë‹¨ì–´)
        - references: ì‹¤ì œ í™•ì¸ê°€ëŠ¥í•œ ìë£Œ 8-10ê°œ (ë°˜ë“œì‹œ ì‹¤ì œ ë§í¬ í¬í•¨)

        ì‹¤í—˜ë°©ë²• ì‘ì„±ë²•:
        1ë‹¨ê³„: [ì œëª©] - (ì¥ë¹„/ì¬ë£Œ ê°„ë‹¨íˆ)
        2ë‹¨ê³„: [ì œëª©] - "ë¨¼ì € ~ë¥¼ ì¤€ë¹„í•©ë‹ˆë‹¤. ë‹¤ìŒìœ¼ë¡œ ~ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤" í˜•íƒœë¡œ ì¹œì ˆí•˜ê²Œ ì„œìˆ 
        3ë‹¨ê³„: [ì œëª©] - "ê·¸ í›„ì— ~ë¥¼ ì§„í–‰í•©ë‹ˆë‹¤. ì´ë•Œ ì£¼ì˜í•  ì ì€ ~ì…ë‹ˆë‹¤" í˜•íƒœë¡œ ì¹œì ˆí•˜ê²Œ ì„œìˆ   
        4ë‹¨ê³„: [ì œëª©] - "ë§ˆì§€ë§‰ìœ¼ë¡œ ~ë¥¼ ì¸¡ì •í•©ë‹ˆë‹¤. ~ë¥¼ ê¸°ë¡í•©ë‹ˆë‹¤" í˜•íƒœë¡œ ì¹œì ˆí•˜ê²Œ ì„œìˆ 
        (ê° ë‹¨ê³„ë§ˆë‹¤ ê³ ë“±í•™ìƒì´ ë”°ë¼í•  ìˆ˜ ìˆë„ë¡ êµ¬ì²´ì ì´ê³  ì¹œì ˆí•œ ì„œìˆ í˜•ìœ¼ë¡œ)

        ì°¸ê³ ë¬¸í—Œ ì‘ì„±ë²•:
        1. ìë£Œì œëª© (ì´ 8-10ê°œ: í•œêµ­ì–´ 6ê°œ + ì˜ì–´ 4ê°œ)
        - ë‚´ìš©: í•µì‹¬ë‚´ìš© 2ë¬¸ì¥ ì„¤ëª…  
        - ë§í¬: ì‹¤ì œ DB ì‚¬ì´íŠ¸ ë§í¬ í¬í•¨
        - í™œìš©: ì—°êµ¬ì— ì–´ë–»ê²Œ ë„ì›€ë˜ëŠ”ì§€
        
        ì¤‘ìš”: ì£¼ì œì™€ ë°€ì ‘í•œ ê´€ë ¨ì´ ìˆëŠ” ìë£Œë§Œ ì„ íƒí•˜ì„¸ìš”.
        """
        
        # ğŸ”¥ ê°„ë‹¨í•œ ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸
        user_prompt = f"""
        ì£¼ì œ: {topic}
        ì•„ì´ë””ì–´: {research_idea}

        ìœ„ ë‚´ìš©ìœ¼ë¡œ í•™ìˆ  ì—°êµ¬ê³„íšì„œë¥¼ JSONìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.
        
        ì£¼ì˜ì‚¬í•­:
        - ì´ˆë¡ê³¼ ì„œë¡ : í•™ìˆ ë…¼ë¬¸ í˜•ì‹ìœ¼ë¡œ, "ê³ ë“±í•™ìƒ" ë“± êµìœ¡ ëŒ€ìƒ ì–¸ê¸‰ ê¸ˆì§€
        - ê²°ë¡ : ì‹¤í—˜ì„ í†µí•´ ì¦ëª…í•˜ë ¤ëŠ” ê³¼í•™ì  ê²°ë¡ ê³¼ í•™ìˆ ì  ì˜ì˜ ì¤‘ì‹¬
        - ì‹¤í—˜ë°©ë²•: "ë¨¼ì € ~ë¥¼ í•©ë‹ˆë‹¤. ë‹¤ìŒìœ¼ë¡œ ~ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤" ì¹œì ˆí•œ ì„œìˆ í˜•
        - ì°¸ê³ ë¬¸í—Œ: 8-10ê°œ, ì£¼ì œì™€ ì§ì ‘ ê´€ë ¨ëœ ìë£Œë§Œ ì„ íƒ
        """
        
        # Claude í˜¸ì¶œ
        response = client.messages.create(
            model="claude-3-5-sonnet-20241022",
            max_tokens=3000,
            temperature=0.2,
            system=system_prompt,
            messages=[
                {"role": "user", "content": user_prompt}
            ]
        )
        
        response_text = response.content[0].text.strip()
        print(f"=== Claude ì‘ë‹µ ì›ë³¸ ===")
        print(response_text[:300] + "...")

        paper_data = extract_json_robust(response_text)
        if paper_data:
            paper_data = validate_and_fix_sections(paper_data)
        
        return paper_data if paper_data else create_error_response()
        
    except Exception as e:
        print(f"âŒ ì „ì²´ ë…¼ë¬¸ ìƒì„± ì˜¤ë¥˜: {e}")
        return create_error_response()

def extract_json_robust(text):
    try:
        try:
            return json.loads(text)
        except:
            pass
        
        if "```json" in text:
            content = text.split("```json")[1].split("```")[0].strip()
        elif "```" in text:
            content = text.split("```")[1].strip()
        else:
            content = text
        
        try:
            return json.loads(content)
        except:
            pass
        
        json_pattern = r'\{[^{}]*(?:\{[^{}]*\}[^{}]*)*\}'
        matches = re.findall(json_pattern, text, re.DOTALL)
        
        for match in matches:
            try:
                data = json.loads(match)
                if isinstance(data, dict) and 'abstract' in data:
                    return data
            except:
                continue
        
        return manual_parse_sections(text)
        
    except:
        return None

def manual_parse_sections(text):
    try:
        sections = {
            "abstract": "",
            "introduction": "",
            "methods": "",
            "results": "",
            "visuals": "",
            "conclusion": "",
            "references": ""
        }
        
        keywords = {
            'abstract': ['ì´ˆë¡', 'abstract', 'ìš”ì•½'],
            'introduction': ['ì„œë¡ ', 'introduction', 'ë°°ê²½', 'ë„ì…'],
            'methods': ['ë°©ë²•', 'method', 'ì‹¤í—˜', 'ì ˆì°¨'],
            'results': ['ê²°ê³¼', 'result', 'ì˜ˆìƒ'],
            'visuals': ['ì‹œê°', 'visual', 'ê·¸ë˜í”„', 'ì°¨íŠ¸'],
            'conclusion': ['ê²°ë¡ ', 'conclusion', 'ê²°ê³¼'],
            'references': ['ì°¸ê³ ', 'reference', 'ë¬¸í—Œ']
        }
        
        lines = text.split('\n')
        current_section = None
        
        for line in lines:
            line = line.strip()
            if not line or line.startswith('{') or line.startswith('}'):
                continue
            
            found_section = None
            for section, kws in keywords.items():
                if any(kw in line.lower() for kw in kws):
                    found_section = section
                    break
            
            if found_section:
                current_section = found_section
            elif current_section and not line.startswith('"') and not line.startswith(','):
                if sections[current_section]:
                    sections[current_section] += " " + line
                else:
                    sections[current_section] = line
        
        for key, value in sections.items():
            if not value.strip():
                sections[key] = get_default_content(key)
        
        return sections
        
    except:
        return None

def validate_and_fix_sections(paper_data):
    try:
        required_sections = ['abstract', 'introduction', 'methods', 'results', 'visuals', 'conclusion', 'references']
        
        for section in required_sections:
            if section not in paper_data or not paper_data[section] or len(paper_data[section].strip()) < 20:
                paper_data[section] = get_default_content(section)
        
        if len(paper_data['methods']) > 1000:
            methods_text = paper_data['methods'][:800] + "...\n\në°ì´í„° ìˆ˜ì§‘ ë° ë¶„ì„: ì‹¤í—˜ ê²°ê³¼ë¥¼ ì²´ê³„ì ìœ¼ë¡œ ê¸°ë¡í•˜ê³  í†µê³„ì ìœ¼ë¡œ ë¶„ì„í•©ë‹ˆë‹¤."
            paper_data['methods'] = methods_text
        
        if paper_data['references']:
            paper_data['references'] = clean_references(paper_data['references'])
            paper_data['references'] = make_links_clickable(paper_data['references'])  # âœ… ë§í¬ í´ë¦­ ê°€ëŠ¥í•˜ê²Œ ì²˜ë¦¬
        
        return paper_data
        
    except:
        return paper_data

def make_links_clickable(reference_text):
    """ë§í¬ í…ìŠ¤íŠ¸ë¥¼ ì‹¤ì œ í´ë¦­ ê°€ëŠ¥í•œ <a> ë§í¬ë¡œ ë³€í™˜"""
    url_pattern = r'(https?://[^\s]+)'
    return re.sub(url_pattern, r'<a href="\1" target="_blank" style="color:#0969da;">ğŸ”— ë§í¬ ë°”ë¡œê°€ê¸°</a>', reference_text)

def get_default_content(section):
    defaults = {
        'abstract': "ë³¸ ì—°êµ¬ëŠ” ì œì‹œëœ ì£¼ì œì— ëŒ€í•´ ì²´ê³„ì ì¸ ì‹¤í—˜ì„ í†µí•´ ê³¼í•™ì  ê·¼ê±°ë¥¼ í™•ë³´í•˜ê³ ì í•œë‹¤...",
        'introduction': "í˜„ì¬ ê´€ë ¨ ë¶„ì•¼ì—ì„œëŠ” ë‹¤ì–‘í•œ ì—°êµ¬ê°€ ì§„í–‰ë˜ê³  ìˆì§€ë§Œ...",
        'methods': "1ë‹¨ê³„: ì‹¤í—˜ ì¬ë£Œ ì¤€ë¹„\ní•„ìš”í•œ ì‹¤í—˜ ë„êµ¬ì™€ ì¬ë£Œë¥¼ ì¤€ë¹„í•©ë‹ˆë‹¤...\n\n4ë‹¨ê³„: ê²°ê³¼ ë¶„ì„ ë° ì •ë¦¬...",
        'results': "ì‹¤í—˜ì„ í†µí•´ ë‹¤ìŒê³¼ ê°™ì€ ê²°ê³¼ë¥¼ ì–»ì„ ê²ƒìœ¼ë¡œ ì˜ˆìƒëœë‹¤...",
        'visuals': "ì‹¤í—˜ ê²°ê³¼ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ í‘œí˜„í•˜ê¸° ìœ„í•´ ë‹¤ìŒê³¼ ê°™ì€ ì‹œê°ìë£Œë¥¼ ì œì‘í•  ì˜ˆì •ì…ë‹ˆë‹¤...",
        'conclusion': "ë³¸ ì—°êµ¬ë¥¼ í†µí•´ ì œì‹œëœ ê°€ì„¤ì´ ì‹¤í—˜ì ìœ¼ë¡œ ê²€ì¦ë  ê²ƒìœ¼ë¡œ ì˜ˆìƒëœë‹¤...",
        'references': "1. ê´€ë ¨ ì£¼ì œ ìµœì‹  ì—°êµ¬ ë™í–¥\n- ë§í¬: https://www.dbpia.co.kr/\n..."
    }
    return defaults.get(section, f"{section} ì„¹ì…˜ ë‚´ìš©ì´ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

def clean_references(ref_text):
    try:
        cleaned = ref_text
        all_links = re.findall(r'https://[^\s]*', cleaned)
        replacement_links = [
            'https://www.dbpia.co.kr/',
            'https://www.riss.kr/',
            'https://www.kci.go.kr/',
            'https://www.ndsl.kr/',
            'https://kiss.kstudy.com/',
            'https://www.nl.go.kr/',
            'https://www.sciencedirect.com/',
            'https://ieeexplore.ieee.org/',
            'https://www.nature.com/',
            'https://pubmed.ncbi.nlm.nih.gov/'
        ]
        for i, old_link in enumerate(all_links):
            if i < len(replacement_links):
                replacement_link = replacement_links[i]
                cleaned = cleaned.replace(old_link, replacement_link, 1)
            else:
                replacement_link = replacement_links[i % len(replacement_links)]
                cleaned = cleaned.replace(old_link, replacement_link, 1)
        return cleaned.strip()
    except:
        return ref_text

def parse_text_response(text):
    return manual_parse_sections(text)

def create_error_response():
    return {
        "abstract": "ë…¼ë¬¸ ì´ˆë¡ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤...",
        "introduction": "ì„œë¡  ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤...",
        "methods": "ì—°êµ¬ ë°©ë²• ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤...",
        "results": "ì˜ˆìƒ ê²°ê³¼ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤...",
        "visuals": "ì‹œê°ìë£Œ ì œì•ˆ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
        "conclusion": "ê²°ë¡  ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
        "references": "ì°¸ê³ ë¬¸í—Œ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
    }
