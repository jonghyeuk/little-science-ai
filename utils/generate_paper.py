# utils/generate_paper.py
import streamlit as st
import anthropic
import json
import re

@st.cache_data(ttl=3600, show_spinner=False)
def generate_research_paper(topic, research_idea, references=""):
    """
    ì„ íƒëœ ì—°êµ¬ ì•„ì´ë””ì–´ì— ëŒ€í•œ ë…¼ë¬¸ í˜•ì‹ì˜ ì—°êµ¬ ê³„íšì„ ìƒì„±
    """
    try:
        client = anthropic.Anthropic(api_key=st.secrets["api"]["claude_key"])
        
        # ì„œë¡  ì¶”ê°€ëœ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ - JSON í˜•ì‹ ì—„ê²©íˆ ìš”êµ¬ + ì°¸ê³ ë¬¸í—Œ ì§€ì¹¨ë§Œ ì¶”ê°€
        system_prompt = """
        ê³ ë“±í•™ìƒì„ ìœ„í•œ ì—°êµ¬ ê³„íšì„œë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”. ë°˜ë“œì‹œ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”.
        
        ì‘ë‹µ í˜•ì‹ (ì´ í˜•ì‹ ì™¸ì—ëŠ” ì ˆëŒ€ ë‹¤ë¥¸ í…ìŠ¤íŠ¸ í¬í•¨ ê¸ˆì§€):
        {"abstract": "ì´ˆë¡", "introduction": "ì„œë¡ ", "methods": "ë°©ë²•", "results": "ê²°ê³¼", "visuals": "ì‹œê°ìë£Œ", "conclusion": "ê²°ë¡ ", "references": "ì°¸ê³ ë¬¸í—Œ"}
        
        ê° ì„¹ì…˜ ì‘ì„± ê°€ì´ë“œ:
        - abstract: ì—°êµ¬ ëª©ì ê³¼ ì˜ˆìƒ ê²°ê³¼ë¥¼ ê°„ë‹¨íˆ ìš”ì•½ (150-200ë‹¨ì–´)
        - introduction: ì—°êµ¬ ë°°ê²½ â†’ ë¬¸ì œì  â†’ ê¸°ì¡´ ì—°êµ¬ â†’ ë³¸ ì—°êµ¬ ëª©ì  ìˆœì„œë¡œ ì‘ì„± (300-400ë‹¨ì–´)
        - methods: ì‹¤í—˜ ì ˆì°¨ì™€ ë°©ë²•ë¡  (300-400ë‹¨ì–´)  
        - results: ì˜ˆìƒë˜ëŠ” ê²°ê³¼ì™€ ì˜ë¯¸ (200-300ë‹¨ì–´)
        - visuals: ì‹œê°ìë£Œ ì œì•ˆì„ í…ìŠ¤íŠ¸ë¡œ ì„¤ëª… (100-200ë‹¨ì–´)
        - conclusion: ì—°êµ¬ì˜ ì˜ì˜ì™€ ê¸°ëŒ€íš¨ê³¼ (150-200ë‹¨ì–´)
        - references: ì•„ë˜ ê·œì¹™ì— ë”°ë¼ ì‹¤ì œ ìë£Œë§Œ ì°¸ì¡°
        
        **ì°¸ê³ ë¬¸í—Œ ì‘ì„± ê·œì¹™:**
        1. ì ˆëŒ€ë¡œ êµ¬ì²´ì ì¸ ë…¼ë¬¸ ì œëª©ì´ë‚˜ ì €ìëª…ì„ ì§€ì–´ë‚´ì§€ ë§ˆë¼
        2. ëŒ€ì‹  ì •ë¶€ê¸°ê´€ ë³´ê³ ì„œ, í•™íšŒ ë°œí‘œìë£Œ, ëŒ€í•™ ì—°êµ¬ì†Œ ìë£Œë§Œ ì œì•ˆí•˜ë¼
        3. í˜•ì‹: **ìë£Œìœ í˜•: ì¼ë°˜ì£¼ì œ** (ì—°ë„) - ê¸°ê´€ëª…
           ìš”ì•½: ì´ ìë£Œì˜ í•µì‹¬ ë‚´ìš© 2-3ë¬¸ì¥ ì„¤ëª…
           ê´€ë ¨ì„±: ë³¸ ì—°êµ¬ì— ì–´ë–»ê²Œ ë„ì›€ì´ ë˜ëŠ”ì§€ 1-2ë¬¸ì¥
           [ê²€ìƒ‰ë§í¬](https://scholar.google.com/scholar?q=í•µì‹¬í‚¤ì›Œë“œ)
        
        ê³ ë“±í•™ìƒì´ ì´í•´í•  ìˆ˜ ìˆëŠ” ìˆ˜ì¤€ìœ¼ë¡œ ì‘ì„±í•˜ë˜, ì²´ê³„ì ì´ê³  êµ¬ì²´ì ìœ¼ë¡œ ì¨ì£¼ì„¸ìš”.
        """
        
        # ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸ - ì°¸ê³ ë¬¸í—Œ ì˜ˆì‹œë§Œ ì¶”ê°€
        user_prompt = f"""
        ì£¼ì œ: {topic}
        ì—°êµ¬ ì•„ì´ë””ì–´: {research_idea}
        
        ìœ„ ë‚´ìš©ìœ¼ë¡œ ê³ ë“±í•™ìƒ ìˆ˜ì¤€ì˜ ì—°êµ¬ ê³„íšì„œë¥¼ JSON í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.
        ê° ì„¹ì…˜ë‹¹ 150-300ë‹¨ì–´ ì •ë„ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.
        
        ì°¸ê³ ë¬¸í—Œ ì˜ˆì‹œ:
        **ì •ë¶€ë³´ê³ ì„œ: ì²­ì†Œë…„ ê±´ê°•ì‹¤íƒœì¡°ì‚¬** (2023) - ë³´ê±´ë³µì§€ë¶€
        ìš”ì•½: ì „êµ­ ì²­ì†Œë…„ì˜ ê±´ê°•ìƒíƒœì™€ ìƒí™œìŠµê´€ì„ ì¡°ì‚¬í•œ ê³µì‹í†µê³„ ìë£Œì…ë‹ˆë‹¤.
        ê´€ë ¨ì„±: ë³¸ ì—°êµ¬ ëŒ€ìƒì¸ ì²­ì†Œë…„ì¸µì˜ í˜„í™© íŒŒì•…ì— í•„ìˆ˜ì ì¸ ê¸°ì´ˆìë£Œì…ë‹ˆë‹¤.
        [ê´€ë ¨ìë£Œ ê²€ìƒ‰](https://scholar.google.com/scholar?q=ì²­ì†Œë…„+ê±´ê°•ì‹¤íƒœ+ë³´ê±´ë³µì§€ë¶€)
        """
        
        # Claude í˜¸ì¶œ
        response = client.messages.create(
            model="claude-3-5-sonnet-20241022",
            max_tokens=3000,
            temperature=0.3,  # ë” ì¼ê´€ëœ JSON ì‘ë‹µì„ ìœ„í•´ ë‚®ì¶¤
            system=system_prompt,
            messages=[
                {"role": "user", "content": user_prompt}
            ]
        )
        
        response_text = response.content[0].text.strip()
        print(f"=== Claude ì‘ë‹µ ì›ë³¸ ===")
        print(response_text[:500] + "...")
        
        # JSON ì¶”ì¶œ ì‹œë„ (ì—¬ëŸ¬ ë°©ë²•ìœ¼ë¡œ)
        paper_data = None
        
        # ë°©ë²• 1: ì§ì ‘ JSON íŒŒì‹±
        try:
            paper_data = json.loads(response_text)
            print("âœ… ì§ì ‘ JSON íŒŒì‹± ì„±ê³µ")
        except:
            print("âŒ ì§ì ‘ JSON íŒŒì‹± ì‹¤íŒ¨, ë‹¤ë¥¸ ë°©ë²• ì‹œë„...")
        
        # ë°©ë²• 2: ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡ ì œê±° í›„ íŒŒì‹±
        if not paper_data:
            try:
                # ```json ... ``` ì œê±°
                if "```json" in response_text:
                    json_content = response_text.split("```json")[1].split("```")[0].strip()
                elif "```" in response_text:
                    json_content = response_text.split("```")[1].strip()
                else:
                    json_content = response_text
                
                paper_data = json.loads(json_content)
                print("âœ… ë§ˆí¬ë‹¤ìš´ ì œê±° í›„ JSON íŒŒì‹± ì„±ê³µ")
            except Exception as e:
                print(f"âŒ ë§ˆí¬ë‹¤ìš´ ì œê±° í›„ì—ë„ ì‹¤íŒ¨: {e}")
        
        # ë°©ë²• 3: ì •ê·œì‹ìœ¼ë¡œ JSON ì¶”ì¶œ
        if not paper_data:
            try:
                # { ... } íŒ¨í„´ ì°¾ê¸°
                json_pattern = r'\{.*\}'
                json_match = re.search(json_pattern, response_text, re.DOTALL)
                if json_match:
                    json_content = json_match.group(0)
                    paper_data = json.loads(json_content)
                    print("âœ… ì •ê·œì‹ ì¶”ì¶œ í›„ JSON íŒŒì‹± ì„±ê³µ")
            except Exception as e:
                print(f"âŒ ì •ê·œì‹ ì¶”ì¶œ í›„ì—ë„ ì‹¤íŒ¨: {e}")
        
        # ë°©ë²• 4: í‚¤ì›Œë“œ ê¸°ë°˜ í…ìŠ¤íŠ¸ íŒŒì‹± (ìµœí›„ì˜ ìˆ˜ë‹¨)
        if not paper_data:
            print("âš ï¸ JSON íŒŒì‹± ëª¨ë‘ ì‹¤íŒ¨, í…ìŠ¤íŠ¸ íŒŒì‹±ìœ¼ë¡œ ëŒ€ì²´")
            paper_data = parse_text_response(response_text)
        
        # ğŸ”¥ ì°¸ê³ ë¬¸í—Œë§Œ í›„ì²˜ë¦¬ ì¶”ê°€
        if paper_data and 'references' in paper_data:
            paper_data['references'] = clean_fake_references(paper_data['references'])
        
        return paper_data
        
    except Exception as e:
        print(f"âŒ ì „ì²´ ë…¼ë¬¸ ìƒì„± ì˜¤ë¥˜: {e}")
        return create_error_response()

def parse_text_response(text):
    """JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ í…ìŠ¤íŠ¸ì—ì„œ ì„¹ì…˜ë³„ë¡œ ì¶”ì¶œ"""
    try:
        sections = {
            "abstract": "",
            "introduction": "",
            "methods": "",
            "results": "",
            "visuals": "",
            "conclusion": "",
            "references": ""
        }
        
        # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ë§¤ì¹­ìœ¼ë¡œ ì„¹ì…˜ ì¶”ì¶œ
        lines = text.split('\n')
        current_section = None
        
        for line in lines:
            line = line.strip()
            if not line:
                continue
                
            # ì„¹ì…˜ í—¤ë” ê°ì§€
            if any(keyword in line.lower() for keyword in ['ì´ˆë¡', 'abstract']):
                current_section = 'abstract'
            elif any(keyword in line.lower() for keyword in ['ì„œë¡ ', 'introduction', 'ë°°ê²½']):
                current_section = 'introduction'
            elif any(keyword in line.lower() for keyword in ['ë°©ë²•', 'method']):
                current_section = 'methods'
            elif any(keyword in line.lower() for keyword in ['ê²°ê³¼', 'result']):
                current_section = 'results'
            elif any(keyword in line.lower() for keyword in ['ì‹œê°', 'visual']):
                current_section = 'visuals'
            elif any(keyword in line.lower() for keyword in ['ê²°ë¡ ', 'conclusion']):
                current_section = 'conclusion'
            elif any(keyword in line.lower() for keyword in ['ì°¸ê³ ', 'reference']):
                current_section = 'references'
            elif current_section and not line.startswith('#'):
                # í˜„ì¬ ì„¹ì…˜ì— ë‚´ìš© ì¶”ê°€
                sections[current_section] += line + " "
        
        # ë¹ˆ ì„¹ì…˜ ì±„ìš°ê¸°
        for key, value in sections.items():
            if not value.strip():
                sections[key] = f"{key.title()} ì„¹ì…˜ì´ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
        
        return sections
        
    except Exception as e:
        print(f"í…ìŠ¤íŠ¸ íŒŒì‹± ì˜¤ë¥˜: {e}")
        return create_error_response()

# ğŸ”¥ ìƒˆë¡œ ì¶”ê°€: ê°€ì§œ ì°¸ê³ ë¬¸í—Œ ì •ë¦¬ í•¨ìˆ˜
def clean_fake_references(ref_text):
    """ê°€ì§œ ë…¼ë¬¸ëª…/ì €ìëª… ì œê±°í•˜ê³  ì•ˆì „í•œ ë§í¬ë¡œ êµì²´"""
    try:
        cleaned = ref_text
        
        # ê°€ì§œ DOI ì œê±°
        cleaned = re.sub(r'DOI\s*:?\s*10\.\d+\/[^\s]+', '', cleaned)
        
        # ì˜ì‹¬ìŠ¤ëŸ¬ìš´ ê°€ì§œ ì €ìëª… ì œê±°
        fake_authors = ['Smith, J.', 'Johnson, A.', 'Brown, M.', 'Lee, K.', 'Kim, S.', 'Park, H.']
        for fake in fake_authors:
            cleaned = cleaned.replace(f'- {fake}', '- ì—°êµ¬ì§„')
            cleaned = cleaned.replace(fake, 'ì—°êµ¬ì§„')
        
        # ê°€ì§œ ì§ì ‘ë§í¬ ì œê±° (scholar.google.com ì œì™¸)
        cleaned = re.sub(r'https?://(?!scholar\.google\.com)[^\s\)]+', '', cleaned)
        
        return cleaned.strip()
    except:
        return ref_text

def create_error_response():
    """ì—ëŸ¬ ë°œìƒ ì‹œ ê¸°ë³¸ ì‘ë‹µ"""
    return {
        "abstract": "ë…¼ë¬¸ ì´ˆë¡ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì£¼ì œë¥¼ ë” êµ¬ì²´ì ìœ¼ë¡œ ì…ë ¥í•˜ê³  ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.",
        "introduction": "ì„œë¡  ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì—°êµ¬ ë°°ê²½ì„ ë‹¤ì‹œ ê²€í† í•´ì£¼ì„¸ìš”.",
        "methods": "ì—°êµ¬ ë°©ë²• ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.",
        "results": "ì˜ˆìƒ ê²°ê³¼ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë„¤íŠ¸ì›Œí¬ ìƒíƒœë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.",
        "visuals": "ì‹œê°ìë£Œ ì œì•ˆ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
        "conclusion": "ê²°ë¡  ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
        "references": "ì°¸ê³ ë¬¸í—Œ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
    }
