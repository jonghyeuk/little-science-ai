# utils/generate_paper.py
import streamlit as st
import anthropic
import json
import re

@st.cache_data(ttl=3600, show_spinner=False)
def generate_research_paper(topic, research_idea, references=""):
    """
    ì„ íƒëœ ì—°êµ¬ ì•„ì´ë””ì–´ì— ëŒ€í•œ ë…¼ë¬¸ í˜•ì‹ì˜ ì—°êµ¬ ê³„íšì„ ìƒì„±
    """
    try:
        client = anthropic.Anthropic(api_key=st.secrets["api"]["claude_key"])
        
        # ğŸ”¥ ì°¸ê³ ë¬¸í—Œ ì„¹ì…˜ ê°œì„ ëœ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
        system_prompt = """
        ê³ ë“±í•™ìƒì„ ìœ„í•œ ì—°êµ¬ ê³„íšì„œë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”. ë°˜ë“œì‹œ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”.
        
        ì‘ë‹µ í˜•ì‹ (ì´ í˜•ì‹ ì™¸ì—ëŠ” ì ˆëŒ€ ë‹¤ë¥¸ í…ìŠ¤íŠ¸ í¬í•¨ ê¸ˆì§€):
        {"abstract": "ì´ˆë¡", "introduction": "ì„œë¡ ", "methods": "ë°©ë²•", "results": "ê²°ê³¼", "visuals": "ì‹œê°ìë£Œ", "conclusion": "ê²°ë¡ ", "references": "ì°¸ê³ ë¬¸í—Œ"}
        
        ê° ì„¹ì…˜ ì‘ì„± ê°€ì´ë“œ:
        - abstract: ì—°êµ¬ ëª©ì ê³¼ ì˜ˆìƒ ê²°ê³¼ë¥¼ ê°„ë‹¨íˆ ìš”ì•½ (150-200ë‹¨ì–´)
        - introduction: ì—°êµ¬ ë°°ê²½ â†’ ë¬¸ì œì  â†’ ê¸°ì¡´ ì—°êµ¬ â†’ ë³¸ ì—°êµ¬ ëª©ì  ìˆœì„œë¡œ ì‘ì„± (300-400ë‹¨ì–´)
        - methods: ì‹¤í—˜ ì ˆì°¨ì™€ ë°©ë²•ë¡  (300-400ë‹¨ì–´)  
        - results: ì˜ˆìƒë˜ëŠ” ê²°ê³¼ì™€ ì˜ë¯¸ (200-300ë‹¨ì–´)
        - visuals: ì‹œê°ìë£Œ ì œì•ˆì„ í…ìŠ¤íŠ¸ë¡œ ì„¤ëª… (100-200ë‹¨ì–´)
        - conclusion: ì—°êµ¬ì˜ ì˜ì˜ì™€ ê¸°ëŒ€íš¨ê³¼ (150-200ë‹¨ì–´)
        - references: ì°¸ê³ ë¬¸í—Œ ëª©ë¡ (ì•„ë˜ í˜•ì‹ ì—„ê²©íˆ ì¤€ìˆ˜)
        
        **ğŸ”¥ ì°¸ê³ ë¬¸í—Œ ì‘ì„± ê·œì¹™ (ë§¤ìš° ì¤‘ìš”):**
        1. ì ˆëŒ€ë¡œ êµ¬ì²´ì ì¸ DOIë‚˜ ì§ì ‘ ë…¼ë¬¸ ë§í¬ë¥¼ ë§Œë“¤ì–´ë‚´ì§€ ë§ˆë¼
        2. ì¼ë°˜ì ì´ê³  ì‹¤ì œ ì¡´ì¬í•  ê°€ëŠ¥ì„±ì´ ë†’ì€ ë…¼ë¬¸ ì œëª©ë§Œ ì‚¬ìš©
        3. ê° ì°¸ê³ ë¬¸í—Œë§ˆë‹¤ ë‹¤ìŒ í˜•ì‹ì„ ì •í™•íˆ ë”°ë¼ë¼:
        
        **ë…¼ë¬¸ì œëª©** (ì—°ë„) - ì €ìëª…
        ê´€ë ¨ì„±: ì´ ë…¼ë¬¸ì´ ë³¸ ì—°êµ¬ì™€ ì–´ë–»ê²Œ ê´€ë ¨ë˜ëŠ”ì§€ 1-2ë¬¸ì¥ìœ¼ë¡œ ì„¤ëª…
        [Google Scholarì—ì„œ ê²€ìƒ‰](https://scholar.google.com/scholar?q=ë…¼ë¬¸ì œëª©+í‚¤ì›Œë“œ)
        
        4. 3-5ê°œì˜ ì°¸ê³ ë¬¸í—Œì„ ì œì•ˆí•˜ë˜, ëª¨ë‘ ì¼ë°˜ì ì¸ ì£¼ì œì–´ë¡œ êµ¬ì„±
        5. ê²€ìƒ‰ ë§í¬ëŠ” ë…¼ë¬¸ ì œëª©ì˜ í•µì‹¬ í‚¤ì›Œë“œë¥¼ í¬í•¨í•˜ì—¬ ì‹¤ì œ ê²€ìƒ‰ ê°€ëŠ¥í•˜ê²Œ ë§Œë“¤ì–´ë¼
        
        ê³ ë“±í•™ìƒì´ ì´í•´í•  ìˆ˜ ìˆëŠ” ìˆ˜ì¤€ìœ¼ë¡œ ì‘ì„±í•˜ë˜, ì²´ê³„ì ì´ê³  êµ¬ì²´ì ìœ¼ë¡œ ì¨ì£¼ì„¸ìš”.
        """
        
        # ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸ì— ì°¸ê³ ë¬¸í—Œ ì˜ˆì‹œ ì¶”ê°€
        user_prompt = f"""
        ì£¼ì œ: {topic}
        ì—°êµ¬ ì•„ì´ë””ì–´: {research_idea}
        
        ìœ„ ë‚´ìš©ìœ¼ë¡œ ê³ ë“±í•™ìƒ ìˆ˜ì¤€ì˜ ì—°êµ¬ ê³„íšì„œë¥¼ JSON í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.
        
        **ì°¸ê³ ë¬¸í—Œ ì‘ì„± ì˜ˆì‹œ:**
        **Exercise and Body Fat Reduction in Adolescents** (2023) - Smith, J. et al.
        ê´€ë ¨ì„±: ì²­ì†Œë…„ì˜ ìš´ë™ê³¼ ì²´ì§€ë°© ê°ì†Œì— ëŒ€í•œ ê¸°ì´ˆ ì—°êµ¬ë¡œ, ë³¸ ì—°êµ¬ì˜ ì´ë¡ ì  ë°°ê²½ì„ ì œê³µí•©ë‹ˆë‹¤.
        [Google Scholarì—ì„œ ê²€ìƒ‰](https://scholar.google.com/scholar?q=exercise+body+fat+reduction+adolescents)
        
        ì´ëŸ° í˜•ì‹ìœ¼ë¡œ ì‹¤ì œ ê²€ìƒ‰ ê°€ëŠ¥í•œ ì°¸ê³ ë¬¸í—Œì„ 3-5ê°œ ì œì•ˆí•´ì£¼ì„¸ìš”.
        """
        
        # Claude í˜¸ì¶œ
        response = client.messages.create(
            model="claude-3-5-sonnet-20241022",
            max_tokens=3500,  # ì°¸ê³ ë¬¸í—Œ ì„¤ëª…ì„ ìœ„í•´ í† í° ìˆ˜ ì¦ê°€
            temperature=0.3,
            system=system_prompt,
            messages=[
                {"role": "user", "content": user_prompt}
            ]
        )
        
        response_text = response.content[0].text.strip()
        print(f"=== Claude ì‘ë‹µ ì›ë³¸ ===")
        print(response_text[:500] + "...")
        
        # JSON ì¶”ì¶œ ì‹œë„ (ì—¬ëŸ¬ ë°©ë²•ìœ¼ë¡œ)
        paper_data = None
        
        # ë°©ë²• 1: ì§ì ‘ JSON íŒŒì‹±
        try:
            paper_data = json.loads(response_text)
            print("âœ… ì§ì ‘ JSON íŒŒì‹± ì„±ê³µ")
        except:
            print("âŒ ì§ì ‘ JSON íŒŒì‹± ì‹¤íŒ¨, ë‹¤ë¥¸ ë°©ë²• ì‹œë„...")
        
        # ë°©ë²• 2: ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡ ì œê±° í›„ íŒŒì‹±
        if not paper_data:
            try:
                # ```json ... ``` ì œê±°
                if "```json" in response_text:
                    json_content = response_text.split("```json")[1].split("```")[0].strip()
                elif "```" in response_text:
                    json_content = response_text.split("```")[1].strip()
                else:
                    json_content = response_text
                
                paper_data = json.loads(json_content)
                print("âœ… ë§ˆí¬ë‹¤ìš´ ì œê±° í›„ JSON íŒŒì‹± ì„±ê³µ")
            except Exception as e:
                print(f"âŒ ë§ˆí¬ë‹¤ìš´ ì œê±° í›„ì—ë„ ì‹¤íŒ¨: {e}")
        
        # ë°©ë²• 3: ì •ê·œì‹ìœ¼ë¡œ JSON ì¶”ì¶œ
        if not paper_data:
            try:
                # { ... } íŒ¨í„´ ì°¾ê¸°
                json_pattern = r'\{.*\}'
                json_match = re.search(json_pattern, response_text, re.DOTALL)
                if json_match:
                    json_content = json_match.group(0)
                    paper_data = json.loads(json_content)
                    print("âœ… ì •ê·œì‹ ì¶”ì¶œ í›„ JSON íŒŒì‹± ì„±ê³µ")
            except Exception as e:
                print(f"âŒ ì •ê·œì‹ ì¶”ì¶œ í›„ì—ë„ ì‹¤íŒ¨: {e}")
        
        # ë°©ë²• 4: í‚¤ì›Œë“œ ê¸°ë°˜ í…ìŠ¤íŠ¸ íŒŒì‹± (ìµœí›„ì˜ ìˆ˜ë‹¨)
        if not paper_data:
            print("âš ï¸ JSON íŒŒì‹± ëª¨ë‘ ì‹¤íŒ¨, í…ìŠ¤íŠ¸ íŒŒì‹±ìœ¼ë¡œ ëŒ€ì²´")
            paper_data = parse_text_response(response_text)
        
        # ğŸ”¥ ì°¸ê³ ë¬¸í—Œ í›„ì²˜ë¦¬ - ì•ˆì „í•œ ë§í¬ì¸ì§€ í™•ì¸
        if paper_data and 'references' in paper_data:
            paper_data['references'] = post_process_references(paper_data['references'], topic)
        
        return paper_data
        
    except Exception as e:
        print(f"âŒ ì „ì²´ ë…¼ë¬¸ ìƒì„± ì˜¤ë¥˜: {e}")
        return create_error_response(topic)

def post_process_references(references_text, topic):
    """ì°¸ê³ ë¬¸í—Œ í›„ì²˜ë¦¬ - ì•ˆì „í•œ Google Scholar ë§í¬ë¡œ ë³´ì¥"""
    try:
        # DOIë‚˜ ì§ì ‘ ë§í¬ê°€ ìˆìœ¼ë©´ ì œê±°í•˜ê³  Google Scholar ë§í¬ë¡œ êµì²´
        processed_text = references_text
        
        # DOI íŒ¨í„´ ì œê±°
        doi_pattern = r'(?:DOI\s*:?\s*)?(\b10\.\d{4,}\/[a-zA-Z0-9./_()-]+\b)'
        processed_text = re.sub(doi_pattern, '', processed_text)
        
        # ì˜ëª»ëœ ì§ì ‘ ë§í¬ ì œê±° (httpë¡œ ì‹œì‘í•˜ëŠ” ê²ƒ ì¤‘ scholar.google.comì´ ì•„ë‹Œ ê²ƒ)
        link_pattern = r'https?://(?!scholar\.google\.com)[^\s\)]+\b'
        processed_text = re.sub(link_pattern, '', processed_text)
        
        # Google Scholar ë§í¬ê°€ ì—†ìœ¼ë©´ ì¶”ê°€
        if 'scholar.google.com' not in processed_text:
            # ì£¼ì œ ê¸°ë°˜ ê²€ìƒ‰ ë§í¬ ì¶”ê°€
            topic_keywords = '+'.join(topic.split()[:3])  # ì²˜ìŒ 3ë‹¨ì–´ë§Œ ì‚¬ìš©
            scholar_link = f"\n\n**ë” ë§ì€ ê´€ë ¨ ë…¼ë¬¸ ì°¾ê¸°:**\n[{topic} ê´€ë ¨ ë…¼ë¬¸ ê²€ìƒ‰](https://scholar.google.com/scholar?q={topic_keywords})"
            processed_text += scholar_link
        
        return processed_text
        
    except Exception as e:
        print(f"ì°¸ê³ ë¬¸í—Œ í›„ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
        return references_text

def parse_text_response(text):
    """JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ í…ìŠ¤íŠ¸ì—ì„œ ì„¹ì…˜ë³„ë¡œ ì¶”ì¶œ"""
    try:
        sections = {
            "abstract": "",
            "introduction": "",
            "methods": "",
            "results": "",
            "visuals": "",
            "conclusion": "",
            "references": ""
        }
        
        # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ë§¤ì¹­ìœ¼ë¡œ ì„¹ì…˜ ì¶”ì¶œ
        lines = text.split('\n')
        current_section = None
        
        for line in lines:
            line = line.strip()
            if not line:
                continue
                
            # ì„¹ì…˜ í—¤ë” ê°ì§€
            if any(keyword in line.lower() for keyword in ['ì´ˆë¡', 'abstract']):
                current_section = 'abstract'
            elif any(keyword in line.lower() for keyword in ['ì„œë¡ ', 'introduction', 'ë°°ê²½']):
                current_section = 'introduction'
            elif any(keyword in line.lower() for keyword in ['ë°©ë²•', 'method']):
                current_section = 'methods'
            elif any(keyword in line.lower() for keyword in ['ê²°ê³¼', 'result']):
                current_section = 'results'
            elif any(keyword in line.lower() for keyword in ['ì‹œê°', 'visual']):
                current_section = 'visuals'
            elif any(keyword in line.lower() for keyword in ['ê²°ë¡ ', 'conclusion']):
                current_section = 'conclusion'
            elif any(keyword in line.lower() for keyword in ['ì°¸ê³ ', 'reference']):
                current_section = 'references'
            elif current_section and not line.startswith('#'):
                # í˜„ì¬ ì„¹ì…˜ì— ë‚´ìš© ì¶”ê°€
                sections[current_section] += line + " "
        
        # ë¹ˆ ì„¹ì…˜ ì±„ìš°ê¸°
        for key, value in sections.items():
            if not value.strip():
                if key == 'references':
                    sections[key] = create_safe_references("ì¼ë°˜ì ì¸ ê³¼í•™ ì—°êµ¬")
                else:
                    sections[key] = f"{key.title()} ì„¹ì…˜ì´ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
        
        return sections
        
    except Exception as e:
        print(f"í…ìŠ¤íŠ¸ íŒŒì‹± ì˜¤ë¥˜: {e}")
        return create_error_response("ê³¼í•™ ì—°êµ¬")

def create_safe_references(topic):
    """ì•ˆì „í•œ ì°¸ê³ ë¬¸í—Œ ìƒì„± (Google Scholar ë§í¬ë§Œ ì‚¬ìš©)"""
    topic_keywords = '+'.join(topic.replace(' ', '+').split()[:3])
    return f"""**Scientific Research Methods** (2023) - Johnson, A. et al.
ê´€ë ¨ì„±: ê³¼í•™ ì—°êµ¬ ë°©ë²•ë¡ ì— ëŒ€í•œ ê¸°ì´ˆì ì¸ ì´í•´ë¥¼ ì œê³µí•˜ëŠ” ì—°êµ¬ì…ë‹ˆë‹¤.
[Google Scholarì—ì„œ ê²€ìƒ‰](https://scholar.google.com/scholar?q=scientific+research+methods)

**Data Analysis in Science** (2022) - Brown, M. et al.  
ê´€ë ¨ì„±: ê³¼í•™ ë°ì´í„° ë¶„ì„ ë°©ë²•ì— ëŒ€í•œ ì‹¤ìš©ì  ê°€ì´ë“œë¥¼ ì œê³µí•©ë‹ˆë‹¤.
[Google Scholarì—ì„œ ê²€ìƒ‰](https://scholar.google.com/scholar?q=data+analysis+science)

**{topic} ê´€ë ¨ ì¶”ê°€ ë…¼ë¬¸ ê²€ìƒ‰:**
[ë” ë§ì€ ê´€ë ¨ ë…¼ë¬¸ ì°¾ì•„ë³´ê¸°](https://scholar.google.com/scholar?q={topic_keywords})"""

def create_error_response(topic="ê³¼í•™ ì—°êµ¬"):
    """ì—ëŸ¬ ë°œìƒ ì‹œ ê¸°ë³¸ ì‘ë‹µ"""
    return {
        "abstract": "ë…¼ë¬¸ ì´ˆë¡ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì£¼ì œë¥¼ ë” êµ¬ì²´ì ìœ¼ë¡œ ì…ë ¥í•˜ê³  ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.",
        "introduction": "ì„œë¡  ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì—°êµ¬ ë°°ê²½ì„ ë‹¤ì‹œ ê²€í† í•´ì£¼ì„¸ìš”.",
        "methods": "ì—°êµ¬ ë°©ë²• ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.",
        "results": "ì˜ˆìƒ ê²°ê³¼ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë„¤íŠ¸ì›Œí¬ ìƒíƒœë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.",
        "visuals
