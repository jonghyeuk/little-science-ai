# utils/generate_paper.py
import streamlit as st
import anthropic
import json
import re

@st.cache_data(ttl=3600, show_spinner=False)
def generate_research_paper(topic, research_idea, references=""):
    """
    ì„ íƒëœ ì—°êµ¬ ì•„ì´ë””ì–´ì— ëŒ€í•œ ë…¼ë¬¸ í˜•ì‹ì˜ ì—°êµ¬ ê³„íšì„ ìƒì„±
    """
    try:
        client = anthropic.Anthropic(api_key=st.secrets["api"]["claude_key"])
        
        # ğŸ”¥ ë ˆí¼ëŸ°ìŠ¤ ìš”êµ¬ì‚¬í•­ ê°„ì†Œí™”
        system_prompt = """
        ê³ ë“±í•™ìƒ ì—°êµ¬ ê³„íšì„œë¥¼ JSON í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.

        ë°˜ë“œì‹œ ì´ JSON í˜•ì‹ë§Œ ì‚¬ìš©:
        {"abstract": "ì´ˆë¡ë‚´ìš©", "introduction": "ì„œë¡ ë‚´ìš©", "methods": "ë°©ë²•ë‚´ìš©", "results": "ê²°ê³¼ë‚´ìš©", "visuals": "ì‹œê°ìë£Œë‚´ìš©", "conclusion": "ê²°ë¡ ë‚´ìš©", "references": "ê²€ìƒ‰ê°€ì´ë“œ"}

        ê° ì„¹ì…˜ ìš”êµ¬ì‚¬í•­:
        - abstract: ì—°êµ¬ëª©ì ê³¼ ì˜ˆìƒê²°ê³¼ ìš”ì•½ (150-200ë‹¨ì–´) - í•™ìˆ ë…¼ë¬¸ í˜•ì‹
        - introduction: ë°°ê²½â†’ë¬¸ì œâ†’ëª©ì  ìˆœì„œ (250-300ë‹¨ì–´) - í•™ìˆ ë…¼ë¬¸ í˜•ì‹
        - methods: ì‹¤í—˜ë‹¨ê³„ë¥¼ ëª…í™•íˆ êµ¬ë¶„í•´ì„œ êµ¬ì²´ì ìœ¼ë¡œ ìƒì„¸í•˜ê²Œ ì‘ì„± (300-350ë‹¨ì–´)
        - results: ì˜ˆìƒë˜ëŠ” êµ¬ì²´ì  ê²°ê³¼ë“¤ (200-250ë‹¨ì–´)
        - visuals: í•„ìš”í•œ ê·¸ë˜í”„/ì°¨íŠ¸ ì„¤ëª… (150-200ë‹¨ì–´)
        - conclusion: ì‹¤í—˜ì„ í†µí•´ ì¦ëª…í•˜ë ¤ëŠ” ê³¼í•™ì  ê²°ë¡ ê³¼ í•™ìˆ ì  ì˜ì˜ (150-200ë‹¨ì–´)
        - references: "ì°¸ê³ ë¬¸í—Œì€ ìë™ìœ¼ë¡œ ê²€ìƒ‰ ê°€ì´ë“œê°€ ì œê³µë©ë‹ˆë‹¤" (ê°„ë‹¨íˆ í•œ ë¬¸ì¥ë§Œ)

        ì‹¤í—˜ë°©ë²• ì‘ì„±ë²•:
        1ë‹¨ê³„: [ì œëª©] - (ì¥ë¹„/ì¬ë£Œ í•„ìš”í•œ ì‚¬í•­ì„ ëª…ì‹œ)
        2ë‹¨ê³„: [ì œëª©] - "ë¨¼ì € ~ë¥¼ ì¤€ë¹„í•©ë‹ˆë‹¤. ë‹¤ìŒìœ¼ë¡œ ~ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤" í˜•íƒœë¡œ ì¹œì ˆí•˜ê²Œ êµ¬ì²´ì ìœ¼ë¡œ ì„œìˆ 
        3ë‹¨ê³„: [ì œëª©] - "ê·¸ í›„ì— ~ë¥¼ ì§„í–‰í•©ë‹ˆë‹¤. ì´ë•Œ ì£¼ì˜í•  ì ì€ ~ì…ë‹ˆë‹¤" í˜•íƒœë¡œ ì¹œì ˆí•˜ê²Œ êµ¬ì²´ì ìœ¼ë¡œ ì„œìˆ   
        4ë‹¨ê³„: [ì œëª©] - "ë§ˆì§€ë§‰ìœ¼ë¡œ ~ë¥¼ ì¸¡ì •í•©ë‹ˆë‹¤. ~ë¥¼ ê¸°ë¡í•©ë‹ˆë‹¤" í˜•íƒœë¡œ ì¹œì ˆí•˜ê²Œ êµ¬ì²´ì ìœ¼ë¡œ ì„œìˆ 
        """
        
        user_prompt = f"""
        ì£¼ì œ: {topic}
        ì•„ì´ë””ì–´: {research_idea}

        ìœ„ ë‚´ìš©ìœ¼ë¡œ í•™ìˆ  ì—°êµ¬ê³„íšì„œë¥¼ JSONìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.
        
        ì£¼ì˜ì‚¬í•­:
        - ì´ˆë¡ê³¼ ì„œë¡ : í•™ìˆ ë…¼ë¬¸ í˜•ì‹ìœ¼ë¡œ ì‘ì„±
        - ì‹¤í—˜ë°©ë²•: "ë¨¼ì € ~ë¥¼ í•©ë‹ˆë‹¤. ë‹¤ìŒìœ¼ë¡œ ~ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤" ì¹œì ˆí•œ êµ¬ì²´ì ì¸ ì„œìˆ í˜•
        - ì°¸ê³ ë¬¸í—Œ: ê°„ë‹¨í•œ í•œ ë¬¸ì¥ë§Œ ì‘ì„±
        """
        
        # Claude í˜¸ì¶œ
        response = client.messages.create(
            model="claude-3-5-sonnet-20241022",
            max_tokens=3500,  # ì°¸ê³ ë¬¸í—Œ ê³ ì •ìœ¼ë¡œ í† í° ì ˆì•½
            temperature=0.2,
            system=system_prompt,
            messages=[
                {"role": "user", "content": user_prompt}
            ]
        )
        
        response_text = response.content[0].text.strip()
        print(f"=== Claude ì‘ë‹µ ì›ë³¸ ===")
        print(response_text[:300] + "...")
        
        # JSON ì¶”ì¶œ
        paper_data = extract_json_robust(response_text)
        
        # JSON ì¶”ì¶œ
        if paper_data:
            paper_data = validate_and_fix_sections(paper_data, topic)
        
        return paper_data if paper_data else create_error_response(topic)
        
    except Exception as e:
        print(f"âŒ ì „ì²´ ë…¼ë¬¸ ìƒì„± ì˜¤ë¥˜: {e}")
        return create_error_response(topic)

def extract_json_robust(text):
    """ê°„ì†Œí™”ëœ JSON ì¶”ì¶œ"""
    try:
        # ë°©ë²• 1: ì§ì ‘ íŒŒì‹±
        try:
            return json.loads(text)
        except:
            pass
        
        # ë°©ë²• 2: ì½”ë“œë¸”ë¡ ì œê±°
        if "```json" in text:
            content = text.split("```json")[1].split("```")[0].strip()
        elif "```" in text:
            content = text.split("```")[1].strip()
        else:
            content = text
        
        try:
            return json.loads(content)
        except:
            pass
        
        # ë°©ë²• 3: ìˆ˜ë™ íŒŒì‹±
        return manual_parse_sections(text)
        
    except:
        return None

def manual_parse_sections(text):
    """ìˆ˜ë™ìœ¼ë¡œ ì„¹ì…˜ íŒŒì‹±"""
    try:
        sections = {
            "abstract": "",
            "introduction": "",
            "methods": "",
            "results": "",
            "visuals": "",
            "conclusion": "",
            "references": ""
        }
        
        keywords = {
            'abstract': ['ì´ˆë¡', 'abstract', 'ìš”ì•½'],
            'introduction': ['ì„œë¡ ', 'introduction', 'ë°°ê²½'],
            'methods': ['ë°©ë²•', 'method', 'ì‹¤í—˜'],
            'results': ['ê²°ê³¼', 'result', 'ì˜ˆìƒ'],
            'visuals': ['ì‹œê°', 'visual', 'ê·¸ë˜í”„'],
            'conclusion': ['ê²°ë¡ ', 'conclusion'],
            'references': ['ì°¸ê³ ', 'reference', 'ë¬¸í—Œ']
        }
        
        lines = text.split('\n')
        current_section = None
        
        for line in lines:
            line = line.strip()
            if not line:
                continue
            
            # ì„¹ì…˜ ê°ì§€
            found_section = None
            for section, kws in keywords.items():
                if any(kw in line.lower() for kw in kws):
                    found_section = section
                    break
            
            if found_section:
                current_section = found_section
            elif current_section and not line.startswith('"'):
                if sections[current_section]:
                    sections[current_section] += " " + line
                else:
                    sections[current_section] = line
        
        return sections
        
    except:
        return None

def validate_and_fix_sections(paper_data, topic):
    """ì„¹ì…˜ë³„ ê²€ì¦ ë° ìˆ˜ì •"""
    try:
        required_sections = ['abstract', 'introduction', 'methods', 'results', 'visuals', 'conclusion', 'references']
        
        for section in required_sections:
            if section == 'references':
                # referencesëŠ” ë¬´ì¡°ê±´ ê²€ìƒ‰ ê°€ì´ë“œë¡œ ëŒ€ì²´
                paper_data[section] = get_search_guide_template(topic)
            elif section not in paper_data or not paper_data[section] or len(paper_data[section].strip()) < 20:
                paper_data[section] = get_default_content(section, topic)
        
        return paper_data
        
    except:
        return paper_data

def get_search_guide_template(topic):
    """ğŸ”¥ ì¤„ë°”ê¿ˆ ì •ë ¬ëœ ê²€ìƒ‰ ê°€ì´ë“œ"""
    return f"""ğŸ“š ì¶”ê°€ ì—°êµ¬ë¥¼ ìœ„í•œ ê²€ìƒ‰ ê°€ì´ë“œ

ì•„ë˜ ë§í¬ì—ì„œ "{topic}" ê´€ë ¨ í‚¤ì›Œë“œë¥¼ ê²€ìƒ‰í•˜ì—¬ ê´€ë ¨ë…¼ë¬¸ë“¤ì„ ì½ì–´ë³´ì„¸ìš”:

**êµ­ë‚´ í•™ìˆ  ê²€ìƒ‰ ì‚¬ì´íŠ¸:**

ë„¤ì´ë²„ í•™ìˆ ì •ë³´: https://academic.naver.com/

RISS í•™ìˆ ì—°êµ¬ì •ë³´: https://www.riss.kr/

DBpia ë…¼ë¬¸ê²€ìƒ‰: https://www.dbpia.co.kr/

í•œêµ­ê³¼í•™ê¸°ìˆ ì •ë³´ì—°êµ¬ì›: https://www.ndsl.kr/

**í•´ì™¸ í•™ìˆ  ê²€ìƒ‰ ì‚¬ì´íŠ¸:**

êµ¬ê¸€ í•™ìˆ ê²€ìƒ‰: https://scholar.google.com/

IEEE Xplore: https://ieeexplore.ieee.org/

PubMed: https://pubmed.ncbi.nlm.nih.gov/

ğŸ’¡ **ê²€ìƒ‰ íŒ:** "{topic}"ì™€ í•¨ê»˜ "ì‹¤í—˜", "ë¶„ì„", "ì‘ìš©", "ìµœì‹  ì—°êµ¬" ë“±ì˜ í‚¤ì›Œë“œë¥¼ ì¡°í•©í•´ì„œ ê²€ìƒ‰í•´ë³´ì„¸ìš”."""

def get_default_content(section, topic):
    """ê¸°ë³¸ ë‚´ìš© ì œê³µ"""
    defaults = {
        'abstract': "ë³¸ ì—°êµ¬ëŠ” ì œì‹œëœ ì£¼ì œì— ëŒ€í•´ ì²´ê³„ì ì¸ ì‹¤í—˜ì„ í†µí•´ ê³¼í•™ì  ê·¼ê±°ë¥¼ í™•ë³´í•˜ê³ ì í•œë‹¤. ì‹¤í—˜ì„ í†µí•´ ì–»ì€ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ ì˜ë¯¸ìˆëŠ” ê²°ë¡ ì„ ë„ì¶œí•  ì˜ˆì •ì´ë‹¤. ì´ ì—°êµ¬ ê²°ê³¼ëŠ” ê´€ë ¨ ë¶„ì•¼ì˜ ì´í•´ë¥¼ ë„“íˆëŠ” ë° ê¸°ì—¬í•  ê²ƒìœ¼ë¡œ ê¸°ëŒ€ëœë‹¤.",
        'introduction': "í˜„ì¬ ê´€ë ¨ ë¶„ì•¼ì—ì„œëŠ” ë‹¤ì–‘í•œ ì—°êµ¬ê°€ ì§„í–‰ë˜ê³  ìˆì§€ë§Œ, ì—¬ì „íˆ í•´ê²°ë˜ì§€ ì•Šì€ ë¬¸ì œë“¤ì´ ì¡´ì¬í•œë‹¤. ê¸°ì¡´ ì—°êµ¬ë“¤ì˜ í•œê³„ì ì„ ë³´ì™„í•˜ê³  ìƒˆë¡œìš´ ê´€ì ì„ ì œì‹œí•˜ê¸° ìœ„í•´ ë³¸ ì—°êµ¬ë¥¼ ìˆ˜í–‰í•œë‹¤. ë³¸ ì—°êµ¬ì˜ ëª©ì ì€ ì‹¤í—˜ì  ì ‘ê·¼ì„ í†µí•´ ì´ë¡ ì  ê°€ì„¤ì„ ê²€ì¦í•˜ëŠ” ê²ƒì´ë‹¤.",
        'methods': "1ë‹¨ê³„: ì‹¤í—˜ ì¬ë£Œ ì¤€ë¹„\ní•„ìš”í•œ ì‹¤í—˜ ë„êµ¬ì™€ ì¬ë£Œë¥¼ ì¤€ë¹„í•©ë‹ˆë‹¤.\n\n2ë‹¨ê³„: ì‹¤í—˜ í™˜ê²½ ì„¤ì •\në¨¼ì € ì‹¤í—˜ì‹¤ì˜ ì¡°ëª…ì„ ì¡°ì ˆí•˜ì—¬ ì ì ˆí•œ í™˜ê²½ì„ ë§Œë“­ë‹ˆë‹¤. ë‹¤ìŒìœ¼ë¡œ ì‹¤í—˜ ì¥ë¹„ë¥¼ ì•ˆì •ì ì¸ ê³³ì— ë°°ì¹˜í•©ë‹ˆë‹¤.\n\n3ë‹¨ê³„: ë°ì´í„° ìˆ˜ì§‘ ì§„í–‰\nê·¸ í›„ì— ì‹¤í—˜ì„ ë‹¨ê³„ì ìœ¼ë¡œ ì§„í–‰í•˜ë©° ê° ë‹¨ê³„ë§ˆë‹¤ ê²°ê³¼ë¥¼ ê¸°ë¡í•©ë‹ˆë‹¤.\n\n4ë‹¨ê³„: ê²°ê³¼ ë¶„ì„ ë° ì •ë¦¬\në§ˆì§€ë§‰ìœ¼ë¡œ ìˆ˜ì§‘ëœ ë°ì´í„°ë¥¼ ì²´ê³„ì ìœ¼ë¡œ ë¶„ì„í•©ë‹ˆë‹¤. ê·¸ë˜í”„ë‚˜ í‘œë¡œ ì •ë¦¬í•˜ì—¬ íŒ¨í„´ì„ ì°¾ì•„ëƒ…ë‹ˆë‹¤.",
        'results': "ì‹¤í—˜ì„ í†µí•´ ë‹¤ìŒê³¼ ê°™ì€ ê²°ê³¼ë¥¼ ì–»ì„ ê²ƒìœ¼ë¡œ ì˜ˆìƒëœë‹¤: ì¸¡ì •ê°’ë“¤ ê°„ì˜ ìƒê´€ê´€ê³„, ê°€ì„¤ì˜ ê²€ì¦ ê²°ê³¼, ê·¸ë¦¬ê³  ì´ë¡ ì  ëª¨ë¸ê³¼ì˜ ì¼ì¹˜ì„± í‰ê°€ì´ë‹¤. ì´ëŸ¬í•œ ê²°ê³¼ëŠ” ê´€ë ¨ ë¶„ì•¼ì˜ ì´ë¡ ì  í† ëŒ€ë¥¼ ê°•í™”í•˜ëŠ” ë° ê¸°ì—¬í•  ê²ƒì´ë‹¤.",
        'visuals': "ì‹¤í—˜ ê²°ê³¼ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ í‘œí˜„í•˜ê¸° ìœ„í•´ ë‹¤ìŒê³¼ ê°™ì€ ì‹œê°ìë£Œë¥¼ ì œì‘í•  ì˜ˆì •ì…ë‹ˆë‹¤: ì‹¤í—˜ ê³¼ì •ì„ ë³´ì—¬ì£¼ëŠ” ì‚¬ì§„, ë°ì´í„° ë³€í™”ë¥¼ ë‚˜íƒ€ë‚´ëŠ” ê·¸ë˜í”„, ê²°ê³¼ë¥¼ ìš”ì•½í•œ í‘œ ë“±ì…ë‹ˆë‹¤.",
        'conclusion': "ë³¸ ì—°êµ¬ë¥¼ í†µí•´ ì œì‹œëœ ê°€ì„¤ì´ ì‹¤í—˜ì ìœ¼ë¡œ ê²€ì¦ë  ê²ƒìœ¼ë¡œ ì˜ˆìƒëœë‹¤. ì´ëŠ” ê´€ë ¨ ë¶„ì•¼ì˜ ì´ë¡ ì  ì´í•´ë¥¼ ê¹Šê²Œ í•˜ê³ , í›„ì† ì—°êµ¬ì˜ ë°©í–¥ì„±ì„ ì œì‹œí•˜ëŠ” ì¤‘ìš”í•œ ì˜ë¯¸ë¥¼ ê°–ëŠ”ë‹¤.",
        'references': get_search_guide_template(topic)
    }
    return defaults.get(section, f"{section} ì„¹ì…˜ ë‚´ìš©ì´ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

def create_error_response(topic):
    """ì—ëŸ¬ ë°œìƒ ì‹œ ê¸°ë³¸ ì‘ë‹µ"""
    return {
        "abstract": "ë…¼ë¬¸ ì´ˆë¡ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì£¼ì œë¥¼ ë” êµ¬ì²´ì ìœ¼ë¡œ ì…ë ¥í•˜ê³  ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.",
        "introduction": "ì„œë¡  ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì—°êµ¬ ë°°ê²½ì„ ë‹¤ì‹œ ê²€í† í•´ì£¼ì„¸ìš”.",
        "methods": "ì—°êµ¬ ë°©ë²• ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.",
        "results": "ì˜ˆìƒ ê²°ê³¼ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë„¤íŠ¸ì›Œí¬ ìƒíƒœë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.",
        "visuals": "ì‹œê°ìë£Œ ì œì•ˆ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
        "conclusion": "ê²°ë¡  ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
        "references": get_search_guide_template(topic)
    }
