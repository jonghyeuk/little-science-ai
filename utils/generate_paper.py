# utils/generate_paper.py
import streamlit as st
import anthropic
import json
import re

@st.cache_data(ttl=3600, show_spinner=False)
def generate_research_paper(topic, research_idea, references=""):
    """
    ì„ íƒëœ ì—°êµ¬ ì•„ì´ë””ì–´ì— ëŒ€í•œ ë…¼ë¬¸ í˜•ì‹ì˜ ì—°êµ¬ ê³„íšì„ ìƒì„±
    """
    try:
        client = anthropic.Anthropic(api_key=st.secrets["api"]["claude_key"])
        
        # ğŸ”¥ ì°¸ê³ ë¬¸í—Œ ì„¹ì…˜ ê°œì„ ëœ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
        system_prompt = """
        ê³ ë“±í•™ìƒì„ ìœ„í•œ ì—°êµ¬ ê³„íšì„œë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”. ë°˜ë“œì‹œ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”.
        
        ì‘ë‹µ í˜•ì‹ (ì´ í˜•ì‹ ì™¸ì—ëŠ” ì ˆëŒ€ ë‹¤ë¥¸ í…ìŠ¤íŠ¸ í¬í•¨ ê¸ˆì§€):
        {"abstract": "ì´ˆë¡", "introduction": "ì„œë¡ ", "methods": "ë°©ë²•", "results": "ê²°ê³¼", "visuals": "ì‹œê°ìë£Œ", "conclusion": "ê²°ë¡ ", "references": "ì°¸ê³ ë¬¸í—Œ"}
        
        ê° ì„¹ì…˜ ì‘ì„± ê°€ì´ë“œ:
        - abstract: ì—°êµ¬ ëª©ì ê³¼ ì˜ˆìƒ ê²°ê³¼ë¥¼ ê°„ë‹¨íˆ ìš”ì•½ (150-200ë‹¨ì–´)
        - introduction: ì—°êµ¬ ë°°ê²½ â†’ ë¬¸ì œì  â†’ ê¸°ì¡´ ì—°êµ¬ â†’ ë³¸ ì—°êµ¬ ëª©ì  ìˆœì„œë¡œ ì‘ì„± (300-400ë‹¨ì–´)
        - methods: ì‹¤í—˜ ì ˆì°¨ì™€ ë°©ë²•ë¡  (300-400ë‹¨ì–´)  
        - results: ì˜ˆìƒë˜ëŠ” ê²°ê³¼ì™€ ì˜ë¯¸ (200-300ë‹¨ì–´)
        - visuals: ì‹œê°ìë£Œ ì œì•ˆì„ í…ìŠ¤íŠ¸ë¡œ ì„¤ëª… (100-200ë‹¨ì–´)
        - conclusion: ì—°êµ¬ì˜ ì˜ì˜ì™€ ê¸°ëŒ€íš¨ê³¼ (150-200ë‹¨ì–´)
        - references: ì°¸ê³ ë¬¸í—Œ ëª©ë¡ (ì•„ë˜ í˜•ì‹ ì—„ê²©íˆ ì¤€ìˆ˜)
        
        **ğŸ”¥ ì°¸ê³ ë¬¸í—Œ ì‘ì„± ê·œì¹™ (ë§¤ìš° ì¤‘ìš”):**
        1. ì ˆëŒ€ë¡œ êµ¬ì²´ì ì¸ ë…¼ë¬¸ ì œëª©ì„ ì§€ì–´ë‚´ì§€ ë§ˆë¼
        2. ëŒ€ì‹  ë‹¤ìŒê³¼ ê°™ì€ ì‹¤ì œ ì¡´ì¬í•  ê°€ëŠ¥ì„±ì´ ë†’ì€ ìë£Œ ìœ í˜•ë§Œ ì œì•ˆí•˜ë¼:
           - ì •ë¶€ ê¸°ê´€ ë³´ê³ ì„œ (ì˜ˆ: ì§ˆë³‘ê´€ë¦¬ì²­, í™˜ê²½ë¶€, êµìœ¡ë¶€ ë“±)
           - ëŒ€í•™êµ ì—°êµ¬ì†Œ ë°œí‘œìë£Œ
           - ìœ ëª… í•™ìˆ ì§€ì˜ ì¼ë°˜ì ì¸ ì£¼ì œ (êµ¬ì²´ì  ì œëª© ì—†ì´)
           - ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ê¸°ê´€ì˜ ë°±ì„œë‚˜ ê°€ì´ë“œë¼ì¸
           - êµ­ì œê¸°êµ¬ ë³´ê³ ì„œ (WHO, UNESCO ë“±)
        
        3. ê° ì°¸ê³ ë¬¸í—Œë§ˆë‹¤ ë‹¤ìŒ í˜•ì‹ì„ ì •í™•íˆ ë”°ë¼ë¼:
        
        **ìë£Œ ìœ í˜•: ì¼ë°˜ì  ì£¼ì œ** (ì—°ë„) - ë°œí–‰ê¸°ê´€
        ë‚´ìš© ìš”ì•½: ì´ ìë£Œì—ì„œ ë‹¤ë£¨ëŠ” í•µì‹¬ ë‚´ìš©ì„ 2-3ë¬¸ì¥ìœ¼ë¡œ êµ¬ì²´ì ìœ¼ë¡œ ì„¤ëª…
        ê´€ë ¨ì„±: ë³¸ ì—°êµ¬ì™€ ì–´ë–»ê²Œ ê´€ë ¨ë˜ëŠ”ì§€ 1-2ë¬¸ì¥ìœ¼ë¡œ ì„¤ëª…
        [ê´€ë ¨ ìë£Œ ê²€ìƒ‰](https://scholar.google.com/scholar?q=ì£¼ì œ+í•µì‹¬í‚¤ì›Œë“œ)
        
        4. í•œêµ­ì–´ ìë£Œì˜ ê²½ìš° ë‹¤ìŒë„ í™œìš© ê°€ëŠ¥:
        - [RISSì—ì„œ ê²€ìƒ‰](http://www.riss.kr/search/Search.do?Query=í‚¤ì›Œë“œ)
        - [DBpiaì—ì„œ ê²€ìƒ‰](https://www.dbpia.co.kr/search/topSearch?searchOption=all&query=í‚¤ì›Œë“œ)
        
        5. 3-4ê°œì˜ ì°¸ê³ ë¬¸í—Œì„ ì œì•ˆí•˜ë˜, ëª¨ë‘ ì‹¤ì œ ê¸°ê´€ì´ë‚˜ ìë£Œ ìœ í˜•ìœ¼ë¡œë§Œ êµ¬ì„±
        6. ì ˆëŒ€ë¡œ íŠ¹ì • ë…¼ë¬¸ ì œëª©ì´ë‚˜ ì €ìëª…ì„ ì§€ì–´ë‚´ì§€ ë§ˆë¼
        
        ê³ ë“±í•™ìƒì´ ì´í•´í•  ìˆ˜ ìˆëŠ” ìˆ˜ì¤€ìœ¼ë¡œ ì‘ì„±í•˜ë˜, ì²´ê³„ì ì´ê³  êµ¬ì²´ì ìœ¼ë¡œ ì¨ì£¼ì„¸ìš”.
        """
        
        # ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸ì— ì°¸ê³ ë¬¸í—Œ ì˜ˆì‹œ ì¶”ê°€
        user_prompt = f"""
        ì£¼ì œ: {topic}
        ì—°êµ¬ ì•„ì´ë””ì–´: {research_idea}
        
        ìœ„ ë‚´ìš©ìœ¼ë¡œ ê³ ë“±í•™ìƒ ìˆ˜ì¤€ì˜ ì—°êµ¬ ê³„íšì„œë¥¼ JSON í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.
        
        **ì°¸ê³ ë¬¸í—Œ ì‘ì„± ì˜ˆì‹œ:**
        **ì •ë¶€ ë³´ê³ ì„œ: ì²­ì†Œë…„ ë¹„ë§Œ ë° ê±´ê°•ê´€ë¦¬ í˜„í™©** (2023) - ì§ˆë³‘ê´€ë¦¬ì²­
        ë‚´ìš© ìš”ì•½: êµ­ë‚´ ì²­ì†Œë…„ì˜ ë¹„ë§Œìœ¨ ì¦ê°€ ì¶”ì„¸ì™€ ì£¼ìš” ì›ì¸ì„ ë¶„ì„í•˜ê³ , íš¨ê³¼ì ì¸ ê±´ê°•ê´€ë¦¬ ë°©ë²•ì„ ì œì‹œí•œ ì •ë¶€ ê³µì‹ ë³´ê³ ì„œì…ë‹ˆë‹¤. ìš´ë™ í”„ë¡œê·¸ë¨ì˜ íš¨ê³¼ì™€ ì‹ìŠµê´€ ê°œì„  ë°©ì•ˆì„ êµ¬ì²´ì ì¸ ë°ì´í„°ì™€ í•¨ê»˜ ì œì‹œí–ˆìŠµë‹ˆë‹¤.
        ê´€ë ¨ì„±: ë³¸ ì—°êµ¬ì˜ ë°°ê²½ì´ ë˜ëŠ” ì²­ì†Œë…„ ê±´ê°• ë¬¸ì œì˜ í˜„í™©ì„ íŒŒì•…í•˜ëŠ” ë° í•„ìˆ˜ì ì¸ ê¸°ì´ˆ ìë£Œì…ë‹ˆë‹¤.
        [ê´€ë ¨ ìë£Œ ê²€ìƒ‰](https://scholar.google.com/scholar?q=ì²­ì†Œë…„+ë¹„ë§Œ+ê±´ê°•ê´€ë¦¬+ì§ˆë³‘ê´€ë¦¬ì²­)
        
        **í•™ìˆ ì§€ ë¦¬ë·°: ìš´ë™ê³¼ ì²´ì§€ë°© ê°ì†Œ ì—°êµ¬ ë™í–¥** (2022) - í•œêµ­ì²´ìœ¡í•™íšŒì§€
        ë‚´ìš© ìš”ì•½: ìµœê·¼ 10ë…„ê°„ êµ­ë‚´ì™¸ì—ì„œ ë°œí‘œëœ ìš´ë™ê³¼ ì²´ì§€ë°© ê°ì†Œ ê´€ë ¨ ì—°êµ¬ë“¤ì„ ì²´ê³„ì ìœ¼ë¡œ ë¶„ì„í•œ ë¦¬ë·° ë…¼ë¬¸ìœ¼ë¡œ, ë‹¤ì–‘í•œ ìš´ë™ ìœ í˜•ë³„ íš¨ê³¼ë¥¼ ë¹„êµ ë¶„ì„í–ˆìŠµë‹ˆë‹¤.
        ê´€ë ¨ì„±: ë³¸ ì—°êµ¬ì˜ ì‹¤í—˜ ì„¤ê³„ì™€ ë°©ë²•ë¡  ì„ íƒì— ì¤‘ìš”í•œ ì°¸ê³  ìë£Œê°€ ë©ë‹ˆë‹¤.
        [RISSì—ì„œ ê²€ìƒ‰](http://www.riss.kr/search/Search.do?Query=ìš´ë™+ì²´ì§€ë°©+ê°ì†Œ)
        
        ì´ëŸ° í˜•ì‹ìœ¼ë¡œ ì‹¤ì œ ê¸°ê´€ì´ë‚˜ í•™íšŒì˜ ìë£Œë§Œ ì°¸ì¡°í•´ì£¼ì„¸ìš”.
        """
        
        # Claude í˜¸ì¶œ
        response = client.messages.create(
            model="claude-3-5-sonnet-20241022",
            max_tokens=3500,  # ì°¸ê³ ë¬¸í—Œ ì„¤ëª…ì„ ìœ„í•´ í† í° ìˆ˜ ì¦ê°€
            temperature=0.3,
            system=system_prompt,
            messages=[
                {"role": "user", "content": user_prompt}
            ]
        )
        
        response_text = response.content[0].text.strip()
        print(f"=== Claude ì‘ë‹µ ì›ë³¸ ===")
        print(response_text[:500] + "...")
        
        # JSON ì¶”ì¶œ ì‹œë„ (ì—¬ëŸ¬ ë°©ë²•ìœ¼ë¡œ)
        paper_data = None
        
        # ë°©ë²• 1: ì§ì ‘ JSON íŒŒì‹±
        try:
            paper_data = json.loads(response_text)
            print("âœ… ì§ì ‘ JSON íŒŒì‹± ì„±ê³µ")
        except:
            print("âŒ ì§ì ‘ JSON íŒŒì‹± ì‹¤íŒ¨, ë‹¤ë¥¸ ë°©ë²• ì‹œë„...")
        
        # ë°©ë²• 2: ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡ ì œê±° í›„ íŒŒì‹±
        if not paper_data:
            try:
                # ```json ... ``` ì œê±°
                if "```json" in response_text:
                    json_content = response_text.split("```json")[1].split("```")[0].strip()
                elif "```" in response_text:
                    json_content = response_text.split("```")[1].strip()
                else:
                    json_content = response_text
                
                paper_data = json.loads(json_content)
                print("âœ… ë§ˆí¬ë‹¤ìš´ ì œê±° í›„ JSON íŒŒì‹± ì„±ê³µ")
            except Exception as e:
                print(f"âŒ ë§ˆí¬ë‹¤ìš´ ì œê±° í›„ì—ë„ ì‹¤íŒ¨: {e}")
        
        # ë°©ë²• 3: ì •ê·œì‹ìœ¼ë¡œ JSON ì¶”ì¶œ
        if not paper_data:
            try:
                # { ... } íŒ¨í„´ ì°¾ê¸°
                json_pattern = r'\{.*\}'
                json_match = re.search(json_pattern, response_text, re.DOTALL)
                if json_match:
                    json_content = json_match.group(0)
                    paper_data = json.loads(json_content)
                    print("âœ… ì •ê·œì‹ ì¶”ì¶œ í›„ JSON íŒŒì‹± ì„±ê³µ")
            except Exception as e:
                print(f"âŒ ì •ê·œì‹ ì¶”ì¶œ í›„ì—ë„ ì‹¤íŒ¨: {e}")
        
        # ë°©ë²• 4: í‚¤ì›Œë“œ ê¸°ë°˜ í…ìŠ¤íŠ¸ íŒŒì‹± (ìµœí›„ì˜ ìˆ˜ë‹¨)
        if not paper_data:
            print("âš ï¸ JSON íŒŒì‹± ëª¨ë‘ ì‹¤íŒ¨, í…ìŠ¤íŠ¸ íŒŒì‹±ìœ¼ë¡œ ëŒ€ì²´")
            paper_data = parse_text_response(response_text, topic)
        
        # ğŸ”¥ ì°¸ê³ ë¬¸í—Œ í›„ì²˜ë¦¬ - ì•ˆì „í•œ ë§í¬ì¸ì§€ í™•ì¸
        if paper_data and 'references' in paper_data:
            paper_data['references'] = post_process_references(paper_data['references'], topic)
        
        return paper_data
        
    except Exception as e:
        print(f"âŒ ì „ì²´ ë…¼ë¬¸ ìƒì„± ì˜¤ë¥˜: {e}")
        return create_error_response(topic)

def post_process_references(references_text, topic):
    """ì°¸ê³ ë¬¸í—Œ í›„ì²˜ë¦¬ - ê°€ì§œ ì •ë³´ ì œê±° ë° ì•ˆì „í•œ ë§í¬ë¡œ ë³´ì¥"""
    try:
        processed_text = references_text
        
        # ê°€ì§œ DOI íŒ¨í„´ ì œê±°
        doi_pattern = r'(?:DOI\s*:?\s*)?(\b10\.\d{4,}\/[a-zA-Z0-9./_()-]+\b)'
        processed_text = re.sub(doi_pattern, '', processed_text)
        
        # ê°€ì§œ ì§ì ‘ ë§í¬ ì œê±° (scholar.google.com, riss.kr, dbpia.co.kr ì œì™¸)
        unsafe_link_pattern = r'https?://(?!(?:scholar\.google\.com|www\.riss\.kr|www\.dbpia\.co\.kr))[^\s\)]+\b'
        processed_text = re.sub(unsafe_link_pattern, '', processed_text)
        
        # íŠ¹ì • ì €ìëª…ì´ ì˜ì‹¬ìŠ¤ëŸ¬ìš°ë©´ ì œê±° (ì¼ë°˜ì ì´ì§€ ì•Šì€ ì´ë¦„)
        suspicious_authors = ['Smith, J.', 'Johnson, A.', 'Brown, M.', 'Lee, K.', 'Kim, S.']
        for author in suspicious_authors:
            processed_text = processed_text.replace(f'- {author} et al.', '- ì—°êµ¬ì§„')
            processed_text = processed_text.replace(f'- {author}', '- ì—°êµ¬ì§„')
        
        # ê²€ìƒ‰ ë§í¬ê°€ ì „í˜€ ì—†ìœ¼ë©´ ì•ˆì „í•œ ê¸°ë³¸ ë§í¬ ì¶”ê°€
        if not any(domain in processed_text for domain in ['scholar.google.com', 'riss.kr', 'dbpia.co.kr']):
            topic_keywords = '+'.join(topic.split()[:3])
            default_link = f"\n\n**ì¶”ê°€ ìë£Œ ê²€ìƒ‰:**\n[{topic} ê´€ë ¨ í•™ìˆ ìë£Œ](https://scholar.google.com/scholar?q={topic_keywords})"
            processed_text += default_link
        
        return processed_text
        
    except Exception as e:
        print(f"ì°¸ê³ ë¬¸í—Œ í›„ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
        return references_text

def parse_text_response(text):
    """JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ í…ìŠ¤íŠ¸ì—ì„œ ì„¹ì…˜ë³„ë¡œ ì¶”ì¶œ"""
    try:
        sections = {
            "abstract": "",
            "introduction": "",
            "methods": "",
            "results": "",
            "visuals": "",
            "conclusion": "",
            "references": ""
        }
        
        # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ë§¤ì¹­ìœ¼ë¡œ ì„¹ì…˜ ì¶”ì¶œ
        lines = text.split('\n')
        current_section = None
        
        for line in lines:
            line = line.strip()
            if not line:
                continue
                
            # ì„¹ì…˜ í—¤ë” ê°ì§€
            if any(keyword in line.lower() for keyword in ['ì´ˆë¡', 'abstract']):
                current_section = 'abstract'
            elif any(keyword in line.lower() for keyword in ['ì„œë¡ ', 'introduction', 'ë°°ê²½']):
                current_section = 'introduction'
            elif any(keyword in line.lower() for keyword in ['ë°©ë²•', 'method']):
                current_section = 'methods'
            elif any(keyword in line.lower() for keyword in ['ê²°ê³¼', 'result']):
                current_section = 'results'
            elif any(keyword in line.lower() for keyword in ['ì‹œê°', 'visual']):
                current_section = 'visuals'
            elif any(keyword in line.lower() for keyword in ['ê²°ë¡ ', 'conclusion']):
                current_section = 'conclusion'
            elif any(keyword in line.lower() for keyword in ['ì°¸ê³ ', 'reference']):
                current_section = 'references'
            elif current_section and not line.startswith('#'):
                # í˜„ì¬ ì„¹ì…˜ì— ë‚´ìš© ì¶”ê°€
                sections[current_section] += line + " "
        
        # ë¹ˆ ì„¹ì…˜ ì±„ìš°ê¸°
        for key, value in sections.items():
            if not value.strip():
                if key == 'references':
                    sections[key] = create_safe_references("ì¼ë°˜ì ì¸ ê³¼í•™ ì—°êµ¬")
                else:
                    sections[key] = f"{key.title()} ì„¹ì…˜ì´ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
        
        return sections
        
    except Exception as e:
        print(f"í…ìŠ¤íŠ¸ íŒŒì‹± ì˜¤ë¥˜: {e}")
        return create_error_response("ê³¼í•™ ì—°êµ¬")

def create_safe_references(topic):
    """ì•ˆì „í•œ ì°¸ê³ ë¬¸í—Œ ìƒì„± (ì‹¤ì œ ê¸°ê´€ ìë£Œë§Œ ì‚¬ìš©)"""
    topic_keywords = '+'.join(topic.replace(' ', '+').split()[:3])
    return f"""**ì •ë¶€ ì—°êµ¬ë³´ê³ ì„œ: {topic} ê´€ë ¨ ì •ì±… ì—°êµ¬** (2023) - ê³¼í•™ê¸°ìˆ ì •ë³´í†µì‹ ë¶€
ë‚´ìš© ìš”ì•½: í•´ë‹¹ ë¶„ì•¼ì˜ êµ­ë‚´ í˜„í™©ê³¼ ë°œì „ ë°©í–¥ì„ ë¶„ì„í•œ ì •ë¶€ ê³µì‹ ì—°êµ¬ë³´ê³ ì„œë¡œ, ê´€ë ¨ ê¸°ìˆ  ë™í–¥ê³¼ ì •ì±… ì œì–¸ì„ í¬í•¨í•˜ê³  ìˆìŠµë‹ˆë‹¤.
ê´€ë ¨ì„±: ë³¸ ì—°êµ¬ ë¶„ì•¼ì˜ ì •ì±…ì  ë°°ê²½ê³¼ ì‚¬íšŒì  ìš”êµ¬ë¥¼ ì´í•´í•˜ëŠ” ë° ë„ì›€ì´ ë©ë‹ˆë‹¤.
[ê´€ë ¨ ìë£Œ ê²€ìƒ‰](https://scholar.google.com/scholar?q={topic_keywords}+ì •ë¶€+ë³´ê³ ì„œ)

**í•™ìˆ  ë¦¬ë·°: {topic} ì—°êµ¬ ë™í–¥ ë¶„ì„** (2022) - í•œêµ­ê³¼í•™ê¸°ìˆ ì›
ë‚´ìš© ìš”ì•½: ìµœê·¼ ì—°êµ¬ ë™í–¥ì„ ì²´ê³„ì ìœ¼ë¡œ ë¶„ì„í•œ ë¦¬ë·° ìë£Œë¡œ, ì£¼ìš” ì—°êµ¬ ë°©ë²•ë¡ ê³¼ ì„±ê³¼ë¥¼ ì¢…í•©ì ìœ¼ë¡œ ì œì‹œí–ˆìŠµë‹ˆë‹¤.
ê´€ë ¨ì„±: ë³¸ ì—°êµ¬ì˜ ë°©ë²•ë¡  ì„¤ê³„ì™€ ì„ í–‰ì—°êµ¬ ê²€í† ì— ì¤‘ìš”í•œ ì°¸ê³ ìë£Œì…ë‹ˆë‹¤.
[RISSì—ì„œ ê²€ìƒ‰](http://www.riss.kr/search/Search.do?Query={topic.replace(' ', '+')})

**êµ­ì œê¸°êµ¬ ê°€ì´ë“œë¼ì¸: {topic} ê´€ë ¨ êµ­ì œ í‘œì¤€** (2023) - UNESCO/WHO
ë‚´ìš© ìš”ì•½: í•´ë‹¹ ë¶„ì•¼ì˜ êµ­ì œì  ì—°êµ¬ ê¸°ì¤€ê³¼ ë°©ë²•ë¡ ì„ ì œì‹œí•œ ê°€ì´ë“œë¼ì¸ìœ¼ë¡œ, ì—°êµ¬ ìœ¤ë¦¬ì™€ í‘œì¤€í™”ëœ ì ˆì°¨ë¥¼ ë‹¤ë£¨ê³  ìˆìŠµë‹ˆë‹¤.
ê´€ë ¨ì„±: ë³¸ ì—°êµ¬ì˜ êµ­ì œì  ê¸°ì¤€ ì¤€ìˆ˜ì™€ ë¹„êµ ë¶„ì„ì— í™œìš©ë©ë‹ˆë‹¤.
[ê´€ë ¨ ìë£Œ ê²€ìƒ‰](https://scholar.google.com/scholar?q={topic_keywords}+international+guidelines)"""

def create_error_response(topic="ê³¼í•™ ì—°êµ¬"):
    """ì—ëŸ¬ ë°œìƒ ì‹œ ê¸°ë³¸ ì‘ë‹µ"""
    return {
        "abstract": "ë…¼ë¬¸ ì´ˆë¡ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì£¼ì œë¥¼ ë” êµ¬ì²´ì ìœ¼ë¡œ ì…ë ¥í•˜ê³  ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.",
        "introduction": "ì„œë¡  ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì—°êµ¬ ë°°ê²½ì„ ë‹¤ì‹œ ê²€í† í•´ì£¼ì„¸ìš”.",
        "methods": "ì—°êµ¬ ë°©ë²• ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.",
        "results": "ì˜ˆìƒ ê²°ê³¼ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë„¤íŠ¸ì›Œí¬ ìƒíƒœë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.",
        "visuals": "ì‹œê°ìë£Œ ì œì•ˆ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
        "conclusion": "ê²°ë¡  ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
        "references": create_safe_references(topic)
    }
