# utils/generate_paper.py
import streamlit as st
import anthropic
import json
import re

@st.cache_data(ttl=3600, show_spinner=False)
def generate_research_paper(topic, research_idea, references=""):
    """
    ì„ íƒëœ ì—°êµ¬ ì•„ì´ë””ì–´ì— ëŒ€í•œ ë…¼ë¬¸ í˜•ì‹ì˜ ì—°êµ¬ ê³„íšì„ ìƒì„±
    """
    try:
        client = anthropic.Anthropic(api_key=st.secrets["api"]["claude_key"])
        
        # ğŸ”¥ ê°„ë‹¨í•˜ê³  ëª…í™•í•œ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ë¡œ ìˆ˜ì •
        system_prompt = """
        ê³ ë“±í•™ìƒ ì—°êµ¬ ê³„íšì„œë¥¼ JSON í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.

        ë°˜ë“œì‹œ ì´ JSON í˜•ì‹ë§Œ ì‚¬ìš©:
        {"abstract": "ì´ˆë¡ë‚´ìš©", "introduction": "ì„œë¡ ë‚´ìš©", "methods": "ë°©ë²•ë‚´ìš©", "results": "ê²°ê³¼ë‚´ìš©", "visuals": "ì‹œê°ìë£Œë‚´ìš©", "conclusion": "ê²°ë¡ ë‚´ìš©", "references": "ì°¸ê³ ë¬¸í—Œë‚´ìš©"}

        ê° ì„¹ì…˜ ìš”êµ¬ì‚¬í•­:
        - abstract: ì—°êµ¬ëª©ì ê³¼ ì˜ˆìƒê²°ê³¼ ìš”ì•½ (100-150ë‹¨ì–´) - í•™ìˆ ë…¼ë¬¸ í˜•ì‹, êµìœ¡ ëŒ€ìƒ ì–¸ê¸‰ ê¸ˆì§€
        - introduction: ë°°ê²½â†’ë¬¸ì œâ†’ëª©ì  ìˆœì„œ (200-250ë‹¨ì–´) - í•™ìˆ ë…¼ë¬¸ í˜•ì‹, êµìœ¡ ëŒ€ìƒ ì–¸ê¸‰ ê¸ˆì§€
        - methods: ì‹¤í—˜ë‹¨ê³„ë¥¼ ëª…í™•íˆ êµ¬ë¶„í•´ì„œ ì‘ì„± (250-300ë‹¨ì–´)
        - results: ì˜ˆìƒë˜ëŠ” êµ¬ì²´ì  ê²°ê³¼ë“¤ (150-200ë‹¨ì–´)
        - visuals: í•„ìš”í•œ ê·¸ë˜í”„/ì°¨íŠ¸ ì„¤ëª… (100-150ë‹¨ì–´)
        - conclusion: ì‹¤í—˜ì„ í†µí•´ ì¦ëª…í•˜ë ¤ëŠ” ê³¼í•™ì  ê²°ë¡ ê³¼ í•™ìˆ ì  ì˜ì˜ (100-150ë‹¨ì–´)
        - references: ì‹¤ì œ í™•ì¸ê°€ëŠ¥í•œ ìë£Œ 3-4ê°œ (ë°˜ë“œì‹œ ì‹¤ì œ ë§í¬ í¬í•¨)

        ì‹¤í—˜ë°©ë²• ì‘ì„±ë²•:
        1ë‹¨ê³„: [ì œëª©] - (ì¥ë¹„/ì¬ë£Œ ê°„ë‹¨íˆ)
        2ë‹¨ê³„: [ì œëª©] - "ë¨¼ì € ~ë¥¼ ì¤€ë¹„í•©ë‹ˆë‹¤. ë‹¤ìŒìœ¼ë¡œ ~ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤" í˜•íƒœë¡œ ì¹œì ˆí•˜ê²Œ ì„œìˆ 
        3ë‹¨ê³„: [ì œëª©] - "ê·¸ í›„ì— ~ë¥¼ ì§„í–‰í•©ë‹ˆë‹¤. ì´ë•Œ ì£¼ì˜í•  ì ì€ ~ì…ë‹ˆë‹¤" í˜•íƒœë¡œ ì¹œì ˆí•˜ê²Œ ì„œìˆ   
        4ë‹¨ê³„: [ì œëª©] - "ë§ˆì§€ë§‰ìœ¼ë¡œ ~ë¥¼ ì¸¡ì •í•©ë‹ˆë‹¤. ~ë¥¼ ê¸°ë¡í•©ë‹ˆë‹¤" í˜•íƒœë¡œ ì¹œì ˆí•˜ê²Œ ì„œìˆ 
        (ê° ë‹¨ê³„ë§ˆë‹¤ ê³ ë“±í•™ìƒì´ ë”°ë¼í•  ìˆ˜ ìˆë„ë¡ êµ¬ì²´ì ì´ê³  ì¹œì ˆí•œ ì„œìˆ í˜•ìœ¼ë¡œ)

        ì°¸ê³ ë¬¸í—Œ ì‘ì„±ë²•:
        1. ìë£Œì œëª©
        - ë‚´ìš©: í•µì‹¬ë‚´ìš© 2ë¬¸ì¥ ì„¤ëª…  
        - ë§í¬: ë‹¤ìŒ ì¤‘ í•˜ë‚˜ë§Œ ì‚¬ìš©
          * https://ieeexplore.ieee.org (ê³µí•™/ì „ì ê´€ë ¨)
          * https://www.nature.com/subjects (ìì—°ê³¼í•™ ê´€ë ¨)  
          * https://www.nist.gov (ì¸¡ì •/í‘œì¤€ ê´€ë ¨)
          * https://energy.mit.edu (ì—ë„ˆì§€ ê´€ë ¨)
          * https://www.nsf.gov/discoveries (ì¼ë°˜ ê³¼í•™)
        - í™œìš©: ì—°êµ¬ì— ì–´ë–»ê²Œ ë„ì›€ë˜ëŠ”ì§€
        
        ì¤‘ìš”: Google Scholar ê²€ìƒ‰ ë§í¬ ì ˆëŒ€ ì‚¬ìš© ê¸ˆì§€! ìœ„ ì‹¤ì œ ê¸°ê´€ ì‚¬ì´íŠ¸ë§Œ ì‚¬ìš©í•˜ì„¸ìš”.
        """
        
        # ğŸ”¥ ê°„ë‹¨í•œ ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸
        user_prompt = f"""
        ì£¼ì œ: {topic}
        ì•„ì´ë””ì–´: {research_idea}

        ìœ„ ë‚´ìš©ìœ¼ë¡œ í•™ìˆ  ì—°êµ¬ê³„íšì„œë¥¼ JSONìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.
        
        ì£¼ì˜ì‚¬í•­:
        - ì´ˆë¡ê³¼ ì„œë¡ : í•™ìˆ ë…¼ë¬¸ í˜•ì‹ìœ¼ë¡œ, "ê³ ë“±í•™ìƒ" ë“± êµìœ¡ ëŒ€ìƒ ì–¸ê¸‰ ê¸ˆì§€
        - ê²°ë¡ : ì‹¤í—˜ì„ í†µí•´ ì¦ëª…í•˜ë ¤ëŠ” ê³¼í•™ì  ê²°ë¡ ê³¼ í•™ìˆ ì  ì˜ì˜ ì¤‘ì‹¬
        - ì‹¤í—˜ë°©ë²•: "ë¨¼ì € ~ë¥¼ í•©ë‹ˆë‹¤. ë‹¤ìŒìœ¼ë¡œ ~ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤" ì¹œì ˆí•œ ì„œìˆ í˜•
        - ì°¸ê³ ë¬¸í—Œ: ë°˜ë“œì‹œ ì‹¤ì œ í´ë¦­ ê°€ëŠ¥í•œ ë§í¬ í¬í•¨
        """
        
        # Claude í˜¸ì¶œ
        response = client.messages.create(
            model="claude-3-5-sonnet-20241022",
            max_tokens=2500,  # í† í° ì¤„ì—¬ì„œ ë” ì§‘ì¤‘ëœ ì‘ë‹µ
            temperature=0.2,  # ë” ì¼ê´€ëœ ì‘ë‹µ
            system=system_prompt,
            messages=[
                {"role": "user", "content": user_prompt}
            ]
        )
        
        response_text = response.content[0].text.strip()
        print(f"=== Claude ì‘ë‹µ ì›ë³¸ ===")
        print(response_text[:300] + "...")
        
        # ğŸ”¥ ë” ê°•ë ¥í•œ JSON ì¶”ì¶œ
        paper_data = extract_json_robust(response_text)
        
        # ğŸ”¥ ì„¹ì…˜ë³„ ê²€ì¦ ë° ìˆ˜ì •
        if paper_data:
            paper_data = validate_and_fix_sections(paper_data)
        
        return paper_data if paper_data else create_error_response()
        
    except Exception as e:
        print(f"âŒ ì „ì²´ ë…¼ë¬¸ ìƒì„± ì˜¤ë¥˜: {e}")
        return create_error_response()

def extract_json_robust(text):
    """ë” ê°•ë ¥í•œ JSON ì¶”ì¶œ"""
    try:
        # ë°©ë²• 1: ì§ì ‘ íŒŒì‹±
        try:
            return json.loads(text)
        except:
            pass
        
        # ë°©ë²• 2: ì½”ë“œë¸”ë¡ ì œê±°
        if "```json" in text:
            content = text.split("```json")[1].split("```")[0].strip()
        elif "```" in text:
            content = text.split("```")[1].strip()
        else:
            content = text
        
        try:
            return json.loads(content)
        except:
            pass
        
        # ë°©ë²• 3: ì •ê·œì‹ìœ¼ë¡œ JSON ì°¾ê¸°
        json_pattern = r'\{[^{}]*(?:\{[^{}]*\}[^{}]*)*\}'
        matches = re.findall(json_pattern, text, re.DOTALL)
        
        for match in matches:
            try:
                data = json.loads(match)
                if isinstance(data, dict) and 'abstract' in data:
                    return data
            except:
                continue
        
        # ë°©ë²• 4: ìˆ˜ë™ íŒŒì‹±
        return manual_parse_sections(text)
        
    except:
        return None

def manual_parse_sections(text):
    """ìˆ˜ë™ìœ¼ë¡œ ì„¹ì…˜ íŒŒì‹±"""
    try:
        sections = {
            "abstract": "",
            "introduction": "",
            "methods": "",
            "results": "",
            "visuals": "",
            "conclusion": "",
            "references": ""
        }
        
        # ë” ìœ ì—°í•œ í‚¤ì›Œë“œ ê²€ìƒ‰
        keywords = {
            'abstract': ['ì´ˆë¡', 'abstract', 'ìš”ì•½'],
            'introduction': ['ì„œë¡ ', 'introduction', 'ë°°ê²½', 'ë„ì…'],
            'methods': ['ë°©ë²•', 'method', 'ì‹¤í—˜', 'ì ˆì°¨'],
            'results': ['ê²°ê³¼', 'result', 'ì˜ˆìƒ'],
            'visuals': ['ì‹œê°', 'visual', 'ê·¸ë˜í”„', 'ì°¨íŠ¸'],
            'conclusion': ['ê²°ë¡ ', 'conclusion', 'ê²°ê³¼'],
            'references': ['ì°¸ê³ ', 'reference', 'ë¬¸í—Œ']
        }
        
        lines = text.split('\n')
        current_section = None
        
        for line in lines:
            line = line.strip()
            if not line or line.startswith('{') or line.startswith('}'):
                continue
            
            # ì„¹ì…˜ ê°ì§€
            found_section = None
            for section, kws in keywords.items():
                if any(kw in line.lower() for kw in kws):
                    found_section = section
                    break
            
            if found_section:
                current_section = found_section
            elif current_section and not line.startswith('"') and not line.startswith(','):
                # ë‚´ìš© ì¶”ê°€
                if sections[current_section]:
                    sections[current_section] += " " + line
                else:
                    sections[current_section] = line
        
        # ë¹ˆ ì„¹ì…˜ ì²˜ë¦¬
        for key, value in sections.items():
            if not value.strip():
                sections[key] = get_default_content(key)
        
        return sections
        
    except:
        return None

def validate_and_fix_sections(paper_data):
    """ì„¹ì…˜ë³„ ê²€ì¦ ë° ìˆ˜ì •"""
    try:
        required_sections = ['abstract', 'introduction', 'methods', 'results', 'visuals', 'conclusion', 'references']
        
        for section in required_sections:
            if section not in paper_data or not paper_data[section] or len(paper_data[section].strip()) < 20:
                paper_data[section] = get_default_content(section)
        
        # methods ì„¹ì…˜ íŠ¹ë³„ ì²˜ë¦¬ (ë„ˆë¬´ ê¸¸ë©´ ë‹¨ì¶•)
        if len(paper_data['methods']) > 1000:
            methods_text = paper_data['methods'][:800] + "...\n\në°ì´í„° ìˆ˜ì§‘ ë° ë¶„ì„: ì‹¤í—˜ ê²°ê³¼ë¥¼ ì²´ê³„ì ìœ¼ë¡œ ê¸°ë¡í•˜ê³  í†µê³„ì ìœ¼ë¡œ ë¶„ì„í•©ë‹ˆë‹¤."
            paper_data['methods'] = methods_text
        
        # references ì„¹ì…˜ ì •ë¦¬
        if paper_data['references']:
            paper_data['references'] = clean_references(paper_data['references'])
        
        return paper_data
        
    except:
        return paper_data

def get_default_content(section):
    """ê¸°ë³¸ ë‚´ìš© ì œê³µ"""
    defaults = {
        'abstract': "ë³¸ ì—°êµ¬ëŠ” ì œì‹œëœ ì£¼ì œì— ëŒ€í•´ ì²´ê³„ì ì¸ ì‹¤í—˜ì„ í†µí•´ ê³¼í•™ì  ê·¼ê±°ë¥¼ í™•ë³´í•˜ê³ ì í•œë‹¤. ì‹¤í—˜ì„ í†µí•´ ì–»ì€ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ ì˜ë¯¸ìˆëŠ” ê²°ë¡ ì„ ë„ì¶œí•  ì˜ˆì •ì´ë‹¤. ì´ ì—°êµ¬ ê²°ê³¼ëŠ” ê´€ë ¨ ë¶„ì•¼ì˜ ì´í•´ë¥¼ ë„“íˆëŠ” ë° ê¸°ì—¬í•  ê²ƒìœ¼ë¡œ ê¸°ëŒ€ëœë‹¤.",
        'introduction': "í˜„ì¬ ê´€ë ¨ ë¶„ì•¼ì—ì„œëŠ” ë‹¤ì–‘í•œ ì—°êµ¬ê°€ ì§„í–‰ë˜ê³  ìˆì§€ë§Œ, ì—¬ì „íˆ í•´ê²°ë˜ì§€ ì•Šì€ ë¬¸ì œë“¤ì´ ì¡´ì¬í•œë‹¤. ê¸°ì¡´ ì—°êµ¬ë“¤ì˜ í•œê³„ì ì„ ë³´ì™„í•˜ê³  ìƒˆë¡œìš´ ê´€ì ì„ ì œì‹œí•˜ê¸° ìœ„í•´ ë³¸ ì—°êµ¬ë¥¼ ìˆ˜í–‰í•œë‹¤. ë³¸ ì—°êµ¬ì˜ ëª©ì ì€ ì‹¤í—˜ì  ì ‘ê·¼ì„ í†µí•´ ì´ë¡ ì  ê°€ì„¤ì„ ê²€ì¦í•˜ëŠ” ê²ƒì´ë‹¤.",
        'methods': "1ë‹¨ê³„: ì‹¤í—˜ ì¬ë£Œ ì¤€ë¹„\ní•„ìš”í•œ ì‹¤í—˜ ë„êµ¬ì™€ ì¬ë£Œë¥¼ ì¤€ë¹„í•©ë‹ˆë‹¤.\n\n2ë‹¨ê³„: ì‹¤í—˜ í™˜ê²½ ì„¤ì •\në¨¼ì € ì‹¤í—˜ì‹¤ì˜ ì¡°ëª…ì„ ì¡°ì ˆí•˜ì—¬ ì ì ˆí•œ í™˜ê²½ì„ ë§Œë“­ë‹ˆë‹¤. ë‹¤ìŒìœ¼ë¡œ ì‹¤í—˜ ì¥ë¹„ë¥¼ ì•ˆì •ì ì¸ ê³³ì— ë°°ì¹˜í•©ë‹ˆë‹¤. ì´ë•Œ ì£¼ì˜í•  ì ì€ ì¥ë¹„ê°€ í”ë“¤ë¦¬ì§€ ì•Šë„ë¡ ê³ ì •í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.\n\n3ë‹¨ê³„: ë°ì´í„° ìˆ˜ì§‘ ì§„í–‰\nê·¸ í›„ì— ì‹¤í—˜ì„ ë‹¨ê³„ì ìœ¼ë¡œ ì§„í–‰í•˜ë©° ê° ë‹¨ê³„ë§ˆë‹¤ ê²°ê³¼ë¥¼ ê¸°ë¡í•©ë‹ˆë‹¤. ì¸¡ì •ê°’ì´ ì •í™•í•œì§€ í™•ì¸í•˜ë©´ì„œ ì§„í–‰í•©ë‹ˆë‹¤. ì‹¤í—˜ ì¤‘ì—ëŠ” ì™¸ë¶€ ìš”ì¸ì´ ì˜í–¥ì„ ì£¼ì§€ ì•Šë„ë¡ ì£¼ì˜í•©ë‹ˆë‹¤.\n\n4ë‹¨ê³„: ê²°ê³¼ ë¶„ì„ ë° ì •ë¦¬\në§ˆì§€ë§‰ìœ¼ë¡œ ìˆ˜ì§‘ëœ ë°ì´í„°ë¥¼ ì²´ê³„ì ìœ¼ë¡œ ë¶„ì„í•©ë‹ˆë‹¤. ê·¸ë˜í”„ë‚˜ í‘œë¡œ ì •ë¦¬í•˜ì—¬ íŒ¨í„´ì„ ì°¾ì•„ëƒ…ë‹ˆë‹¤. ì˜ˆìƒ ê²°ê³¼ì™€ ë¹„êµí•˜ì—¬ ì˜ë¯¸ìˆëŠ” ê²°ë¡ ì„ ë„ì¶œí•©ë‹ˆë‹¤.",
        'results': "ì‹¤í—˜ì„ í†µí•´ ë‹¤ìŒê³¼ ê°™ì€ ê²°ê³¼ë¥¼ ì–»ì„ ê²ƒìœ¼ë¡œ ì˜ˆìƒëœë‹¤: ì¸¡ì •ê°’ë“¤ ê°„ì˜ ìƒê´€ê´€ê³„, ê°€ì„¤ì˜ ê²€ì¦ ê²°ê³¼, ê·¸ë¦¬ê³  ì´ë¡ ì  ëª¨ë¸ê³¼ì˜ ì¼ì¹˜ì„± í‰ê°€ì´ë‹¤. ì´ëŸ¬í•œ ê²°ê³¼ëŠ” ê´€ë ¨ ë¶„ì•¼ì˜ ì´ë¡ ì  í† ëŒ€ë¥¼ ê°•í™”í•˜ëŠ” ë° ê¸°ì—¬í•  ê²ƒì´ë‹¤.",
        'visuals': "ì‹¤í—˜ ê²°ê³¼ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ í‘œí˜„í•˜ê¸° ìœ„í•´ ë‹¤ìŒê³¼ ê°™ì€ ì‹œê°ìë£Œë¥¼ ì œì‘í•  ì˜ˆì •ì…ë‹ˆë‹¤: ì‹¤í—˜ ê³¼ì •ì„ ë³´ì—¬ì£¼ëŠ” ì‚¬ì§„, ë°ì´í„° ë³€í™”ë¥¼ ë‚˜íƒ€ë‚´ëŠ” ê·¸ë˜í”„, ê²°ê³¼ë¥¼ ìš”ì•½í•œ í‘œ ë“±ì…ë‹ˆë‹¤.",
        'conclusion': "ë³¸ ì—°êµ¬ë¥¼ í†µí•´ ì œì‹œëœ ê°€ì„¤ì´ ì‹¤í—˜ì ìœ¼ë¡œ ê²€ì¦ë  ê²ƒìœ¼ë¡œ ì˜ˆìƒëœë‹¤. ì´ëŠ” ê´€ë ¨ ë¶„ì•¼ì˜ ì´ë¡ ì  ì´í•´ë¥¼ ê¹Šê²Œ í•˜ê³ , í›„ì† ì—°êµ¬ì˜ ë°©í–¥ì„±ì„ ì œì‹œí•˜ëŠ” ì¤‘ìš”í•œ ì˜ë¯¸ë¥¼ ê°–ëŠ”ë‹¤. ë˜í•œ ë³¸ ì—°êµ¬ì—ì„œ ê°œë°œëœ ì‹¤í—˜ ë°©ë²•ë¡ ì€ ìœ ì‚¬ ì—°êµ¬ì— í™œìš©ë  ìˆ˜ ìˆì„ ê²ƒì´ë‹¤.",
        'references': "1. ê´€ë ¨ ì£¼ì œ ì—°êµ¬ ë™í–¥\n- ë‚´ìš©: í•´ë‹¹ ë¶„ì•¼ì˜ ìµœì‹  ì—°êµ¬ ë™í–¥ê³¼ ì£¼ìš” ë°œê²¬ì‚¬í•­ì„ ì •ë¦¬í•œ ìë£Œì…ë‹ˆë‹¤. êµ­ë‚´ì™¸ ì—°êµ¬ í˜„í™©ì„ íŒŒì•…í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n- ë§í¬: https://scholar.google.com/scholar?q=related+research+trends+2024\n- í™œìš©: ì—°êµ¬ ë°°ê²½ ì´í•´ì™€ ë°©í–¥ ì„¤ì •ì— ë„ì›€ì´ ë©ë‹ˆë‹¤.\n\n2. ì‹¤í—˜ ë°©ë²•ë¡  ê°€ì´ë“œ\n- ë‚´ìš©: ê³¼í•™ì  ì‹¤í—˜ ì„¤ê³„ì™€ ë°ì´í„° ë¶„ì„ ë°©ë²•ì— ëŒ€í•œ ì¢…í•©ì  ì•ˆë‚´ì„œì…ë‹ˆë‹¤.\n- ë§í¬: https://www.physics.org/experimental-methods\n- í™œìš©: ì²´ê³„ì ì¸ ì‹¤í—˜ ì§„í–‰ì„ ìœ„í•œ ì°¸ê³ ìë£Œë¡œ í™œìš©í•©ë‹ˆë‹¤.\n\n3. ì •ë¶€ ì—°êµ¬ ë³´ê³ ì„œ\n- ë‚´ìš©: ê´€ë ¨ ë¶„ì•¼ì— ëŒ€í•œ ì •ë¶€ ì°¨ì›ì˜ ì—°êµ¬ ë° ì •ì±… ìë£Œì…ë‹ˆë‹¤.\n- ë§í¬: https://www.ndsl.kr\n- í™œìš©: êµ­ê°€ì  ê´€ì ì—ì„œì˜ ì—°êµ¬ ë°©í–¥ì„± íŒŒì•…ì— ë„ì›€ì´ ë©ë‹ˆë‹¤."
    }
    return defaults.get(section, f"{section} ì„¹ì…˜ ë‚´ìš©ì´ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

def clean_references(ref_text):
    """ì°¸ê³ ë¬¸í—Œ ì •ë¦¬ - í•œêµ­+ì˜ë¬¸ DB ì‚¬ì´íŠ¸ë¡œ êµì²´ (í•œêµ­ 4ê°œ, ì˜ë¬¸ 3ê°œ)"""
    try:
        cleaned = ref_text
        
        # ğŸ”¥ ëª¨ë“  ë§í¬ë¥¼ ì‹¤ì œ DB ì‚¬ì´íŠ¸ë¡œ êµì²´
        import re
        
        # ëª¨ë“  ë§í¬ íŒ¨í„´ ì°¾ê¸° (scholar, sciencedirect ë“±)
        all_links = re.findall(r'https://[^\s]*', cleaned)
        
        # êµì²´ìš© ë§í¬ (í•œêµ­ 4ê°œ + ì˜ë¬¸ 3ê°œ)
        replacement_links = [
            'https://www.dbpia.co.kr/search/topSearch?searchName=',  # í•œêµ­ 1
            'https://www.riss.kr/search/Search.do?queryText=',       # í•œêµ­ 2  
            'https://www.kci.go.kr/kciportal/ci/sereArticleSearch/ciSereArtiView.kci', # í•œêµ­ 3
            'https://www.ndsl.kr/ndsl/search/detail/trend/trendSearchResultDetail.do', # í•œêµ­ 4
            'https://www.sciencedirect.com/search?qs=',             # ì˜ë¬¸ 1
            'https://ieeexplore.ieee.org/search/searchresult.jsp?queryText=', # ì˜ë¬¸ 2
            'https://pubmed.ncbi.nlm.nih.gov/?term='               # ì˜ë¬¸ 3
        ]
        
        # ë°œê²¬ëœ ë§í¬ë¥¼ ìˆœì„œëŒ€ë¡œ êµì²´
        for i, old_link in enumerate(all_links):
            if i < len(replacement_links):
                replacement_link = replacement_links[i]
                cleaned = cleaned.replace(old_link, replacement_link, 1)
            else:
                # 7ê°œ ì´ˆê³¼ ì‹œ ìˆœí™˜
                replacement_link = replacement_links[i % len(replacement_links)]
                cleaned = cleaned.replace(old_link, replacement_link, 1)
        
        return cleaned.strip()
    except:
        return ref_text

def parse_text_response(text):
    """JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ í…ìŠ¤íŠ¸ì—ì„œ ì„¹ì…˜ë³„ë¡œ ì¶”ì¶œ"""
    return manual_parse_sections(text)

def create_error_response():
    """ì—ëŸ¬ ë°œìƒ ì‹œ ê¸°ë³¸ ì‘ë‹µ"""
    return {
        "abstract": "ë…¼ë¬¸ ì´ˆë¡ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì£¼ì œë¥¼ ë” êµ¬ì²´ì ìœ¼ë¡œ ì…ë ¥í•˜ê³  ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.",
        "introduction": "ì„œë¡  ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì—°êµ¬ ë°°ê²½ì„ ë‹¤ì‹œ ê²€í† í•´ì£¼ì„¸ìš”.",
        "methods": "ì—°êµ¬ ë°©ë²• ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.",
        "results": "ì˜ˆìƒ ê²°ê³¼ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë„¤íŠ¸ì›Œí¬ ìƒíƒœë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.",
        "visuals": "ì‹œê°ìë£Œ ì œì•ˆ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
        "conclusion": "ê²°ë¡  ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
        "references": "ì°¸ê³ ë¬¸í—Œ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
    }
