# utils/generate_paper.py
import streamlit as st
import anthropic
import json
import re

@st.cache_data(ttl=3600, show_spinner=False)
def generate_research_paper(topic, research_idea, references=""):
    """
    ì„ íƒëœ ì—°êµ¬ ì•„ì´ë””ì–´ì— ëŒ€í•œ ë…¼ë¬¸ í˜•ì‹ì˜ ì—°êµ¬ ê³„íšì„ ìƒì„±
    """
    try:
        client = anthropic.Anthropic(api_key=st.secrets["api"]["claude_key"])
        
        # ğŸ”¥ ìˆ˜ì •ëœ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ - ì‹¤í—˜ë°©ë²• ë¶€ë¶„ ëŒ€í­ ê°•í™”
        system_prompt = """
        ê³ ë“±í•™ìƒì„ ìœ„í•œ ì—°êµ¬ ê³„íšì„œë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”. ë°˜ë“œì‹œ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”.
        
        ì‘ë‹µ í˜•ì‹ (ì´ í˜•ì‹ ì™¸ì—ëŠ” ì ˆëŒ€ ë‹¤ë¥¸ í…ìŠ¤íŠ¸ í¬í•¨ ê¸ˆì§€):
        {"abstract": "ì´ˆë¡", "introduction": "ì„œë¡ ", "methods": "ë°©ë²•", "results": "ê²°ê³¼", "visuals": "ì‹œê°ìë£Œ", "conclusion": "ê²°ë¡ ", "references": "ì°¸ê³ ë¬¸í—Œ"}
        
        ê° ì„¹ì…˜ ì‘ì„± ê°€ì´ë“œ:
        - abstract: ì—°êµ¬ ëª©ì ê³¼ ì˜ˆìƒ ê²°ê³¼ë¥¼ ê°„ë‹¨íˆ ìš”ì•½ (150-200ë‹¨ì–´)
        - introduction: ì—°êµ¬ ë°°ê²½ â†’ ë¬¸ì œì  â†’ ê¸°ì¡´ ì—°êµ¬ â†’ ë³¸ ì—°êµ¬ ëª©ì  ìˆœì„œë¡œ ì‘ì„± (300-400ë‹¨ì–´)
        - methods: ì‹¤í—˜ ì ˆì°¨ì™€ ë°©ë²•ë¡  (400-500ë‹¨ì–´) - ì•„ë˜ ê·œì¹™ ì¤€ìˆ˜
        - results: ì˜ˆìƒë˜ëŠ” ê²°ê³¼ì™€ ì˜ë¯¸ (200-300ë‹¨ì–´)
        - visuals: ì‹œê°ìë£Œ ì œì•ˆì„ í…ìŠ¤íŠ¸ë¡œ ì„¤ëª… (100-200ë‹¨ì–´)
        - conclusion: ì—°êµ¬ì˜ ì˜ì˜ì™€ ê¸°ëŒ€íš¨ê³¼ (150-200ë‹¨ì–´)
        - references: ì•„ë˜ ê·œì¹™ì— ë”°ë¼ ì‹¤ì œ ìë£Œë§Œ ì°¸ì¡°
        
        **ğŸ”¥ ì‹¤í—˜ë°©ë²•(Methods) ì‘ì„± ê·œì¹™ (ê°€ì¥ ì¤‘ìš”!):**
        1. **í•„ìš”í•œ ì¬ë£Œ ë° ì¥ë¹„** (2-3ë¬¸ì¥ìœ¼ë¡œ ê°„ë‹¨íˆ)
           - í•µì‹¬ ì¥ë¹„ë§Œ ë‚˜ì—´, ë„ˆë¬´ ê¸¸ì§€ ì•Šê²Œ
        
        2. **ì‹¤í—˜ ì ˆì°¨** (ì „ì²´ ë¶„ëŸ‰ì˜ 80% í• ë‹¹) - ë§¤ìš° ìƒì„¸í•˜ê³  ì¹œì ˆí•˜ê²Œ!
           - "1ë‹¨ê³„: [ì œëª©]" í˜•ì‹ìœ¼ë¡œ ë²ˆí˜¸ ë§¤ê¸°ê¸°
           - ê° ë‹¨ê³„ë§ˆë‹¤ êµ¬ì²´ì ì¸ í–‰ë™ì„ ì„œìˆ í˜•ìœ¼ë¡œ ì„¤ëª…
           - "ë¨¼ì €", "ë‹¤ìŒìœ¼ë¡œ", "ê·¸ í›„ì—", "ë§ˆì§€ë§‰ìœ¼ë¡œ" ë“± ì—°ê²°ì–´ ì‚¬ìš©
           - ê³ ë“±í•™ìƒì´ ë”°ë¼ í•  ìˆ˜ ìˆì„ ì •ë„ë¡œ ì¹œì ˆí•˜ê³  êµ¬ì²´ì ìœ¼ë¡œ
           - ì¸¡ì • ë°©ë²•, ê¸°ë¡ ë°©ë²•, ì£¼ì˜ì‚¬í•­ë„ í¬í•¨
           - ìµœì†Œ 5-7ë‹¨ê³„ë¡œ ë‚˜ëˆ„ì–´ ì„¤ëª…
        
        3. **ë°ì´í„° ìˆ˜ì§‘ ë° ë¶„ì„**
           - ì–´ë–¤ ë°ì´í„°ë¥¼ ì–´ë–»ê²Œ ê¸°ë¡í• ì§€
           - ë°˜ë³µ ì‹¤í—˜ íšŸìˆ˜ì™€ ì´ìœ 
        
        **ì°¸ê³ ë¬¸í—Œ ì‘ì„± ê·œì¹™:**
        1. ì‹¤ì œ í™•ì¸ ê°€ëŠ¥í•œ ìë£Œë§Œ ì‚¬ìš©í•˜ê³ , í´ë¦­ ê°€ëŠ¥í•œ ë§í¬ ì œê³µ
        2. ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì‘ì„±:
           **[ë²ˆí˜¸]. ìë£Œ ì œëª©** 
           ğŸ“„ ë‚´ìš© ìš”ì•½: (ì´ ìë£Œê°€ ë‹¤ë£¨ëŠ” í•µì‹¬ ë‚´ìš©ì„ 2-3ë¬¸ì¥ìœ¼ë¡œ ì„¤ëª…)
           ğŸ”— ë§í¬: [ì‹¤ì œ ì ‘ê·¼ ê°€ëŠ¥í•œ URL]
           ğŸ“Œ í™œìš© ë°©ì•ˆ: (ë³¸ ì—°êµ¬ì— ì–´ë–»ê²Œ ë„ì›€ì´ ë˜ëŠ”ì§€ 1-2ë¬¸ì¥)
        
        3. ì¶”ì²œ ìë£Œ ìœ í˜•:
           - Google Scholar ê²€ìƒ‰ ê²°ê³¼ (scholar.google.com)
           - ì •ë¶€ê¸°ê´€ ê³µì‹ ë³´ê³ ì„œ (.go.kr)
           - ëŒ€í•™ ì—°êµ¬ì†Œ ìë£Œ
           - IEEE, Nature, Science ë“± ê³µê°œ ìë£Œ
           - arXiv í”„ë¦¬í”„ë¦°íŠ¸
        
        ê³ ë“±í•™ìƒì´ ì‹¤ì œë¡œ ì‹¤í—˜í•  ìˆ˜ ìˆì„ ì •ë„ë¡œ ì¹œì ˆí•˜ê³  êµ¬ì²´ì ìœ¼ë¡œ ì¨ì£¼ì„¸ìš”.
        """
        
        user_prompt = f"""
        ì£¼ì œ: {topic}
        ì—°êµ¬ ì•„ì´ë””ì–´: {research_idea}
        
        ìœ„ ë‚´ìš©ìœ¼ë¡œ ê³ ë“±í•™ìƒ ìˆ˜ì¤€ì˜ ì—°êµ¬ ê³„íšì„œë¥¼ JSON í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.
        
        íŠ¹íˆ ì‹¤í—˜ë°©ë²•(methods) ì„¹ì…˜ì€:
        - ì¥ë¹„ ë‚˜ì—´ë³´ë‹¤ëŠ” "ì‹¤í—˜ì„ ì–´ë–»ê²Œ ì§„í–‰í•˜ëŠ”ì§€" ë‹¨ê³„ë³„ ì„¤ëª…ì— ì§‘ì¤‘
        - "1ë‹¨ê³„: ì¤€ë¹„ ê³¼ì •ì—ì„œëŠ”...", "2ë‹¨ê³„: ì¸¡ì • ê³¼ì •ì—ì„œëŠ”..." í˜•ì‹ìœ¼ë¡œ ìƒì„¸íˆ
        - ê³ ë“±í•™ìƒì´ ì‹¤ì œë¡œ ë”°ë¼í•  ìˆ˜ ìˆì„ ì •ë„ë¡œ ì¹œì ˆí•˜ê²Œ ì‘ì„±
        
        íŠ¹íˆ ì°¸ê³ ë¬¸í—Œ(references) ì„¹ì…˜ì€:
        - ì‹¤ì œ í´ë¦­í•´ì„œ í™•ì¸ ê°€ëŠ¥í•œ ë§í¬ë§Œ í¬í•¨
        - ê° ìë£Œì˜ í•µì‹¬ ë‚´ìš©ì„ 2-3ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½
        - Google Scholar, arXiv, ì •ë¶€ê¸°ê´€ ì‚¬ì´íŠ¸ ë“± ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì¶œì²˜ë§Œ ì‚¬ìš©
        - í˜•ì‹ ì˜ˆì‹œ: "1. ìë£Œì œëª© ğŸ“„ ë‚´ìš©ìš”ì•½: ... ğŸ”— ë§í¬: https://... ğŸ“Œ í™œìš©ë°©ì•ˆ: ..."
        """
        
        # Claude í˜¸ì¶œ
        response = client.messages.create(
            model="claude-3-5-sonnet-20241022",
            max_tokens=3500,  # ë” ê¸´ ì‘ë‹µì„ ìœ„í•´ ì¦ê°€
            temperature=0.3,
            system=system_prompt,
            messages=[
                {"role": "user", "content": user_prompt}
            ]
        )
        
        response_text = response.content[0].text.strip()
        print(f"=== Claude ì‘ë‹µ ì›ë³¸ ===")
        print(response_text[:500] + "...")
        
        # JSON ì¶”ì¶œ ì‹œë„ (ì—¬ëŸ¬ ë°©ë²•ìœ¼ë¡œ)
        paper_data = None
        
        # ë°©ë²• 1: ì§ì ‘ JSON íŒŒì‹±
        try:
            paper_data = json.loads(response_text)
            print("âœ… ì§ì ‘ JSON íŒŒì‹± ì„±ê³µ")
        except:
            print("âŒ ì§ì ‘ JSON íŒŒì‹± ì‹¤íŒ¨, ë‹¤ë¥¸ ë°©ë²• ì‹œë„...")
        
        # ë°©ë²• 2: ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡ ì œê±° í›„ íŒŒì‹±
        if not paper_data:
            try:
                # ```json ... ``` ì œê±°
                if "```json" in response_text:
                    json_content = response_text.split("```json")[1].split("```")[0].strip()
                elif "```" in response_text:
                    json_content = response_text.split("```")[1].strip()
                else:
                    json_content = response_text
                
                paper_data = json.loads(json_content)
                print("âœ… ë§ˆí¬ë‹¤ìš´ ì œê±° í›„ JSON íŒŒì‹± ì„±ê³µ")
            except Exception as e:
                print(f"âŒ ë§ˆí¬ë‹¤ìš´ ì œê±° í›„ì—ë„ ì‹¤íŒ¨: {e}")
        
        # ë°©ë²• 3: ì •ê·œì‹ìœ¼ë¡œ JSON ì¶”ì¶œ
        if not paper_data:
            try:
                # { ... } íŒ¨í„´ ì°¾ê¸°
                json_pattern = r'\{.*\}'
                json_match = re.search(json_pattern, response_text, re.DOTALL)
                if json_match:
                    json_content = json_match.group(0)
                    paper_data = json.loads(json_content)
                    print("âœ… ì •ê·œì‹ ì¶”ì¶œ í›„ JSON íŒŒì‹± ì„±ê³µ")
            except Exception as e:
                print(f"âŒ ì •ê·œì‹ ì¶”ì¶œ í›„ì—ë„ ì‹¤íŒ¨: {e}")
        
        # ë°©ë²• 4: í‚¤ì›Œë“œ ê¸°ë°˜ í…ìŠ¤íŠ¸ íŒŒì‹± (ìµœí›„ì˜ ìˆ˜ë‹¨)
        if not paper_data:
            print("âš ï¸ JSON íŒŒì‹± ëª¨ë‘ ì‹¤íŒ¨, í…ìŠ¤íŠ¸ íŒŒì‹±ìœ¼ë¡œ ëŒ€ì²´")
            paper_data = parse_text_response(response_text)
        
        # ì°¸ê³ ë¬¸í—Œë§Œ í›„ì²˜ë¦¬ ì¶”ê°€
        if paper_data and 'references' in paper_data:
            paper_data['references'] = clean_fake_references(paper_data['references'])
        
        return paper_data
        
    except Exception as e:
        print(f"âŒ ì „ì²´ ë…¼ë¬¸ ìƒì„± ì˜¤ë¥˜: {e}")
        return create_error_response()

def parse_text_response(text):
    """JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ í…ìŠ¤íŠ¸ì—ì„œ ì„¹ì…˜ë³„ë¡œ ì¶”ì¶œ"""
    try:
        sections = {
            "abstract": "",
            "introduction": "",
            "methods": "",
            "results": "",
            "visuals": "",
            "conclusion": "",
            "references": ""
        }
        
        # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ë§¤ì¹­ìœ¼ë¡œ ì„¹ì…˜ ì¶”ì¶œ
        lines = text.split('\n')
        current_section = None
        
        for line in lines:
            line = line.strip()
            if not line:
                continue
                
            # ì„¹ì…˜ í—¤ë” ê°ì§€
            if any(keyword in line.lower() for keyword in ['ì´ˆë¡', 'abstract']):
                current_section = 'abstract'
            elif any(keyword in line.lower() for keyword in ['ì„œë¡ ', 'introduction', 'ë°°ê²½']):
                current_section = 'introduction'
            elif any(keyword in line.lower() for keyword in ['ë°©ë²•', 'method']):
                current_section = 'methods'
            elif any(keyword in line.lower() for keyword in ['ê²°ê³¼', 'result']):
                current_section = 'results'
            elif any(keyword in line.lower() for keyword in ['ì‹œê°', 'visual']):
                current_section = 'visuals'
            elif any(keyword in line.lower() for keyword in ['ê²°ë¡ ', 'conclusion']):
                current_section = 'conclusion'
            elif any(keyword in line.lower() for keyword in ['ì°¸ê³ ', 'reference']):
                current_section = 'references'
            elif current_section and not line.startswith('#'):
                # í˜„ì¬ ì„¹ì…˜ì— ë‚´ìš© ì¶”ê°€
                sections[current_section] += line + " "
        
        # ë¹ˆ ì„¹ì…˜ ì±„ìš°ê¸°
        for key, value in sections.items():
            if not value.strip():
                sections[key] = f"{key.title()} ì„¹ì…˜ì´ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
        
        return sections
        
    except Exception as e:
        print(f"í…ìŠ¤íŠ¸ íŒŒì‹± ì˜¤ë¥˜: {e}")
        return create_error_response()

def clean_fake_references(ref_text):
    """ì°¸ê³ ë¬¸í—Œ í’ˆì§ˆ ê°œì„  - ì‹¤ì œ ë§í¬ëŠ” ìœ ì§€í•˜ê³  ê°€ì§œ ì •ë³´ë§Œ ì œê±°"""
    try:
        cleaned = ref_text
        
        # ğŸ”¥ ì‹¤ì œ í™•ì¸ ê°€ëŠ¥í•œ ë„ë©”ì¸ì€ ìœ ì§€
        trusted_domains = [
            'scholar.google.com',
            'arxiv.org', 
            'ieee.org',
            'nature.com',
            'science.org',
            'ncbi.nlm.nih.gov',
            'go.kr',  # ì •ë¶€ê¸°ê´€
            'edu',    # ëŒ€í•™
            'ac.kr'   # í•œêµ­ ëŒ€í•™
        ]
        
        # ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ë„ë©”ì¸ì˜ ë§í¬ëŠ” ìœ ì§€
        # ë‚˜ë¨¸ì§€ ì˜ì‹¬ìŠ¤ëŸ¬ìš´ ë§í¬ë§Œ ì œê±°
        lines = cleaned.split('\n')
        filtered_lines = []
        
        for line in lines:
            # ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ë„ë©”ì¸ ë§í¬ê°€ ìˆìœ¼ë©´ ìœ ì§€
            has_trusted_link = any(domain in line for domain in trusted_domains)
            
            if has_trusted_link:
                filtered_lines.append(line)
            else:
                # ì˜ì‹¬ìŠ¤ëŸ¬ìš´ ë§í¬ ì œê±°
                line_without_suspicious = re.sub(r'https?://[^\s\)]+', '', line)
                if line_without_suspicious.strip():  # ë¹ˆ ì¤„ì´ ì•„ë‹ˆë©´ ì¶”ê°€
                    filtered_lines.append(line_without_suspicious)
        
        cleaned = '\n'.join(filtered_lines)
        
        # ì˜ì‹¬ìŠ¤ëŸ¬ìš´ ê°€ì§œ ì €ìëª… ì œê±° (ê¸°ì¡´ ë¡œì§ ìœ ì§€)
        fake_authors = ['Smith, J.', 'Johnson, A.', 'Brown, M.', 'Lee, K.', 'Kim, S.', 'Park, H.']
        for fake in fake_authors:
            cleaned = cleaned.replace(f'- {fake}', '- ì—°êµ¬ì§„')
            cleaned = cleaned.replace(fake, 'ì—°êµ¬ì§„')
        
        return cleaned.strip()
    except:
        return ref_text

def create_error_response():
    """ì—ëŸ¬ ë°œìƒ ì‹œ ê¸°ë³¸ ì‘ë‹µ"""
    return {
        "abstract": "ë…¼ë¬¸ ì´ˆë¡ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì£¼ì œë¥¼ ë” êµ¬ì²´ì ìœ¼ë¡œ ì…ë ¥í•˜ê³  ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.",
        "introduction": "ì„œë¡  ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì—°êµ¬ ë°°ê²½ì„ ë‹¤ì‹œ ê²€í† í•´ì£¼ì„¸ìš”.",
        "methods": "ì—°êµ¬ ë°©ë²• ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.",
        "results": "ì˜ˆìƒ ê²°ê³¼ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë„¤íŠ¸ì›Œí¬ ìƒíƒœë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.",
        "visuals": "ì‹œê°ìë£Œ ì œì•ˆ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
        "conclusion": "ê²°ë¡  ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
        "references": "ì°¸ê³ ë¬¸í—Œ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
    }
