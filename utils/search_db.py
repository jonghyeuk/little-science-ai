import pandas as pd
import os
import streamlit as st
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from utils.explain_topic import explain_topic
from openai import OpenAI

# ğŸ“ ë‚´ë¶€ DB ê²½ë¡œ
DB_PATH = os.path.join("data", "ISEF Final DB.xlsx")

# ğŸ”¤ ì—´ ì´ë¦„ ë§¤í•‘
COLUMN_MAP = {
    'project title': 'ì œëª©',
    'year': 'ì—°ë„',
    'category': 'ë¶„ì•¼'
}

# âœ… GPT ë²ˆì—­ í•¨ìˆ˜ (ìºì‹œ ì‚¬ìš©)
@st.cache_data(show_spinner=False)
def gpt_translate(text: str, tgt_lang="en") -> str:
    try:
        client = OpenAI(api_key=st.secrets["api"]["openai_key"])
        prompt = f"ë‹¤ìŒ ë¬¸ì¥ì„ {tgt_lang} ì–¸ì–´ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ë²ˆì—­í•´ì¤˜: '{text}'"
        res = client.chat.completions.create(
            model="gpt-4",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.3
        )
        return res.choices[0].message.content.strip()
    except Exception:
        return text

# âœ… ìš”ì•½ ìƒì„± í•¨ìˆ˜
def get_summary(title):
    try:
        return explain_topic(title)[0]
    except:
        return "ìš”ì•½ ì—†ìŒ"

# âœ… ë‚´ë¶€ DB ë¡œë“œ ë° ì •ì œ
def load_internal_db():
    try:
        df = pd.read_excel(DB_PATH)
    except Exception as e:
        st.error(f"âŒ ë‚´ë¶€ DB ë¡œë“œ ì‹¤íŒ¨: {e}")
        st.stop()

    df.columns = [col.strip().lower() for col in df.columns]
    df.rename(columns=lambda c: COLUMN_MAP.get(c, c), inplace=True)

    df['ì œëª©'] = df.get('ì œëª©', pd.Series(["ì œëª© ì—†ìŒ"] * len(df))).fillna("ì œëª© ì—†ìŒ").astype(str)
    df['ìš”ì•½'] = df.get('ìš”ì•½', pd.Series([""] * len(df))).fillna("").astype(str)
    df['ë¶„ì•¼'] = df.get('ë¶„ì•¼', pd.Series(["ë¶„ì•¼ ì—†ìŒ"] * len(df))).fillna("ë¶„ì•¼ ì—†ìŒ").astype(str)
    df['ì—°ë„'] = df.get('ì—°ë„', pd.Series(["ì—°ë„ ì—†ìŒ"] * len(df))).fillna("ì—°ë„ ì—†ìŒ").astype(str)

    return df

# âœ… ìœ ì‚¬ ë…¼ë¬¸ ê²€ìƒ‰
def search_similar_titles(user_input, max_results=5):
    df = load_internal_db()

    # ğŸ” ì…ë ¥ ì£¼ì œ GPT ë²ˆì—­
    translated_input = gpt_translate(user_input)

    # ğŸ” DB ì œëª© ë¦¬ìŠ¤íŠ¸ ë²ˆì—­
    unique_titles = list(set(df['ì œëª©'].tolist()))
    translated_map = {t: gpt_translate(t) for t in unique_titles}
    df['ì œëª©_ë²ˆì—­'] = df['ì œëª©'].map(translated_map)

    # ğŸ” TF-IDF ìœ ì‚¬ë„ ë¶„ì„
    corpus = df['ì œëª©_ë²ˆì—­'].tolist() + [translated_input]
    try:
        vectorizer = TfidfVectorizer(analyzer='char_wb', ngram_range=(3, 5), lowercase=True)
        tfidf_matrix = vectorizer.fit_transform(corpus)
        cosine_sim = cosine_similarity(tfidf_matrix[-1], tfidf_matrix[:-1]).flatten()
    except Exception as e:
        st.error(f"âŒ ìœ ì‚¬ë„ ë¶„ì„ ì˜¤ë¥˜: {e}")
        st.stop()

    df['score'] = cosine_sim
    df = df[df['score'] > 0]

    top = df.sort_values(by='score', ascending=False).head(max_results)

    # â›“ ìš”ì•½ ìƒì„± ë³´ì™„
    top['ìš”ì•½'] = top.apply(
        lambda row: row['ìš”ì•½'].strip() if row['ìš”ì•½'].strip() else get_summary(row['ì œëª©']),
        axis=1
    )

    return top[['ì œëª©', 'ìš”ì•½', 'ì—°ë„', 'ë¶„ì•¼', 'score']].to_dict(orient='records')
