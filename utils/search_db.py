# search_db.py ìˆ˜ì • ë²„ì „
import pandas as pd
import os
import streamlit as st
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from utils.explain_topic import explain_topic
from openai import OpenAI
import re

# ğŸ“ ë‚´ë¶€ DB ê²½ë¡œ
DB_PATH = os.path.join("data", "ISEF Final DB.xlsx")

# ğŸ”¤ ì—´ ì´ë¦„ ë§¤í•‘
COLUMN_MAP = {
    'project title': 'ì œëª©',
    'year': 'ì—°ë„',
    'category': 'ë¶„ì•¼'
}

# í‚¤ì›Œë“œ ì¶”ì¶œ í•¨ìˆ˜ (NLTK ì—†ì´ êµ¬í˜„)
def extract_keywords(text, top_n=5):
    """í…ìŠ¤íŠ¸ì—ì„œ ì¤‘ìš” í‚¤ì›Œë“œ ì¶”ì¶œ - ê°„ë‹¨í•œ ë²„ì „"""
    # íŠ¹ìˆ˜ë¬¸ì ì œê±° ë° ì†Œë¬¸ìí™”
    text = re.sub(r'[^\w\s]', '', text.lower())
    
    # í•œêµ­ì–´ ë¶ˆìš©ì–´ (ì§ì ‘ ì •ì˜)
    stopwords = ['ì´', 'ê·¸', 'ì €', 'ê²ƒ', 'ë°', 'ë“±', 'ë¥¼', 'ì„', 'ì—', 'ì—ì„œ', 'ì˜', 'ìœ¼ë¡œ', 'ë¡œ', 'ì—ê²Œ', 'í•˜ë‹¤', 'ìˆë‹¤', 'ë˜ë‹¤']
    
    # ë‹¨ì–´ ë¶„ë¦¬ ë° ë¶ˆìš©ì–´ ì œê±°
    words = []
    for word in text.split():
        if word not in stopwords and len(word) > 1:  # 2ê¸€ì ì´ìƒë§Œ í¬í•¨
            words.append(word)
    
    # ë¹ˆë„ìˆ˜ ê¸°ë°˜ í‚¤ì›Œë“œ ì¶”ì¶œ
    word_counts = {}
    for word in words:
        word_counts[word] = word_counts.get(word, 0) + 1
    
    # ë¹ˆë„ìˆœ ì •ë ¬ ë° ìƒìœ„ í‚¤ì›Œë“œ ë°˜í™˜
    sorted_words = sorted(word_counts.items(), key=lambda x: x[1], reverse=True)
    return [word for word, _ in sorted_words[:top_n]]

# âœ… GPT ë²ˆì—­ í•¨ìˆ˜ (í‚¤ì›Œë“œë§Œ ë²ˆì—­)
@st.cache_data(show_spinner=False)
def gpt_translate_keywords(keywords, tgt_lang="en") -> list:
    """í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸ë§Œ ë²ˆì—­ (API í˜¸ì¶œ ìµœì†Œí™”)"""
    if not keywords:
        return []
        
    try:
        client = OpenAI(api_key=st.secrets["api"]["openai_key"])
        # í‚¤ì›Œë“œë¥¼ í•œ ë²ˆì— ë²ˆì—­ ìš”ì²­
        keyword_text = ", ".join(keywords)
        prompt = f"ë‹¤ìŒ í‚¤ì›Œë“œë“¤ì„ {tgt_lang}ë¡œ ë²ˆì—­í•´ì£¼ì„¸ìš”. ë²ˆì—­ëœ í‚¤ì›Œë“œë§Œ ì‰¼í‘œë¡œ êµ¬ë¶„í•˜ì—¬ ì•Œë ¤ì£¼ì„¸ìš”: {keyword_text}"
        
        res = client.chat.completions.create(
            model="gpt-4",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.3
        )
        
        # ë²ˆì—­ëœ í‚¤ì›Œë“œ íŒŒì‹±
        translated = res.choices[0].message.content.strip()
        return [k.strip() for k in translated.split(',')]
    except Exception as e:
        st.warning(f"í‚¤ì›Œë“œ ë²ˆì—­ ì¤‘ ì˜¤ë¥˜: {e}")
        return keywords  # ì‹¤íŒ¨ ì‹œ ì›ë³¸ ë°˜í™˜

# âœ… ìš”ì•½ ìƒì„± í•¨ìˆ˜
def get_summary(title):
    try:
        return explain_topic(title)[0]
    except:
        return "ìš”ì•½ ì—†ìŒ"

# âœ… ë‚´ë¶€ DB ë¡œë“œ ë° ì •ì œ
def load_internal_db():
    try:
        df = pd.read_excel(DB_PATH)
    except Exception as e:
        st.error(f"âŒ ë‚´ë¶€ DB ë¡œë“œ ì‹¤íŒ¨: {e}")
        return pd.DataFrame()  # ë¹ˆ ë°ì´í„°í”„ë ˆì„ ë°˜í™˜
        
    df.columns = [col.strip().lower() for col in df.columns]
    df = df.rename(columns=lambda c: COLUMN_MAP.get(c, c))
    
    # í•„ìˆ˜ ì—´ ì¶”ê°€ (ì•ˆì „í•˜ê²Œ)
    for col in ['ì œëª©', 'ìš”ì•½', 'ë¶„ì•¼', 'ì—°ë„']:
        if col not in df.columns:
            df[col] = "ì •ë³´ ì—†ìŒ"
    
    # ëˆ„ë½ëœ ê°’ ì²˜ë¦¬
    df['ì œëª©'] = df['ì œëª©'].fillna("ì œëª© ì—†ìŒ").astype(str)
    df['ìš”ì•½'] = df['ìš”ì•½'].fillna("").astype(str)
    df['ë¶„ì•¼'] = df['ë¶„ì•¼'].fillna("ë¶„ì•¼ ì—†ìŒ").astype(str)
    df['ì—°ë„'] = df['ì—°ë„'].fillna("ì—°ë„ ì—†ìŒ").astype(str)
    
    return df

# âœ… ìƒˆë¡œìš´ ìœ ì‚¬ ë…¼ë¬¸ ê²€ìƒ‰ í•¨ìˆ˜
def search_similar_titles(user_input, max_results=5):
    # DB ë¡œë“œ
    df = load_internal_db()
    
    # DBê°€ ë¹„ì–´ìˆìœ¼ë©´ ë¹ˆ ê²°ê³¼ ë°˜í™˜
    if df.empty:
        st.error("âŒ ë‚´ë¶€ DBê°€ ë¹„ì–´ìˆê±°ë‚˜ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return []
    
    # 1. ì‚¬ìš©ì ì…ë ¥ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ
    keywords = extract_keywords(user_input)
    
    # í‚¤ì›Œë“œê°€ ì—†ìœ¼ë©´ ë¹ˆ ê²°ê³¼ ë°˜í™˜
    if not keywords:
        st.warning("âš ï¸ ì…ë ¥ì—ì„œ í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return []
    
    # 2. í‚¤ì›Œë“œë§Œ ë²ˆì—­ (API í˜¸ì¶œ ìµœì†Œí™”)
    translated_keywords = gpt_translate_keywords(keywords)
    
    if not translated_keywords:
        st.warning("âš ï¸ í‚¤ì›Œë“œ ë²ˆì—­ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
        translated_keywords = keywords  # ë²ˆì—­ ì‹¤íŒ¨ ì‹œ ì›ë³¸ ì‚¬ìš©
    
    # 3. ê²€ìƒ‰ìš© ì¿¼ë¦¬ ìƒì„±
    search_query = " ".join(translated_keywords)
    
    # 4. ì˜ë¬¸ ì œëª©ì— ëŒ€í•´ TF-IDF ìœ ì‚¬ë„ ë¶„ì„
    # DBì— ì˜ë¬¸ ì œëª© í•„ë“œê°€ ìˆë‹¤ê³  ê°€ì •
    title_field = 'project title' if 'project title' in df.columns else 'ì œëª©'
    
    # ì•ˆì „í•˜ê²Œ corpus ìƒì„±
    corpus = df[title_field].fillna("").astype(str).tolist()
    corpus.append(search_query)  # ë§ˆì§€ë§‰ì— ê²€ìƒ‰ì–´ ì¶”ê°€
    
    try:
        # ë‹¨ì–´ ìˆ˜ì¤€ ë¶„ì„
        vectorizer = TfidfVectorizer(
            analyzer='word', 
            ngram_range=(1, 2),
            lowercase=True,
            max_features=5000
        )
        
        tfidf_matrix = vectorizer.fit_transform(corpus)
        
        # ë§ˆì§€ë§‰ í–‰(ê²€ìƒ‰ì–´)ê³¼ ë‚˜ë¨¸ì§€ í–‰(DB) ì‚¬ì´ì˜ ìœ ì‚¬ë„ ê³„ì‚°
        cosine_sim = cosine_similarity(tfidf_matrix[-1:], tfidf_matrix[:-1])[0]
        
        # ìœ ì‚¬ë„ ì ìˆ˜ê°€ ì˜¬ë°”ë¥¸ ê¸¸ì´ì¸ì§€ í™•ì¸
        if len(cosine_sim) != len(df):
            st.error(f"âŒ ìœ ì‚¬ë„ ë²¡í„° ê¸¸ì´({len(cosine_sim)})ì™€ ë°ì´í„°í”„ë ˆì„ ê¸¸ì´({len(df)})ê°€ ì¼ì¹˜í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
            return []
            
    except Exception as e:
        st.error(f"âŒ ìœ ì‚¬ë„ ë¶„ì„ ì˜¤ë¥˜: {str(e)}")
        return []
    
    # 5. ê²°ê³¼ ë°ì´í„°í”„ë ˆì„ ìƒì„± (ì›ë³¸ ìˆ˜ì • ë°©ì§€)
    result_df = df.copy()
    result_df['score'] = cosine_sim
    
    # ìµœì†Œ ìœ ì‚¬ë„ ì„ê³„ê°’ ì ìš©
    filtered_df = result_df[result_df['score'] > 0.1].copy()
    
    # ê²°ê³¼ê°€ ì—†ìœ¼ë©´ ë¹ˆ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜
    if filtered_df.empty:
        return []
    
    # 6. ìƒìœ„ ê²°ê³¼ ì„ íƒ
    top_df = filtered_df.sort_values(by='score', ascending=False).head(max_results)
    
    # 7. ìš”ì•½ ì •ë³´ ìƒì„± (ì•ˆì „í•˜ê²Œ)
    def safe_get_summary(row):
        try:
            if row['ìš”ì•½'] and str(row['ìš”ì•½']).strip() and str(row['ìš”ì•½']).strip() != "ìš”ì•½ ì—†ìŒ":
                return str(row['ìš”ì•½']).strip()
            else:
                return get_summary(row['ì œëª©'])
        except:
            return "ìš”ì•½ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    
    top_df.loc[:, 'ìš”ì•½'] = top_df.apply(safe_get_summary, axis=1)
    
    # 8. í•„ìš”í•œ ì—´ë§Œ ì„ íƒ
    result_columns = ['ì œëª©', 'ìš”ì•½', 'ì—°ë„', 'ë¶„ì•¼', 'score']
    available_columns = [col for col in result_columns if col in top_df.columns]
    
    # ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
    return top_df[available_columns].to_dict(orient='records')
