import pandas as pd
import os
import streamlit as st
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from utils.explain_topic import explain_topic
from openai import OpenAI
import re

# ğŸ“ ë‚´ë¶€ DB ê²½ë¡œ
DB_PATH = os.path.join("data", "ISEF Final DB.xlsx")

# ğŸ”¤ ISEF DB ì—´ ë§¤í•‘
COLUMN_MAP = {
    'Project Title': 'ì œëª©',
    'Year': 'ì—°ë„',
    'Category': 'ë¶„ì•¼',
    'Fair Country': 'êµ­ê°€',
    'Fair State': 'ì§€ì—­',
    'Awards': 'ìˆ˜ìƒ'
}

# í‚¤ì›Œë“œ ì¶”ì¶œ í•¨ìˆ˜
def extract_keywords(text, top_n=5):
    text = re.sub(r'[^\w\s]', '', text.lower())
    stopwords = ['ì´', 'ê·¸', 'ì €', 'ê²ƒ', 'ë°', 'ë“±', 'ë¥¼', 'ì„', 'ì—', 'ì—ì„œ', 'ì˜', 'ìœ¼ë¡œ', 'ë¡œ', 'ì—ê²Œ', 'í•˜ë‹¤', 'ìˆë‹¤', 'ë˜ë‹¤',
                'the', 'of', 'and', 'a', 'to', 'in', 'is', 'that', 'for', 'on', 'with']
    
    words = [word for word in text.split() if word not in stopwords and len(word) > 1]
    
    word_counts = {}
    for word in words:
        word_counts[word] = word_counts.get(word, 0) + 1
    
    sorted_words = sorted(word_counts.items(), key=lambda x: x[1], reverse=True)
    return [word for word, _ in sorted_words[:top_n]]

# íš¨ìœ¨ì ì¸ GPT ë²ˆì—­ í•¨ìˆ˜ - í‚¤ì›Œë“œë§Œ ë²ˆì—­
@st.cache_data(show_spinner=False)
def gpt_translate_keywords(keywords, tgt_lang="en") -> list:
    if not keywords:
        return []
        
    try:
        client = OpenAI(api_key=st.secrets["api"]["openai_key"])
        keyword_text = ", ".join(keywords)
        prompt = f"ë‹¤ìŒ í‚¤ì›Œë“œë“¤ì„ {tgt_lang}ë¡œ ë²ˆì—­í•´ì£¼ì„¸ìš”. ë²ˆì—­ëœ í‚¤ì›Œë“œë§Œ ì‰¼í‘œë¡œ êµ¬ë¶„í•˜ì—¬ ì•Œë ¤ì£¼ì„¸ìš”: {keyword_text}"
        
        res = client.chat.completions.create(
            model="gpt-4",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.3
        )
        
        translated = res.choices[0].message.content.strip()
        return [k.strip() for k in translated.split(',')]
    except Exception as e:
        st.warning(f"í‚¤ì›Œë“œ ë²ˆì—­ ì¤‘ ì˜¤ë¥˜: {e}")
        return keywords

# í”„ë¡œì íŠ¸ ë‚´ìš© ì¶”ë¡  í•¨ìˆ˜ (ìºì‹± ì ìš©)
@st.cache_data(show_spinner=False, ttl=3600)
def infer_project_content(title, category=None):
    try:
        prompt = title
        if category:
            prompt = f"{title} (ì—°êµ¬ ë¶„ì•¼: {category})"
            
        explanation = explain_topic(prompt)[0]
        return explanation
    except Exception as e:
        return f"ì´ í”„ë¡œì íŠ¸ëŠ” '{title}'ì— ê´€í•œ ì—°êµ¬ì…ë‹ˆë‹¤."

# ë‚´ë¶€ DB ë¡œë“œ ë° ì •ì œ
@st.cache_data(ttl=3600)
def load_internal_db():
    try:
        df = pd.read_excel(DB_PATH)
        return df
    except Exception as e:
        st.error(f"âŒ ë‚´ë¶€ DB ë¡œë“œ ì‹¤íŒ¨: {e}")
        return pd.DataFrame()

# ìœ ì‚¬ í”„ë¡œì íŠ¸ ê²€ìƒ‰ í•¨ìˆ˜
def search_similar_titles(user_input, max_results=5):
    df = load_internal_db()
    
    if df.empty:
        return []
    
    # 1. í‚¤ì›Œë“œ ì¶”ì¶œ
    keywords = extract_keywords(user_input)
    if not keywords:
        return []
    
    # 2. í‚¤ì›Œë“œ ë²ˆì—­ (API í˜¸ì¶œ 1íšŒ)
    translated_keywords = gpt_translate_keywords(keywords)
    if not translated_keywords:
        translated_keywords = keywords
    
    search_query = " ".join(translated_keywords)
    
    # 3. ì˜ì–´ ì œëª©ìœ¼ë¡œ ê²€ìƒ‰
    title_field = 'Project Title'
    if title_field not in df.columns:
        return []
    
    corpus = df[title_field].fillna("").astype(str).tolist()
    corpus.append(search_query)
    
    try:
        vectorizer = TfidfVectorizer(
            analyzer='word', 
            ngram_range=(1, 2),
            lowercase=True
        )
        
        tfidf_matrix = vectorizer.fit_transform(corpus)
        cosine_sim = cosine_similarity(tfidf_matrix[-1:], tfidf_matrix[:-1])[0]
    except Exception as e:
        return []
    
    # 4. ê²°ê³¼ ì •ë ¬
    result_df = df.copy()
    result_df['score'] = cosine_sim
    filtered_df = result_df[result_df['score'] > 0.05].copy()
    
    if filtered_df.empty:
        return []
    
    # 5. ìƒìœ„ ê²°ê³¼ ì„ íƒ
    top_df = filtered_df.sort_values(by='score', ascending=False).head(max_results)
    
    # 6. ê²°ê³¼ êµ¬ì„± (íŒŒì´ë„ë¦¬ìŠ¤íŠ¸ ì •ë³´ ì œì™¸)
    results = []
    for _, row in top_df.iterrows():
        project_title = row.get('Project Title', '')
        category = row.get('Category', '')
        
        result_item = {
            'ì œëª©': project_title,  # ì˜ì–´ ì œëª© ì‚¬ìš©
            'ì—°ë„': str(row.get('Year', '')),
            'ë¶„ì•¼': category,
            'êµ­ê°€': row.get('Fair Country', ''),
            'ì§€ì—­': row.get('Fair State', ''),
            'ìˆ˜ìƒ': row.get('Awards', ''),
            'ìš”ì•½': infer_project_content(project_title, category),  # í•„ìš”í•  ë•Œë§Œ ì¶”ë¡ 
            'score': float(row.get('score', 0))
        }
        
        results.append(result_item)
    
    return results
