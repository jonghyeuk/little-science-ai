from fpdf import FPDF
import os
import re
import warnings
from datetime import datetime
import contextlib

# ê²½ê³  ì–µì œ
warnings.filterwarnings("ignore", category=UserWarning, module="fpdf")
warnings.filterwarnings("ignore")

@contextlib.contextmanager
def suppress_warnings():
    with warnings.catch_warnings():
        warnings.simplefilter("ignore")
        yield

# ì„¤ì •
FONT_REGULAR = os.path.join("fonts", "NanumGothic-Regular.ttf")
FONT_BOLD = os.path.join("fonts", "NanumGothic-Bold.ttf")
OUTPUT_DIR = "outputs"

class ModernSciencePDF(FPDF):
    def __init__(self, topic="ê³¼í•™ ì—°êµ¬"):
        super().__init__(format='A4')
        self.set_auto_page_break(auto=True, margin=25)
        self.set_margins(20, 20, 20)
        self.topic = self.clean_text_minimal(topic)
        self.setup_fonts()
        self.page_count = 0
        
    def setup_fonts(self):
        """í°íŠ¸ ì„¤ì • - ê°„ë‹¨í•˜ê³  ì•ˆì •ì ìœ¼ë¡œ"""
        self.korean_available = False
        try:
            with suppress_warnings():
                if os.path.exists(FONT_REGULAR):
                    self.add_font('Korean', '', FONT_REGULAR, uni=True)
                    self.korean_available = True
                if os.path.exists(FONT_BOLD):
                    self.add_font('KoreanBold', '', FONT_BOLD, uni=True)
        except:
            pass
            
    def set_font_safe(self, weight='normal', size=10):
        """ì•ˆì „í•œ í°íŠ¸ ì„¤ì •"""
        try:
            if self.korean_available:
                font_name = 'KoreanBold' if weight == 'bold' else 'Korean'
                self.set_font(font_name, size=size)
            else:
                style = 'B' if weight == 'bold' else ''
                self.set_font('Arial', style, size)
        except:
            self.set_font('Arial', '', size)
    
    def header(self):
        if self.page_no() > 1:
            self.set_font_safe('normal', 8)
            self.set_text_color(150, 150, 150)
            header_text = f'{self.topic} - ì—°êµ¬íƒìƒ‰ë³´ê³ ì„œ'
            if len(header_text) > 40:
                header_text = header_text[:37] + "..."
            self.cell(0, 8, header_text, align='R', ln=True)
            self.ln(2)
            
    def footer(self):
        self.set_y(-15)
        self.set_font_safe('normal', 8)
        self.set_text_color(120, 120, 120)
        self.cell(0, 10, f'- {self.page_no()} -', align='C')
    
    def clean_text_minimal(self, text):
        """ìµœì†Œí•œì˜ í…ìŠ¤íŠ¸ ì •ë¦¬ - ìì—°ìŠ¤ëŸ¬ì›€ ë³´ì¡´"""
        if not text:
            return ""
        
        text = str(text)
        
        # ê¸°ë³¸ì ì¸ ì •ë¦¬ë§Œ
        text = re.sub(r'#{1,6}\s*', '', text)  # ë§ˆí¬ë‹¤ìš´ í—¤ë”ë§Œ ì œê±°
        text = re.sub(r'\*\*([^*]+)\*\*', r'\1', text)  # **ë³¼ë“œ** ì œê±°
        text = re.sub(r'[`]', '', text)  # ë°±í‹±ë§Œ ì œê±°
        text = re.sub(r'https?://[^\s\)]+', '', text)  # URL ì œê±°
        
        # ì´ëª¨ì§€ëŠ” ì¼ë¶€ë§Œ ì œê±° (ë„ˆë¬´ ë§ì´ ì œê±°í•˜ì§€ ì•ŠìŒ)
        common_emojis = r'[ğŸ“˜ğŸ“„ğŸŒğŸ”¬ğŸ’¡âš™ï¸ğŸŒğŸ“ŠğŸ¯]'
        text = re.sub(common_emojis, '', text)
        
        # ê³µë°± ì •ë¦¬
        text = re.sub(r'\s+', ' ', text)
        text = re.sub(r'\n\s*\n\s*\n+', '\n\n', text)
        
        return text.strip()
    
    def add_cover_page(self):
        """í˜„ëŒ€ì ì¸ í‘œì§€ í˜ì´ì§€"""
        self.add_page()
        
        # ìƒë‹¨ ê³µê°„
        self.ln(25)
        
        # ë©”ì¸ ì œëª©
        self.set_font_safe('bold', 22)
        self.set_text_color(30, 30, 30)
        self.multi_cell(0, 15, self.topic, align='C')
        self.ln(8)
        
        # ë¶€ì œëª©
        self.set_font_safe('normal', 16)
        self.set_text_color(80, 80, 80)
        self.multi_cell(0, 10, 'ê³¼í•™ ì—°êµ¬ íƒìƒ‰ ë³´ê³ ì„œ', align='C')
        
        # ì¥ì‹ì„ 
        self.ln(15)
        self.set_draw_color(100, 100, 100)
        self.line(50, self.get_y(), 160, self.get_y())
        self.ln(15)
        
        # ì„¤ëª…
        self.set_font_safe('normal', 11)
        self.set_text_color(100, 100, 100)
        description = "ë³¸ ë³´ê³ ì„œëŠ” AIë¥¼ í™œìš©í•˜ì—¬ ê³¼í•™ ì—°êµ¬ ì£¼ì œë¥¼ íƒìƒ‰í•˜ê³ ,\nê´€ë ¨ ë¬¸í—Œì„ ì¡°ì‚¬í•˜ë©°, ì—°êµ¬ ê³„íšì„ ìˆ˜ë¦½í•œ ê²°ê³¼ì…ë‹ˆë‹¤."
        self.multi_cell(0, 8, description, align='C')
        
        # í•˜ë‹¨ ì •ë³´
        self.ln(30)
        self.set_font_safe('normal', 10)
        self.set_text_color(120, 120, 120)
        today = datetime.now().strftime("%Yë…„ %mì›” %dì¼")
        self.multi_cell(0, 6, f'ìƒì„±ì¼: {today}', align='C')
        self.ln(2)
        self.multi_cell(0, 6, 'LittleScienceAI', align='C')
    
    def add_section_header(self, title, level=1):
        """ì„¹ì…˜ í—¤ë” ì¶”ê°€"""
        # í˜ì´ì§€ í•˜ë‹¨ì—ì„œ ì‹œì‘í•˜ì§€ ì•Šë„ë¡
        if self.get_y() > 240:
            self.add_page()
        
        self.ln(8)
        
        if level == 1:
            self.set_font_safe('bold', 16)
            self.set_text_color(40, 40, 40)
            # ì¥ì‹ì ì¸ ë¼ì¸ ì¶”ê°€
            self.set_draw_color(70, 130, 180)
            self.line(20, self.get_y()-2, 190, self.get_y()-2)
            self.ln(2)
        else:
            self.set_font_safe('bold', 13)
            self.set_text_color(60, 60, 60)
        
        self.multi_cell(0, 10, title, align='L')
        self.ln(4)
    
    def add_content_block(self, content, preserve_length=True):
        """ë‚´ìš© ë¸”ë¡ ì¶”ê°€ - ìì—°ìŠ¤ëŸ¬ì›€ ë³´ì¡´"""
        if not content:
            return
            
        self.set_font_safe('normal', 10)
        self.set_text_color(70, 70, 70)
        
        cleaned_content = self.clean_text_minimal(content)
        
        # í…ìŠ¤íŠ¸ ìë¥´ê¸° ìµœì†Œí™” - ì‚¬ìš©ì ì„ í˜¸ì‚¬í•­ ë°˜ì˜
        if preserve_length and len(cleaned_content) > 2000:
            # ë¬¸ë‹¨ ë‹¨ìœ„ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ì¤„ì´ê¸°
            paragraphs = cleaned_content.split('\n\n')
            kept_paragraphs = []
            total_length = 0
            
            for para in paragraphs:
                if total_length + len(para) < 1800:  # ì—¬ìœ ìˆê²Œ ì„¤ì •
                    kept_paragraphs.append(para)
                    total_length += len(para)
                else:
                    # ë§ˆì§€ë§‰ ë¬¸ì¥ê¹Œì§€ ì™„ì „íˆ í¬í•¨
                    sentences = para.split('. ')
                    for sent in sentences:
                        if total_length + len(sent) < 1900:
                            kept_paragraphs.append(sent + '.')
                            total_length += len(sent)
                        else:
                            break
                    break
            
            cleaned_content = '\n\n'.join(kept_paragraphs)
        
        # ìì—°ìŠ¤ëŸ¬ìš´ ì¤„ë°”ê¿ˆìœ¼ë¡œ ì¶œë ¥
        paragraphs = cleaned_content.split('\n\n')
        for para in paragraphs:
            if para.strip():
                self.multi_cell(0, 6, para.strip(), align='L')
                self.ln(3)
    
    def add_paper_card(self, title, summary, source=""):
        """ë…¼ë¬¸ ì¹´ë“œ í˜•íƒœë¡œ ì¶”ê°€"""
        # í˜ì´ì§€ ëì—ì„œ ì¹´ë“œê°€ ì‹œì‘ë˜ì§€ ì•Šë„ë¡
        if self.get_y() > 230:
            self.add_page()
        
        # ì¹´ë“œ ë°°ê²½ìƒ‰ (ì—°í•œ íšŒìƒ‰)
        self.set_fill_color(248, 249, 250)
        card_height = 35  # ì˜ˆìƒ ë†’ì´
        self.rect(15, self.get_y(), 180, card_height, 'F')
        
        # ì—¬ë°±
        self.ln(3)
        self.set_x(20)
        
        # ì œëª©
        self.set_font_safe('bold', 10)
        self.set_text_color(40, 40, 40)
        clean_title = self.clean_text_minimal(title)
        # ì œëª©ì€ ì ë‹¹íˆ ì¤„ì´ë˜ ìì—°ìŠ¤ëŸ½ê²Œ
        if len(clean_title) > 80:
            clean_title = clean_title[:77] + "..."
        self.multi_cell(175, 6, f"ğŸ“„ {clean_title}", align='L')
        
        # ì¶œì²˜
        if source:
            self.set_x(20)
            self.set_font_safe('normal', 8)
            self.set_text_color(120, 120, 120)
            self.multi_cell(175, 5, source, align='L')
        
        # ìš”ì•½
        self.set_x(20)
        self.set_font_safe('normal', 9)
        self.set_text_color(80, 80, 80)
        clean_summary = self.clean_text_minimal(summary)
        
        # ìš”ì•½ë„ ìì—°ìŠ¤ëŸ½ê²Œ ì¤„ì´ê¸°
        if len(clean_summary) > 300:
            sentences = clean_summary.split('. ')
            kept_sentences = []
            total_len = 0
            for sent in sentences:
                if total_len + len(sent) < 280:
                    kept_sentences.append(sent)
                    total_len += len(sent)
                else:
                    break
            clean_summary = '. '.join(kept_sentences)
            if not clean_summary.endswith('.'):
                clean_summary += '.'
        
        self.multi_cell(175, 5, clean_summary, align='L')
        self.ln(6)
    
    def add_research_section(self, title, content):
        """ì—°êµ¬ ê³„íš ì„¹ì…˜ ì¶”ê°€"""
        self.ln(5)
        
        # ì„¹ì…˜ ì œëª©
        self.set_font_safe('bold', 12)
        self.set_text_color(50, 50, 50)
        self.multi_cell(0, 8, title, align='L')
        self.ln(2)
        
        # ë‚´ìš©
        self.set_font_safe('normal', 10)
        self.set_text_color(70, 70, 70)
        cleaned_content = self.clean_text_minimal(content)
        
        # ì—°êµ¬ ê³„íšì€ ë” ìì„¸íˆ ë³´ì¡´
        if len(cleaned_content) > 1500:
            paragraphs = cleaned_content.split('\n')
            kept_paragraphs = []
            total_length = 0
            
            for para in paragraphs:
                if total_length + len(para) < 1400:
                    kept_paragraphs.append(para)
                    total_length += len(para)
                else:
                    break
            
            cleaned_content = '\n'.join(kept_paragraphs)
        
        self.multi_cell(0, 6, cleaned_content, align='L')
        self.ln(4)

def extract_topic_from_content(content):
    """ë‚´ìš©ì—ì„œ ì£¼ì œ ì¶”ì¶œ"""
    try:
        # ì œëª© íŒ¨í„´ë“¤ ì‹œë„
        patterns = [
            r'# ğŸ“˜\s*([^\n-]+?)(?:\s*-|$)',  # ê¸°ë³¸ íŒ¨í„´
            r'title["\']:\s*["\']([^"\']+)["\']',  # JSON íŒ¨í„´
            r'ì£¼ì œ[:\s]*([^\n]+)',  # ê°„ë‹¨ íŒ¨í„´
        ]
        
        for pattern in patterns:
            match = re.search(pattern, content, re.IGNORECASE)
            if match:
                topic = match.group(1).strip()
                # ë¶ˆí•„ìš”í•œ ë¶€ë¶„ ì œê±°
                topic = re.sub(r'ì£¼ì œ\s*í•´ì„¤', '', topic).strip()
                if len(topic) > 3:
                    return topic[:60] if len(topic) > 60 else topic
        
        return "ê³¼í•™ ì—°êµ¬ íƒìƒ‰"
    except:
        return "ê³¼í•™ ì—°êµ¬ íƒìƒ‰"

def extract_structured_data(content):
    """ì•±ì˜ êµ¬ì¡°í™”ëœ ë°ì´í„° ì¶”ì¶œ - ê°„ë‹¨í•˜ê³  ì•ˆì •ì ìœ¼ë¡œ"""
    result = {
        'topic_explanation': '',
        'isef_papers': [],
        'arxiv_papers': [],
        'generated_paper': {}
    }
    
    try:
        # ì£¼ì œ í•´ì„¤ ì¶”ì¶œ (ì²« ë²ˆì§¸ ì„¹ì…˜)
        explanation_match = re.search(r'# ğŸ“˜[^\n]*\n(.*?)(?=## ğŸ“„|## ğŸŒ|$)', content, re.DOTALL)
        if explanation_match:
            result['topic_explanation'] = explanation_match.group(1).strip()
        
        # ISEF ë…¼ë¬¸ ì¶”ì¶œ - ë” ê°„ë‹¨í•˜ê²Œ
        if "ISEF" in content and "ì¶œí’ˆë…¼ë¬¸" in content:
            isef_section = content[content.find("ISEF"):content.find("arXiv") if "arXiv" in content else len(content)]
            
            # ì œëª©ê³¼ ë‚´ìš© ë§¤ì¹­ - ë” ê´€ëŒ€í•˜ê²Œ
            title_pattern = r'ğŸ“Œ\s*([^\n]+?)(?:\n|$)'
            content_pattern = r'ğŸ“Œ[^\n]*\n[^\n]*\n([^ğŸ“Œ]+?)(?=ğŸ“Œ|$)'
            
            titles = re.findall(title_pattern, isef_section)
            contents = re.findall(content_pattern, isef_section, re.DOTALL)
            
            for i, title in enumerate(titles[:3]):  # ìµœëŒ€ 3ê°œ
                summary = contents[i].strip() if i < len(contents) else "ê´€ë ¨ ì—°êµ¬ í”„ë¡œì íŠ¸ì…ë‹ˆë‹¤."
                result['isef_papers'].append((title.strip(), summary))
        
        # arXiv ë…¼ë¬¸ ì¶”ì¶œ - ë” ê°„ë‹¨í•˜ê²Œ  
        if "arXiv" in content:
            arxiv_section = content[content.find("arXiv"):]
            
            title_pattern = r'ğŸŒ\s*([^\n]+?)(?:\n|$)'
            content_pattern = r'ğŸŒ[^\n]*\n[^\n]*\n([^ğŸŒ]+?)(?=ğŸŒ|$)'
            
            titles = re.findall(title_pattern, arxiv_section)
            contents = re.findall(content_pattern, arxiv_section, re.DOTALL)
            
            for i, title in enumerate(titles[:3]):  # ìµœëŒ€ 3ê°œ
                summary = contents[i].strip() if i < len(contents) else "ê´€ë ¨ ì—°êµ¬ ë…¼ë¬¸ì…ë‹ˆë‹¤."
                result['arxiv_papers'].append((title.strip(), summary))
        
        # ìƒì„±ëœ ë…¼ë¬¸ ì¶”ì¶œ
        if "ìƒì„±ëœ ì—°êµ¬ ë…¼ë¬¸" in content or "ìƒì„±ëœ ì—°êµ¬ê³„íšì„œ" in content:
            paper_section = content[content.find("ìƒì„±ëœ ì—°êµ¬"):]
            
            sections = {
                'ì´ˆë¡': r'ì´ˆë¡[^\n]*\n([^#]+?)(?=###|$)',
                'ì„œë¡ ': r'ì„œë¡ [^\n]*\n([^#]+?)(?=###|$)', 
                'ì‹¤í—˜ ë°©ë²•': r'ì‹¤í—˜\s*ë°©ë²•[^\n]*\n([^#]+?)(?=###|$)',
                'ì˜ˆìƒ ê²°ê³¼': r'ì˜ˆìƒ\s*ê²°ê³¼[^\n]*\n([^#]+?)(?=###|$)',
                'ê²°ë¡ ': r'ê²°ë¡ [^\n]*\n([^#]+?)(?=###|$)',
                'ì°¸ê³ ë¬¸í—Œ': r'ì°¸ê³ ë¬¸í—Œ[^\n]*\n([^#]+?)(?=###|$)'
            }
            
            for section_name, pattern in sections.items():
                match = re.search(pattern, paper_section, re.DOTALL | re.IGNORECASE)
                if match:
                    content_text = match.group(1).strip()
                    if len(content_text) > 20:
                        result['generated_paper'][section_name] = content_text
        
        return result
        
    except Exception as e:
        print(f"ë°ì´í„° ì¶”ì¶œ ì˜¤ë¥˜: {e}")
        return result

def generate_modern_pdf(content, filename="research_report.pdf"):
    """ìƒˆë¡œìš´ í˜„ëŒ€ì  PDF ìƒì„±"""
    try:
        # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
        os.makedirs(OUTPUT_DIR, exist_ok=True)
        
        # ë°ì´í„° ì¶”ì¶œ
        topic = extract_topic_from_content(content)
        data = extract_structured_data(content)
        
        print(f"ğŸ“Š PDF ìƒì„± ì‹œì‘: {topic}")
        print(f"   - ì£¼ì œí•´ì„¤: {len(data['topic_explanation'])}ì")
        print(f"   - ISEF ë…¼ë¬¸: {len(data['isef_papers'])}ê°œ")
        print(f"   - arXiv ë…¼ë¬¸: {len(data['arxiv_papers'])}ê°œ") 
        print(f"   - ìƒì„±ëœ ë…¼ë¬¸: {len(data['generated_paper'])}ê°œ ì„¹ì…˜")
        
        # PDF ìƒì„±
        with suppress_warnings():
            pdf = ModernSciencePDF(topic)
            
            # 1. í‘œì§€
            pdf.add_cover_page()
            
            # 2. ì£¼ì œ íƒìƒ‰
            pdf.add_page()
            pdf.add_section_header("ğŸ”¬ ì£¼ì œ íƒìƒ‰ ë° ë¶„ì„")
            
            if data['topic_explanation']:
                # ê°œë… ì •ì˜ ë¶€ë¶„ ì¶”ì¶œ
                explanation = data['topic_explanation']
                
                # ê°œë… ì •ì˜
                if 'ê°œë…' in explanation or 'ì •ì˜' in explanation:
                    concept_section = explanation.split('ì‘ìš©')[0] if 'ì‘ìš©' in explanation else explanation[:800]
                    if len(concept_section) > 100:
                        pdf.add_section_header("ê°œë… ì •ì˜ ë° ì›ë¦¬", level=2)
                        pdf.add_content_block(concept_section)
                
                # í™•ì¥ ê°€ëŠ¥í•œ íƒêµ¬ ì•„ì´ë””ì–´
                if 'í™•ì¥ ê°€ëŠ¥í•œ íƒêµ¬' in explanation:
                    ideas_start = explanation.find('í™•ì¥ ê°€ëŠ¥í•œ íƒêµ¬')
                    ideas_section = explanation[ideas_start:]
                    if len(ideas_section) > 100:
                        pdf.add_section_header("ì—°êµ¬ ì•„ì´ë””ì–´", level=2)
                        pdf.add_content_block(ideas_section)
            
            # 3. ê´€ë ¨ ì—°êµ¬ ì¡°ì‚¬
            pdf.add_section_header("ğŸ“š ê´€ë ¨ ì—°êµ¬ ë¬¸í—Œ ì¡°ì‚¬")
            
            # ISEF ì—°êµ¬
            if data['isef_papers']:
                pdf.add_section_header("ISEF í”„ë¡œì íŠ¸ ë¶„ì„", level=2)
                for title, summary in data['isef_papers']:
                    pdf.add_paper_card(title, summary, "ì¶œì²˜: ISEF (International Science and Engineering Fair)")
            
            # arXiv ì—°êµ¬
            if data['arxiv_papers']:
                pdf.add_section_header("ìµœì‹  ì—°êµ¬ë…¼ë¬¸ ë¶„ì„", level=2)
                for title, summary in data['arxiv_papers']:
                    pdf.add_paper_card(title, summary, "ì¶œì²˜: arXiv (í”„ë¦¬í”„ë¦°íŠ¸ ë…¼ë¬¸ì €ì¥ì†Œ)")
            
            # 4. ì—°êµ¬ ê³„íšì„œ
            if data['generated_paper']:
                pdf.add_section_header("ğŸ“ ì—°êµ¬ ê³„íšì„œ")
                
                # ë…¼ë¬¸ ì„¹ì…˜ë“¤ì„ ìˆœì„œëŒ€ë¡œ
                section_order = ['ì´ˆë¡', 'ì„œë¡ ', 'ì‹¤í—˜ ë°©ë²•', 'ì˜ˆìƒ ê²°ê³¼', 'ê²°ë¡ ', 'ì°¸ê³ ë¬¸í—Œ']
                section_english = {
                    'ì´ˆë¡': 'Abstract',
                    'ì„œë¡ ': 'Introduction', 
                    'ì‹¤í—˜ ë°©ë²•': 'Methods',
                    'ì˜ˆìƒ ê²°ê³¼': 'Expected Results',
                    'ê²°ë¡ ': 'Conclusion',
                    'ì°¸ê³ ë¬¸í—Œ': 'References'
                }
                
                for section_name in section_order:
                    if section_name in data['generated_paper']:
                        english_name = section_english.get(section_name, section_name)
                        title = f"{section_name} ({english_name})"
                        content_text = data['generated_paper'][section_name]
                        
                        if section_name == 'ì°¸ê³ ë¬¸í—Œ':
                            pdf.add_section_header(title, level=2)
                            # ì°¸ê³ ë¬¸í—Œì€ ë³„ë„ ì²˜ë¦¬
                            pdf.add_content_block("ì‹¤ì œ ì—°êµ¬ ìˆ˜í–‰ ì‹œ ê´€ë ¨ ë…¼ë¬¸ë“¤ì„ ì°¾ì•„ APA ìŠ¤íƒ€ì¼ë¡œ ì‘ì„±í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.", preserve_length=False)
                        else:
                            pdf.add_section_header(title, level=2)
                            pdf.add_content_block(content_text, preserve_length=True)
            
            # ì €ì¥
            output_path = os.path.join(OUTPUT_DIR, filename)
            pdf.output(output_path)
        
        # ê²€ì¦
        if os.path.exists(output_path) and os.path.getsize(output_path) > 5000:
            print(f"âœ… PDF ìƒì„± ì„±ê³µ: {output_path}")
            return output_path
        else:
            raise Exception("PDF íŒŒì¼ì´ ì˜¬ë°”ë¥´ê²Œ ìƒì„±ë˜ì§€ ì•ŠìŒ")
            
    except Exception as e:
        print(f"âŒ PDF ìƒì„± ì‹¤íŒ¨: {e}")
        
        # ì‹¤íŒ¨ì‹œ í…ìŠ¤íŠ¸ íŒŒì¼ë¡œ ë°±ì—…
        try:
            txt_path = os.path.join(OUTPUT_DIR, filename.replace('.pdf', '_backup.txt'))
            with open(txt_path, 'w', encoding='utf-8') as f:
                f.write(f"=== {topic} ì—°êµ¬íƒìƒ‰ë³´ê³ ì„œ ===\n")
                f.write(f"ìƒì„±ì¼: {datetime.now()}\n\n")
                f.write("PDF ìƒì„±ì— ì‹¤íŒ¨í•˜ì—¬ í…ìŠ¤íŠ¸ë¡œ ì €ì¥í•©ë‹ˆë‹¤.\n\n")
                f.write(content)
            return txt_path
        except:
            return None

# ê¸°ì¡´ í•¨ìˆ˜ ì´ë¦„ í˜¸í™˜ì„±ì„ ìœ„í•´
def generate_pdf(content, filename="research_report.pdf"):
    """ê¸°ì¡´ í•¨ìˆ˜ëª… í˜¸í™˜ì„±"""
    return generate_modern_pdf(content, filename)
