# app.py ìˆ˜ì •ë³¸ (ì •ë³´ ì„¤ëª…ì„ ì‚¬ì´ë“œë°”ë¡œ ì´ë™ + DB ì´ˆê¸°í™” ì¶”ê°€ + í‹ˆìƒˆì£¼ì œ ì„ íƒ ê¸°ëŠ¥ ì¶”ê°€)
import streamlit as st
import time
import re
import logging
from utils.layout import load_css
from utils.search_db import search_similar_titles, initialize_db  # initialize_db ì¶”ê°€
from utils.search_arxiv import search_arxiv
from utils.explain_topic import explain_topic
from utils.pdf_generator import generate_pdf
from utils.generate_paper import generate_research_paper

# 3. ì¶”ê°€: streamlit ì½˜ì†” ë¡œê·¸ í™•ì¸ì„ ìœ„í•œ ì½”ë“œ (ë§¨ ìœ„ì— ì¶”ê°€)
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# ì•± ì‹œì‘ ì‹œ DB ì´ˆê¸°í™” (ì„±ëŠ¥ ìµœì í™”)
initialize_db()

# í‹ˆìƒˆì£¼ì œ íŒŒì‹± í•¨ìˆ˜ (ìˆ˜ì •ëœ ë²„ì „)
def parse_niche_topics(explanation_lines):
    """explain_topic ê²°ê³¼ì—ì„œ í™•ì¥ ê°€ëŠ¥í•œ íƒêµ¬ ì•„ì´ë””ì–´ ì„¹ì…˜ì„ íŒŒì‹±"""
    try:
        topics = []
        
        # ì „ì²´ ë¼ì¸ì„ í•˜ë‚˜ì˜ í…ìŠ¤íŠ¸ë¡œ í•©ì¹˜ê¸°
        full_text = "\n".join(explanation_lines)
        print(f"=== ì „ì²´ í…ìŠ¤íŠ¸ í™•ì¸ ===\n{full_text[:500]}...\n")
        
        # "í™•ì¥ ê°€ëŠ¥í•œ íƒêµ¬ ì•„ì´ë””ì–´" ì„¹ì…˜ ì°¾ê¸°
        if "í™•ì¥ ê°€ëŠ¥í•œ íƒêµ¬ ì•„ì´ë””ì–´" in full_text:
            # í•´ë‹¹ ì„¹ì…˜ ì´í›„ì˜ í…ìŠ¤íŠ¸ ì¶”ì¶œ
            section_start = full_text.find("í™•ì¥ ê°€ëŠ¥í•œ íƒêµ¬ ì•„ì´ë””ì–´")
            section_text = full_text[section_start:]
            print(f"=== ì„¹ì…˜ í…ìŠ¤íŠ¸ ===\n{section_text[:300]}...\n")
            
            # ë¼ì¸ë³„ë¡œ ë¶„ë¦¬
            lines = section_text.split('\n')
            
            current_topic = ""
            current_description = ""
            
            for line in lines:
                line = line.strip()
                print(f"ì²˜ë¦¬ ì¤‘ì¸ ë¼ì¸: '{line}'")
                
                # â€¢ ë¡œ ì‹œì‘í•˜ëŠ” ì œëª© ì°¾ê¸°
                if line.startswith('â€¢') and len(line) > 2:
                    # ì´ì „ ì£¼ì œê°€ ìˆë‹¤ë©´ ì €ì¥
                    if current_topic:
                        full_topic = f"{current_topic}"
                        if current_description:
                            full_topic += f" - {current_description}"
                        topics.append(full_topic)
                        print(f"ì£¼ì œ ì €ì¥: {full_topic}")
                    
                    # ìƒˆ ì£¼ì œ ì‹œì‘
                    current_topic = line[1:].strip()  # â€¢ ì œê±°
                    current_description = ""
                    print(f"ìƒˆ ì£¼ì œ ì‹œì‘: {current_topic}")
                
                # Â· ë¡œ ì‹œì‘í•˜ëŠ” ì„¤ëª… ì°¾ê¸°  
                elif line.startswith('Â·') and current_topic and len(line) > 2:
                    current_description = line[1:].strip()  # Â· ì œê±°
                    print(f"ì„¤ëª… ì¶”ê°€: {current_description}")
            
            # ë§ˆì§€ë§‰ ì£¼ì œ ì €ì¥
            if current_topic:
                full_topic = f"{current_topic}"
                if current_description:
                    full_topic += f" - {current_description}"
                topics.append(full_topic)
                print(f"ë§ˆì§€ë§‰ ì£¼ì œ ì €ì¥: {full_topic}")
        
        print(f"=== ìµœì¢… íŒŒì‹±ëœ ì£¼ì œë“¤ ===\n{topics}\n")
        
        # ìµœì†Œ 3ê°œ ë³´ì¥
        if len(topics) >= 3:
            return topics
        else:
            fallback_topics = [
                "ê¸°ì¡´ ì—°êµ¬ì˜ í•œê³„ì  ê°œì„  - í˜„ì¬ ì—°êµ¬ì—ì„œ ë¶€ì¡±í•œ ë¶€ë¶„ì„ ì°¾ì•„ ê°œì„ ë°©ì•ˆ ì œì‹œ",
                "ì‹¤ìš©ì  ì‘ìš© ë°©ì•ˆ íƒêµ¬ - ì‹¤ìƒí™œì— ì ìš©í•  ìˆ˜ ìˆëŠ” êµ¬ì²´ì  ë°©ë²• ì—°êµ¬", 
                "ë‹¤ë¥¸ ë¶„ì•¼ì™€ì˜ ìœµí•© ì—°êµ¬ - íƒ€ í•™ë¬¸ ë¶„ì•¼ì™€ ì—°ê²°í•œ ìƒˆë¡œìš´ ì ‘ê·¼ë²•"
            ]
            print(f"fallback ì£¼ì œ ì‚¬ìš©: {fallback_topics}")
            return fallback_topics
        
    except Exception as e:
        print(f"íŒŒì‹± ì˜¤ë¥˜: {e}")  # ë””ë²„ê¹…ìš©
        fallback_topics = [
            "ê¸°ì¡´ ì—°êµ¬ì˜ í•œê³„ì  ê°œì„  - í˜„ì¬ ì—°êµ¬ì—ì„œ ë¶€ì¡±í•œ ë¶€ë¶„ì„ ì°¾ì•„ ê°œì„ ë°©ì•ˆ ì œì‹œ",
            "ì‹¤ìš©ì  ì‘ìš© ë°©ì•ˆ íƒêµ¬ - ì‹¤ìƒí™œì— ì ìš©í•  ìˆ˜ ìˆëŠ” êµ¬ì²´ì  ë°©ë²• ì—°êµ¬",
            "ë‹¤ë¥¸ ë¶„ì•¼ì™€ì˜ ìœµí•© ì—°êµ¬ - íƒ€ í•™ë¬¸ ë¶„ì•¼ì™€ ì—°ê²°í•œ ìƒˆë¡œìš´ ì ‘ê·¼ë²•"
        ]
        return fallback_topics

# DOI ê°ì§€ ë° ë§í¬ ë³€í™˜ í•¨ìˆ˜
def convert_doi_to_links(text):
    """DOI íŒ¨í„´ì„ ê°ì§€í•˜ì—¬ í´ë¦­ ê°€ëŠ¥í•œ ë§í¬ë¡œ ë³€í™˜"""
    # DOI íŒ¨í„´ ì •ê·œ í‘œí˜„ì‹: 10.XXXX/YYYY í˜•ì‹
    doi_pattern = r'(?<!\w)(?:DOI\s*:\s*)?(\b10\.\d{4,}\/[a-zA-Z0-9./_()-]+\b)'
    
    # HTML ë§í¬ë¡œ ë³€í™˜
    def replace_doi(match):
        doi = match.group(1)
        return f'<a href="https://doi.org/{doi}" target="_blank" style="color: #0969da; text-decoration: none;">{doi}</a>'
    
    # í…ìŠ¤íŠ¸ ë‚´ DOI íŒ¨í„´ì„ ë§í¬ë¡œ ë³€í™˜
    linked_text = re.sub(doi_pattern, replace_doi, text)
    
    return linked_text

# ê¸°ë³¸ ì„¤ì •
st.set_page_config(page_title="LittleScienceAI", layout="wide")
load_css()

# ì¤‘ì•™ ì •ë ¬ CSS
st.markdown("""
<style>
section.main > div.block-container {
    max-width: 800px !important; 
    margin: 0 auto !important;
    padding: 2rem 3rem !important;
    background-color: white !important;
}

.sidebar-info-box {
    background-color: #f8f9fa;
    padding: 10px;
    border-radius: 5px;
    margin-bottom: 15px;
    border-left: 3px solid #4a86e8;
    font-size: 0.9em;
}

.sidebar-info-box h4 {
    margin-top: 0;
    color: #2c5aa0;
}

.sidebar-info-box.arxiv {
    border-left-color: #4caf50;
}

.sidebar-info-box.arxiv h4 {
    color: #2e7d32;
}

.paper-subsection {
    background-color: #f8f9fa;
    border-radius: 8px;
    padding: 15px;
    margin: 15px 0;
    border-left: 3px solid #28a745;
}

.stButton > button {
    height: 50px;
    display: flex;
    align-items: center;
    justify-content: center;
}
</style>
""", unsafe_allow_html=True)

# ì¸ì¦ ì‹œìŠ¤í…œ
ACCESS_KEYS = st.secrets["general"]["access_keys"]
if "authenticated" not in st.session_state:
    st.session_state.authenticated = False

if not st.session_state.authenticated:
    st.markdown("## LittleScienceAI ë¡œê·¸ì¸")
    user_key = st.text_input("ğŸ”‘ ì¸ì¦ í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”", type="password")
    
    if user_key in ACCESS_KEYS:
        st.session_state.authenticated = True
        st.rerun()
    elif user_key:
        st.warning("ğŸš« ì˜¬ë°”ë¥¸ ì¸ì¦ í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
    st.stop()

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” (ğŸ”¥ ìºì‹±ìš© ìƒíƒœ ì¶”ê°€)
if 'niche_topics' not in st.session_state:
    st.session_state.niche_topics = []
if 'generated_paper' not in st.session_state:
    st.session_state.generated_paper = {}
# ğŸ”¥ ìºì‹±ìš© ì„¸ì…˜ ìƒíƒœ (ìµœì†Œí•œë§Œ ì¶”ê°€)
if 'last_searched_topic' not in st.session_state:
    st.session_state.last_searched_topic = ""
if 'cached_internal_results' not in st.session_state:
    st.session_state.cached_internal_results = []
if 'cached_arxiv_results' not in st.session_state:
    st.session_state.cached_arxiv_results = []

# ì‚¬ì´ë“œë°”
st.sidebar.title("ğŸ§­ íƒìƒ‰ ë‹¨ê³„")
st.sidebar.markdown("""
1. ì£¼ì œ ì…ë ¥
2. ê°œë… í•´ì„¤ ë³´ê¸°
3. ë…¼ë¬¸ ì¶”ì²œ í™•ì¸
4. í‹ˆìƒˆì£¼ì œ ì„ íƒ
5. ë…¼ë¬¸ í˜•ì‹ ì‘ì„±
6. PDF ì €ì¥
""")

# ì‚¬ì´ë“œë°”ì— í•™ìˆ  ìë£Œ ì„¤ëª… ì¶”ê°€
st.sidebar.markdown("---")
st.sidebar.markdown("### ğŸ“š í•™ìˆ  ìë£Œ ì •ë³´")

# ISEF ì„¤ëª… ì¶”ê°€
st.sidebar.markdown("""
<div class="sidebar-info-box">
<h4>ğŸ“Š ISEF</h4>
<p>
ì„¸ê³„ ìµœëŒ€ ê·œëª¨ì˜ ê³ ë“±í•™ìƒ ê³¼í•™ ê²½ì§„ëŒ€íšŒë¡œ, 80ì—¬ ê°œêµ­ì—ì„œ 1,800ëª… ì´ìƒì˜ í•™ìƒë“¤ì´ ì°¸ê°€í•˜ì—¬ í˜ì‹ ì ì¸ ì—°êµ¬ í”„ë¡œì íŠ¸ë¥¼ ë°œí‘œí•©ë‹ˆë‹¤. 1950ë…„ë¶€í„° ì‹œì‘ëœ ì´ ëŒ€íšŒëŠ” ê³¼í•™, ê¸°ìˆ , ê³µí•™, ìˆ˜í•™(STEM) ë¶„ì•¼ì˜ ì°¨ì„¸ëŒ€ ì¸ì¬ë¥¼ ë°œêµ´í•©ë‹ˆë‹¤.
</p>
</div>
""", unsafe_allow_html=True)

# arXiv ì„¤ëª… ì¶”ê°€
st.sidebar.markdown("""
<div class="sidebar-info-box arxiv">
<h4>ğŸ“‘ arXiv</h4>
<p>
ë¬¼ë¦¬í•™, ìˆ˜í•™, ì»´í“¨í„° ê³¼í•™ ë“±ì˜ ë¶„ì•¼ì—ì„œ ì—°êµ¬ìë“¤ì´ ë…¼ë¬¸ì„ ì •ì‹ ì¶œíŒ ì „ì— ê³µìœ í•˜ëŠ” í”Œë«í¼ì…ë‹ˆë‹¤. ì½”ë„¬ ëŒ€í•™ì—ì„œ ìš´ì˜í•˜ë©°, ìµœì‹  ì—°êµ¬ ë™í–¥ì„ ë¹ ë¥´ê²Œ ì ‘í•  ìˆ˜ ìˆì§€ë§Œ ì¼ë¶€ëŠ” ì•„ì§ peer reviewë¥¼ ê±°ì¹˜ì§€ ì•Šì€ ìƒíƒœì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
</p>
</div>
""", unsafe_allow_html=True)

# ë©”ì¸ íƒ€ì´í‹€
st.title("ğŸ§ª ê³¼í•™ë…¼ë¬¸ ì£¼ì œ íƒìƒ‰ ë„ìš°ë¯¸")

# ì´ˆê¸°í™”
if 'full_text' not in st.session_state:
    st.session_state.full_text = ""

# ê²€ìƒ‰ì°½
topic = st.text_input("ğŸ”¬ ì—°êµ¬í•˜ê³  ì‹¶ì€ ê³¼í•™ ì£¼ì œë¥¼ ì…ë ¥í•˜ì„¸ìš”:", 
                     placeholder="ì˜ˆ: ì–‘ì ì»´í“¨íŒ…, ìœ ì „ì í¸ì§‘, ë¯¸ìƒë¬¼ ì—°ë£Œì „ì§€...")

# ğŸ”¥ ì£¼ì œê°€ ì…ë ¥ëœ ê²½ìš° (ìºì‹± ë¡œì§ ì ìš©)
if topic:
    # ìƒˆ ì£¼ì œì¼ ë•Œë§Œ ê²€ìƒ‰ ì‹¤í–‰
    if True:  # st.session_state.last_searched_topic != topic:
        # ìƒˆ ì£¼ì œ ê²€ìƒ‰
        st.session_state.last_searched_topic = topic
        st.session_state.generated_paper = {}  # ë…¼ë¬¸ ì´ˆê¸°í™”
        
        # ì£¼ì œ í•´ì„¤ í‘œì‹œ
        st.subheader("ğŸ“˜ ì£¼ì œ í•´ì„¤")
        
        # ì¦‰ì‹œ í•´ì„¤ ìƒì„± ë° í‘œì‹œ (DOI ë§í¬ ë³€í™˜ ì¶”ê°€)
        with st.spinner("ğŸ¤– AIê°€ ì£¼ì œ ë¶„ì„ ì¤‘..."):
            try:
                explanation_lines = explain_topic(topic)
                explanation_text = "\n\n".join(explanation_lines)
                
                # í‹ˆìƒˆì£¼ì œ íŒŒì‹± ë° ì €ì¥
                print("=== ë””ë²„ê¹…: explanation_lines êµ¬ì¡° ===")
                for i, line in enumerate(explanation_lines):
                    print(f"ë¼ì¸ {i}: {repr(line[:100])}...")  # ì²˜ìŒ 100ìë§Œ ì¶œë ¥
                    if "í™•ì¥ ê°€ëŠ¥í•œ íƒêµ¬ ì•„ì´ë””ì–´" in line:
                        print(f"*** ì°¾ì•˜ë‹¤! ë¼ì¸ {i}ì— í™•ì¥ ê°€ëŠ¥í•œ íƒêµ¬ ì•„ì´ë””ì–´ ìˆìŒ ***")
                        print(f"ì „ì²´ ë‚´ìš©: {repr(line)}")
                        break
                print("=== ë””ë²„ê¹… ë ===")

                st.session_state.niche_topics = parse_niche_topics(explanation_lines)
                
                # DOI íŒ¨í„´ì„ ë§í¬ë¡œ ë³€í™˜ (í™”ë©´ í‘œì‹œìš©)
                linked_explanation = convert_doi_to_links(explanation_text)
                
                # ë§í¬ê°€ í¬í•¨ëœ ì„¤ëª… í‘œì‹œ
                st.markdown(linked_explanation, unsafe_allow_html=True)
                
                # PDFìš© í…ìŠ¤íŠ¸ëŠ” ì›ë³¸ í˜•ì‹ìœ¼ë¡œ ì €ì¥ (ë§ˆí¬ë‹¤ìš´ í˜•ì‹)
                st.session_state.full_text = f"# ğŸ“˜ {topic} - ì£¼ì œ í•´ì„¤\n\n{explanation_text}\n\n"
            except Exception as e:
                st.error(f"ì£¼ì œ í•´ì„¤ ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}")
                st.session_state.full_text = f"# ğŸ“˜ {topic} - ì£¼ì œ í•´ì„¤\n\nìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ\n\n"
        
        # ğŸ”¥ ë‚´ë¶€ DB ê²€ìƒ‰ ê²°ê³¼ (ê²€ìƒ‰ ì‹¤í–‰ + ê²°ê³¼ ì €ì¥)
        st.subheader("ğŸ“„ ISEF (International Science and Engineering Fair) ì¶œí’ˆë…¼ë¬¸")
        
        with st.spinner("ğŸ” ISEF ê´€ë ¨ í”„ë¡œì íŠ¸ë¥¼ ë¹ ë¥´ê²Œ ê²€ìƒ‰ ì¤‘..."):
            try:
                # ê²€ìƒ‰ ì‹¤í–‰ ë° ìºì‹œ ì €ì¥
                st.session_state.cached_internal_results = search_similar_titles(topic)
                internal_results = st.session_state.cached_internal_results
                
                if not internal_results:
                    st.info("â— ê´€ë ¨ í”„ë¡œì íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
                    st.session_state.full_text += "## ğŸ“„ ë‚´ë¶€ DB ìœ ì‚¬ ë…¼ë¬¸\n\nâ— ê´€ë ¨ í”„ë¡œì íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.\n\n"
                else:
                    st.session_state.full_text += "## ğŸ“„ ë‚´ë¶€ DB ìœ ì‚¬ ë…¼ë¬¸\n\n"
                    
                    for project in internal_results:
                        title = project.get('ì œëª©', '')
                        summary = project.get('ìš”ì•½', '')
                        
                        # ë©”íƒ€ ì •ë³´
                        meta_parts = []
                        if project.get('ì—°ë„'):
                            meta_parts.append(f"ğŸ“… {project['ì—°ë„']}")
                        if project.get('ë¶„ì•¼'):
                            meta_parts.append(f"ğŸ”¬ {project['ë¶„ì•¼']}")
                        if project.get('êµ­ê°€'):
                            loc = project['êµ­ê°€']
                            if project.get('ì§€ì—­'):
                                loc += f", {project['ì§€ì—­']}"
                            meta_parts.append(f"ğŸŒ {loc}")
                        if project.get('ìˆ˜ìƒ'):
                            meta_parts.append(f"ğŸ† {project['ìˆ˜ìƒ']}")
                        
                        meta_text = " Â· ".join(meta_parts)
                        
                        # ë‚´ë¶€ ê²°ê³¼ì—ì„œë„ DOI ë³€í™˜ ì ìš©
                        linked_summary = convert_doi_to_links(summary)
                        
                        # ì¹´ë“œ í˜•íƒœë¡œ í‘œì‹œ
                        st.markdown(f"""
                        <div style="background-color: #f8f9fa; border: 1px solid #eee; border-radius: 8px; padding: 16px; margin: 16px 0;">
                            <h3 style="color: #333; margin-top: 0;">ğŸ“Œ {title}</h3>
                            <p style="color: #666; font-style: italic; margin-bottom: 12px;">{meta_text}</p>
                            <p>{linked_summary}</p>
                        </div>
                        """, unsafe_allow_html=True)
                        
                        st.session_state.full_text += f"- **{title}**\n{summary}\n_{meta_text}_\n\n"
            except Exception as e:
                st.error(f"ë‚´ë¶€ DB ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {str(e)}")
                st.session_state.cached_internal_results = []
                st.session_state.full_text += "## ğŸ“„ ë‚´ë¶€ DB ìœ ì‚¬ ë…¼ë¬¸\n\nê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ\n\n"
        
        # ğŸ”¥ arXiv ê²°ê³¼ (ê²€ìƒ‰ ì‹¤í–‰ + ê²°ê³¼ ì €ì¥)
        st.subheader("ğŸŒ ì•„ì¹´ì´ë¸Œ arXiv ì—ì„œ ì°¾ì€ ê´€ë ¨ ë…¼ë¬¸")
        
        with st.spinner("ğŸ” arXiv ë…¼ë¬¸ ê²€ìƒ‰ ì¤‘..."):
            try:
                # ê²€ìƒ‰ ì‹¤í–‰ ë° ìºì‹œ ì €ì¥
                st.session_state.cached_arxiv_results = search_arxiv(topic)
                arxiv_results = st.session_state.cached_arxiv_results
                
                if not arxiv_results:
                    st.info("â— ê´€ë ¨ ë…¼ë¬¸ì´ ì—†ìŠµë‹ˆë‹¤.")
                    st.session_state.full_text += "## ğŸŒ arXiv ìœ ì‚¬ ë…¼ë¬¸\n\nâ— ê´€ë ¨ ë…¼ë¬¸ì´ ì—†ìŠµë‹ˆë‹¤.\n\n"
                else:
                    st.session_state.full_text += "## ğŸŒ arXiv ìœ ì‚¬ ë…¼ë¬¸\n\n"
                    
                    for paper in arxiv_results:
                        title = paper.get('title', '')
                        summary = paper.get('summary', '')
                        link = paper.get('link', '')
                        
                        # arXiv ê²°ê³¼ì—ì„œë„ DOI ë³€í™˜ ì ìš©
                        linked_summary = convert_doi_to_links(summary)
                        
                        # ì¹´ë“œ í˜•íƒœë¡œ í‘œì‹œ (í”„ë¦¬í”„ë¦°íŠ¸ í‘œì‹œ ì¶”ê°€)
                        st.markdown(f"""
                        <div style="background-color: #f8f9fa; border: 1px solid #eee; border-radius: 8px; padding: 16px; margin: 16px 0;">
                            <h3 style="color: #333; margin-top: 0;">ğŸŒ {title}</h3>
                            <p style="color: #666; font-style: italic; margin-bottom: 12px;">ì¶œì²˜: arXiv (í”„ë¦¬í”„ë¦°íŠ¸ ì €ì¥ì†Œ)</p>
                            <p>{linked_summary}</p>
                            <a href="{link}" target="_blank" style="color: #0969da; text-decoration: none;">ğŸ”— ë…¼ë¬¸ ë§í¬ ë³´ê¸°</a>
                        </div>
                        """, unsafe_allow_html=True)
                        
                        st.session_state.full_text += f"- **{title}**\n{summary}\n[ë§í¬]({link})\n\n"
            except Exception as e:
                st.error(f"arXiv ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {str(e)}")
                st.session_state.cached_arxiv_results = []
                st.session_state.full_text += "## ğŸŒ arXiv ìœ ì‚¬ ë…¼ë¬¸\n\nê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ\n\n"
    
    else:
        # ğŸ”¥ ê°™ì€ ì£¼ì œ - ìºì‹œ ì‚¬ìš© (ìŠ¤í”¼ë„ˆ ì—†ì´ ì €ì¥ëœ ê²°ê³¼ í‘œì‹œ)
        st.subheader("ğŸ“˜ ì£¼ì œ í•´ì„¤")
        if st.session_state.full_text:
            explanation_part = st.session_state.full_text.split("## ğŸ“„ ë‚´ë¶€ DB ìœ ì‚¬ ë…¼ë¬¸")[0]
            explanation_text = explanation_part.replace(f"# ğŸ“˜ {topic} - ì£¼ì œ í•´ì„¤\n\n", "")
            linked_explanation = convert_doi_to_links(explanation_text)
            st.markdown(linked_explanation, unsafe_allow_html=True)
        
        # ğŸ”¥ ìºì‹œëœ ISEF ê²°ê³¼ í‘œì‹œ (ì›ë³¸ ë¡œì§ ê·¸ëŒ€ë¡œ)
        st.subheader("ğŸ“„ ISEF (International Science and Engineering Fair) ì¶œí’ˆë…¼ë¬¸")
        
        internal_results = st.session_state.cached_internal_results
        if not internal_results:
            st.info("â— ê´€ë ¨ í”„ë¡œì íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
        else:
            for project in internal_results:
                title = project.get('ì œëª©', '')
                summary = project.get('ìš”ì•½', '')
                
                # ë©”íƒ€ ì •ë³´
                meta_parts = []
                if project.get('ì—°ë„'):
                    meta_parts.append(f"ğŸ“… {project['ì—°ë„']}")
                if project.get('ë¶„ì•¼'):
                    meta_parts.append(f"ğŸ”¬ {project['ë¶„ì•¼']}")
                if project.get('êµ­ê°€'):
                    loc = project['êµ­ê°€']
                    if project.get('ì§€ì—­'):
                        loc += f", {project['ì§€ì—­']}"
                    meta_parts.append(f"ğŸŒ {loc}")
                if project.get('ìˆ˜ìƒ'):
                    meta_parts.append(f"ğŸ† {project['ìˆ˜ìƒ']}")
                
                meta_text = " Â· ".join(meta_parts)
                
                # ë‚´ë¶€ ê²°ê³¼ì—ì„œë„ DOI ë³€í™˜ ì ìš©
                linked_summary = convert_doi_to_links(summary)
                
                # ì¹´ë“œ í˜•íƒœë¡œ í‘œì‹œ
                st.markdown(f"""
                <div style="background-color: #f8f9fa; border: 1px solid #eee; border-radius: 8px; padding: 16px; margin: 16px 0;">
                    <h3 style="color: #333; margin-top: 0;">ğŸ“Œ {title}</h3>
                    <p style="color: #666; font-style: italic; margin-bottom: 12px;">{meta_text}</p>
                    <p>{linked_summary}</p>
                </div>
                """, unsafe_allow_html=True)
        
        # ğŸ”¥ ìºì‹œëœ arXiv ê²°ê³¼ í‘œì‹œ (ì›ë³¸ ë¡œì§ ê·¸ëŒ€ë¡œ)
        st.subheader("ğŸŒ ì•„ì¹´ì´ë¸Œ arXiv ì—ì„œ ì°¾ì€ ê´€ë ¨ ë…¼ë¬¸")
        
        arxiv_results = st.session_state.cached_arxiv_results
        if not arxiv_results:
            st.info("â— ê´€ë ¨ ë…¼ë¬¸ì´ ì—†ìŠµë‹ˆë‹¤.")
        else:
            for paper in arxiv_results:
                title = paper.get('title', '')
                summary = paper.get('summary', '')
                link = paper.get('link', '')
                
                # arXiv ê²°ê³¼ì—ì„œë„ DOI ë³€í™˜ ì ìš©
                linked_summary = convert_doi_to_links(summary)
                
                # ì¹´ë“œ í˜•íƒœë¡œ í‘œì‹œ (í”„ë¦¬í”„ë¦°íŠ¸ í‘œì‹œ ì¶”ê°€)
                st.markdown(f"""
                <div style="background-color: #f8f9fa; border: 1px solid #eee; border-radius: 8px; padding: 16px; margin: 16px 0;">
                    <h3 style="color: #333; margin-top: 0;">ğŸŒ {title}</h3>
                    <p style="color: #666; font-style: italic; margin-bottom: 12px;">ì¶œì²˜: arXiv (í”„ë¦¬í”„ë¦°íŠ¸ ì €ì¥ì†Œ)</p>
                    <p>{linked_summary}</p>
                    <a href="{link}" target="_blank" style="color: #0969da; text-decoration: none;">ğŸ”— ë…¼ë¬¸ ë§í¬ ë³´ê¸°</a>
                </div>
                """, unsafe_allow_html=True)
    
    # ========== í‹ˆìƒˆì£¼ì œ ì„ íƒ ì„¹ì…˜ ì¶”ê°€ ==========
    if st.session_state.niche_topics:
        st.markdown("---")
        st.subheader("ğŸ¯ ì„¸ë¶€ í‹ˆìƒˆì£¼ì œ ì„ íƒ")
        st.markdown("ìœ„ì—ì„œ ì œì•ˆëœ íƒêµ¬ ì•„ì´ë””ì–´ ì¤‘ì—ì„œ **1ê°œ**ë¥¼ ì„ íƒí•˜ì—¬ ì²´ê³„ì ì¸ ë…¼ë¬¸ í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•´ë³´ì„¸ìš”.")
        
        # ë¼ë””ì˜¤ ë²„íŠ¼ìœ¼ë¡œ 1ê°œë§Œ ì„ íƒ
        selected_topic_index = st.radio(
            "ì—°êµ¬í•˜ê³  ì‹¶ì€ í‹ˆìƒˆì£¼ì œë¥¼ ì„ íƒí•˜ì„¸ìš”:",
            range(len(st.session_state.niche_topics)),
            format_func=lambda x: f"ì£¼ì œ {x+1}: {st.session_state.niche_topics[x]}",
            key="selected_niche_topic"
        )
        
        # ğŸ”¥ ë…¼ë¬¸ ìƒì„± ë²„íŠ¼ (st.rerun() ì œê±°)
        if st.button("ğŸ“ ì„ íƒí•œ ì£¼ì œë¡œ ë…¼ë¬¸ í˜•ì‹ ì‘ì„±í•˜ê¸°", type="primary"):
            selected_idea = st.session_state.niche_topics[selected_topic_index]
            
            print(f"=== ë…¼ë¬¸ ìƒì„± ì‹œì‘ ===")
            print(f"ì£¼ì œ: {topic}")
            print(f"ì„ íƒëœ ì•„ì´ë””ì–´: {selected_idea}")
            print(f"ì°¸ê³ ìë£Œ ê¸¸ì´: {len(st.session_state.full_text)} ë¬¸ì")
            
            # ë…¼ë¬¸ ìƒì„±
            with st.spinner("ğŸ¤– AIê°€ ì²´ê³„ì ì¸ ë…¼ë¬¸ì„ ì‘ì„± ì¤‘ì…ë‹ˆë‹¤... (ì•½ 30ì´ˆ ì†Œìš”)"):
                try:
                    st.session_state.generated_paper = generate_research_paper(
                        topic=topic, 
                        research_idea=selected_idea, 
                        references=st.session_state.full_text
                    )
                    print(f"ë…¼ë¬¸ ìƒì„± ì™„ë£Œ: {type(st.session_state.generated_paper)}")
                    print(f"ë…¼ë¬¸ í‚¤ë“¤: {list(st.session_state.generated_paper.keys()) if isinstance(st.session_state.generated_paper, dict) else 'dictê°€ ì•„ë‹˜'}")
                except Exception as e:
                    print(f"ë…¼ë¬¸ ìƒì„± ì˜¤ë¥˜: {e}")
                    st.error(f"ë…¼ë¬¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
                    st.session_state.generated_paper = {}
            
            if st.session_state.generated_paper:
                st.success("ğŸ“„ ë…¼ë¬¸ì´ ì„±ê³µì ìœ¼ë¡œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤!")
                # st.rerun() â† ğŸ”¥ ì œê±°!
            else:
                st.error("ë…¼ë¬¸ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
    
    # ========== ë…¼ë¬¸ í‘œì‹œ ì„¹ì…˜ ==========
    if st.session_state.generated_paper and isinstance(st.session_state.generated_paper, dict):
        st.markdown("---")
        st.subheader("ğŸ“„ ìƒì„±ëœ ì—°êµ¬ ë…¼ë¬¸")
        
        paper_data = st.session_state.generated_paper
        
        # ì´ˆë¡
        if paper_data.get("abstract"):
            st.markdown('<div class="paper-subsection">', unsafe_allow_html=True)
            st.markdown("### ğŸ“‹ ì´ˆë¡ (Abstract)")
            st.markdown(paper_data["abstract"])
            st.markdown('</div>', unsafe_allow_html=True)
        
        # ì‹¤í—˜ ë°©ë²•
        if paper_data.get("methods"):
            st.markdown('<div class="paper-subsection">', unsafe_allow_html=True)
            st.markdown("### ğŸ”¬ ì‹¤í—˜ ë°©ë²• (Methods)")
            st.markdown(paper_data["methods"])
            st.markdown('</div>', unsafe_allow_html=True)
        
        # ì˜ˆìƒ ê²°ê³¼
        if paper_data.get("results"):
            st.markdown('<div class="paper-subsection">', unsafe_allow_html=True)
            st.markdown("### ğŸ“Š ì˜ˆìƒ ê²°ê³¼ (Expected Results)")
            st.markdown(paper_data["results"])
            st.markdown('</div>', unsafe_allow_html=True)
        
        # ì‹œê°ìë£Œ ì œì•ˆ
        if paper_data.get("visuals"):
            st.markdown('<div class="paper-subsection">', unsafe_allow_html=True)
            st.markdown("### ğŸ“ˆ ì‹œê°ìë£Œ ì œì•ˆ (Suggested Visualizations)")
            st.markdown(paper_data["visuals"])
            st.markdown('</div>', unsafe_allow_html=True)
        
        # ê²°ë¡ 
        if paper_data.get("conclusion"):
            st.markdown('<div class="paper-subsection">', unsafe_allow_html=True)
            st.markdown("### ğŸ¯ ê²°ë¡  (Conclusion)")
            st.markdown(paper_data["conclusion"])
            st.markdown('</div>', unsafe_allow_html=True)
        
        # ì°¸ê³ ë¬¸í—Œ
        if paper_data.get("references"):
            st.markdown('<div class="paper-subsection">', unsafe_allow_html=True)
            st.markdown("### ğŸ“š ì°¸ê³ ë¬¸í—Œ (References)")
            st.markdown(paper_data["references"])
            st.markdown('</div>', unsafe_allow_html=True)
        
        # PDFìš© í…ìŠ¤íŠ¸ì— ë…¼ë¬¸ ë‚´ìš© ì¶”ê°€
        paper_text = f"""
## ğŸ“„ ìƒì„±ëœ ì—°êµ¬ ë…¼ë¬¸

### ì´ˆë¡
{paper_data.get("abstract", "")}

### ì‹¤í—˜ ë°©ë²•
{paper_data.get("methods", "")}

### ì˜ˆìƒ ê²°ê³¼
{paper_data.get("results", "")}

### ì‹œê°ìë£Œ ì œì•ˆ
{paper_data.get("visuals", "")}

### ê²°ë¡ 
{paper_data.get("conclusion", "")}

### ì°¸ê³ ë¬¸í—Œ
{paper_data.get("references", "")}
"""
        st.session_state.full_text += paper_text
        
        # ë‹¤ì‹œ ì‘ì„± ë²„íŠ¼
        if st.button("ğŸ”„ ë‹¤ë¥¸ ì£¼ì œë¡œ ë‹¤ì‹œ ì‘ì„±í•˜ê¸°"):
            st.session_state.generated_paper = {}
            st.rerun()
    
    # PDF ì €ì¥ ë²„íŠ¼ (ê¸°ì¡´ ìœ„ì¹˜ ìœ ì§€)
    if st.session_state.full_text:
        st.markdown("---")
        if st.button("ğŸ“¥ ì´ ë‚´ìš© PDFë¡œ ì €ì¥í•˜ê¸°"):
            path = generate_pdf(st.session_state.full_text)
            with open(path, "rb") as f:
                st.download_button(
                    "ğŸ“„ PDF ë‹¤ìš´ë¡œë“œ", 
                    f, 
                    file_name="little_science_ai_research.pdf",
                    mime="application/pdf"
                )
